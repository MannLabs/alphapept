{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1bcb4c",
   "metadata": {},
   "source": [
    "# Paper Figure 4: ML scoring\n",
    "\n",
    "Now with arabidopsis FDR estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0517e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from test_files import get_files, prepare_test\n",
    "\n",
    "files = ['thermo_HeLa.raw', 'human.fasta', 'arabidopsis.fasta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c07291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir F:\\alphapept\\sandbox\\temp/fig4.\n"
     ]
    }
   ],
   "source": [
    "tmp_folder = os.path.join(os.getcwd(),'temp/')\n",
    "test_folder = 'fig4'\n",
    "\n",
    "get_files(tmp_folder, files)\n",
    "prepare_test(files, tmp_folder, test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623f43e",
   "metadata": {},
   "source": [
    "## Search raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ff559c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import alphapept.settings\n",
    "import alphapept.paths\n",
    "import alphapept.interface\n",
    "\n",
    "test_folder = os.path.join(tmp_folder, test_folder)\n",
    "\n",
    "file_name = os.path.join(test_folder, files[0])\n",
    "settings = alphapept.settings.load_settings(alphapept.paths.DEFAULT_SETTINGS_PATH)\n",
    "settings['experiment']['file_paths'] = [file_name]\n",
    "settings['experiment']['fasta_paths'] = [os.path.join(test_folder, _) for _ in ['human.fasta', 'arabidopsis.fasta']]\n",
    "#settings_ = alphapept.interface.run_complete_workflow(settings)\n",
    "base, ext = os.path.splitext(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d912a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'F:\\alphapept\\sandbox\\temp\\fig4\\thermo_HeLa.ms_data.hdf', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d7487788e78b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0malphapept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_ML_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_with_ML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_with_x_tandem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut_global_fdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_RF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_precursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut_fdr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mms_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malphapept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMS_Data_File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'thermo_HeLa.ms_data.hdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mms_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'second_search'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\alphapept\\alphapept\\io.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file_name, is_read_only, is_new_file, is_overwritable)\u001b[0m\n\u001b[0;32m    625\u001b[0m                 \u001b[0mhdf_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"last_updated\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhdf_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_overwritable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\alphapept\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\.conda\\envs\\alphapept\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'F:\\alphapept\\sandbox\\temp\\fig4\\thermo_HeLa.ms_data.hdf', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import alphapept.io\n",
    "from alphapept.score import get_ML_features, filter_with_ML, filter_with_x_tandem, cut_global_fdr, train_RF, filter_score, filter_precursor, cut_fdr\n",
    "\n",
    "ms_file = alphapept.io.MS_Data_File(os.path.join(test_folder,'thermo_HeLa.ms_data.hdf'))\n",
    "\n",
    "df = ms_file.read(dataset_name='second_search')\n",
    "df_ = get_ML_features(df)\n",
    "\n",
    "df = df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exclude_features = ['precursor_idx','ion_idx','fasta_index','feature_rank','raw_rank','rank','db_idx', 'feature_idx', 'precursor', 'query_idx', 'raw_idx','sequence','decoy','naked_sequence','target']\n",
    "train_fdr_level = 0.1\n",
    "ini_score = 'x_tandem'\n",
    "min_train = 1000\n",
    "test_size = 0.8\n",
    "max_depth = [5,25,50]\n",
    "max_leaf_nodes = [150,200,250]\n",
    "n_jobs=-1\n",
    "scoring='accuracy'\n",
    "plot = True\n",
    "random_state = 42\n",
    "\n",
    "features = [_ for _ in df.columns if _ not in exclude_features]\n",
    "\n",
    "# Setup ML pipeline\n",
    "scaler = StandardScaler()\n",
    "rfc = RandomForestClassifier(random_state=random_state) # class_weight={False:1,True:5},\n",
    "## Initiate scaling + classification pipeline\n",
    "pipeline = Pipeline([('scaler', scaler), ('clf', rfc)])\n",
    "parameters = {'clf__max_depth':(max_depth), 'clf__max_leaf_nodes': (max_leaf_nodes)}\n",
    "## Setup grid search framework for parameter selection and internal cross validation\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=5, scoring=scoring,\n",
    "                 verbose=0,return_train_score=True,n_jobs=n_jobs)\n",
    "\n",
    "# Prepare target and decoy df\n",
    "df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "df['target'] = ~df['decoy']\n",
    "df['score'] = df[ini_score]\n",
    "dfT = df[~df.decoy]\n",
    "dfD = df[df.decoy]\n",
    "\n",
    "# Select high scoring targets (<= train_fdr_level)\n",
    "df_prescore = filter_score(df)\n",
    "df_prescore = filter_precursor(df_prescore)\n",
    "scored = cut_fdr(df_prescore, fdr_level = train_fdr_level, plot=False)[1]\n",
    "highT = scored[scored.decoy==False]\n",
    "dfT_high = dfT[dfT['query_idx'].isin(highT.query_idx)]\n",
    "dfT_high = dfT_high[dfT_high['db_idx'].isin(highT.db_idx)]\n",
    "\n",
    "# Determine the number of psms for semi-supervised learning\n",
    "n_train = int(dfT_high.shape[0])\n",
    "if dfD.shape[0] < n_train:\n",
    "    n_train = int(dfD.shape[0])\n",
    "    logging.info(\"The total number of available decoys is lower than the initial set of high scoring targets.\")\n",
    "if n_train < min_train:\n",
    "    raise ValueError(\"There are fewer high scoring targets or decoys than required by 'min_train'.\")\n",
    "\n",
    "# Subset the targets and decoys datasets to result in a balanced dataset\n",
    "df_training = dfT_high.sample(n=n_train, random_state=random_state).append(dfD.sample(n=n_train, random_state=random_state))\n",
    "\n",
    "# Select training and test sets\n",
    "X = df_training[features]\n",
    "y = df_training['target'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=test_size, random_state=random_state, stratify=y.values)\n",
    "\n",
    "# Train the classifier on the training set via 5-fold cross-validation and subsequently test on the test set\n",
    "logging.info('Training & cross-validation on {} targets and {} decoys'.format(np.sum(y_train),X_train.shape[0]-np.sum(y_train)))\n",
    "cv.fit(X_train,y_train)\n",
    "\n",
    "logging.info('The best parameters selected by 5-fold cross-validation were {}'.format(cv.best_params_))\n",
    "logging.info('The train {} was {}'.format(scoring, cv.score(X_train, y_train)))\n",
    "logging.info('Testing on {} targets and {} decoys'.format(np.sum(y_test),X_test.shape[0]-np.sum(y_test)))\n",
    "logging.info('The test {} was {}'.format(scoring, cv.score(X_test, y_test)))\n",
    "\n",
    "feature_importances=cv.best_estimator_.named_steps['clf'].feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1][:40]\n",
    "\n",
    "top_features = X.columns[indices][:40]\n",
    "top_score = feature_importances[indices][:40]\n",
    "\n",
    "feature_dict = dict(zip(top_features, top_score))\n",
    "logging.info(f\"Top features {feature_dict}\")\n",
    "\n",
    "# Inspect feature importances\n",
    "if plot:\n",
    "    import seaborn as sns\n",
    "    g = sns.barplot(y=X.columns[indices][:40],\n",
    "                    x = feature_importances[indices][:40],\n",
    "                    orient='h', palette='RdBu')\n",
    "    g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "    g.set_ylabel(\"Features\",fontsize=12)\n",
    "    g.tick_params(labelsize=9)\n",
    "    g.set_title(\"Feature importance\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f168691",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_blue = '#17212b'\n",
    "light_blue = '#3dc5ef'\n",
    "teal= '#42dee1'\n",
    "green = '#6eecb9'\n",
    "yellow = '#eef5b3'\n",
    "hfont = {'fontname':'Arial', 'size':10}\n",
    "\n",
    "colors = [dark_blue, light_blue, teal, green, yellow]\n",
    "\n",
    "plt.figure(figsize=(2.363*1.5,2.363)) #60x60\n",
    "\n",
    "height=0.5\n",
    "top_n = 10\n",
    "color_index = 3\n",
    "\n",
    "y = list(X.columns[indices][:top_n][::-1])\n",
    "x = feature_importances[indices][:top_n][::-1]\n",
    "\n",
    "remainder = feature_importances[indices][top_n:].sum()\n",
    "\n",
    "x = np.append(remainder, x)\n",
    "y = ['Remainder'] + y\n",
    "\n",
    "plt.barh(y, x, height, color = colors[color_index], linewidth=1, edgecolor='black')\n",
    "\n",
    "plt.xticks(**hfont)\n",
    "plt.yticks(**hfont)\n",
    "plt.xlabel('Relative importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_feature_importance.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24065e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_with_x_tandem(df_)\n",
    "\n",
    "decoy_ = df[df[\"decoy\"]]['score']\n",
    "target_ = df[~df[\"decoy\"]]['score']\n",
    "\n",
    "plt.figure(figsize=(2.363, 2.363)) #60x60\n",
    "\n",
    "bins = np.linspace(df['score'].min(), 75, 60)\n",
    "histogram, bins = np.histogram(decoy_, bins=bins, density=True)\n",
    "histogram_, bins = np.histogram(target_, bins=bins, density=True)\n",
    "\n",
    "bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "plt.plot(bin_centers, histogram_, color=colors[1], label='Target')\n",
    "plt.fill_between(bin_centers, histogram_, alpha=0.7, color=colors[1])\n",
    "\n",
    "plt.plot(bin_centers, histogram, color=colors[0], label='Decoy')\n",
    "plt.fill_between(bin_centers, histogram, alpha=0.7, color=colors[0])\n",
    "\n",
    "plt.xticks(**hfont)\n",
    "plt.yticks(**hfont)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('X!')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_x_score.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a361a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_with_ML(df_, cv, features = features)\n",
    "\n",
    "decoy_ = df[df[\"decoy\"]]['score']\n",
    "target_ = df[~df[\"decoy\"]]['score']\n",
    "\n",
    "plt.figure(figsize=(2.363, 2.363)) #60x60\n",
    "\n",
    "bins = np.linspace(0, 1, 60)\n",
    "histogram, bins = np.histogram(decoy_, bins=bins, density=True)\n",
    "histogram_, bins = np.histogram(target_, bins=bins, density=True)\n",
    "\n",
    "bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "plt.plot(bin_centers, histogram_, color=colors[1], label='Target')\n",
    "plt.fill_between(bin_centers, histogram_, alpha=0.7, color=colors[1])\n",
    "\n",
    "plt.plot(bin_centers, histogram, color=colors[0], label='Decoy')\n",
    "plt.fill_between(bin_centers, histogram, alpha=0.7, color=colors[0])\n",
    "\n",
    "plt.xticks(**hfont)\n",
    "plt.yticks(**hfont)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('ML')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_ml_score.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d52206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = filter_with_ML(df_, cv, features = features)\n",
    "df_x = filter_with_x_tandem(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_fdr = cut_global_fdr(df_ml, analyte_level='precursor')\n",
    "df_x_fdr = cut_global_fdr(df_x, analyte_level='precursor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_fdr = df_ml_fdr.sort_values(by='q_value')\n",
    "df_ml_fdr = df_ml_fdr.reset_index(drop=True)\n",
    "\n",
    "df_x_fdr = df_x_fdr.sort_values(by='q_value')\n",
    "df_x_fdr = df_x_fdr.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.363, 2.363)) #60x60\n",
    "plt.plot(df_ml_fdr['q_value'], df_ml_fdr.index, label='ML', color = colors[3])\n",
    "plt.plot(df_x_fdr['q_value'], df_x_fdr.index, label ='X!', color = colors[0])\n",
    "plt.xlabel('q-value')\n",
    "plt.ylabel('Identified PSMs')\n",
    "\n",
    "plt.yticks([0, 1e4, 2e4, 3e4, 4e4, 5e4, 6e4])\n",
    "plt.xticks([0.00, 0.005, 0.01])\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(**hfont)\n",
    "plt.yticks(**hfont)\n",
    "plt.savefig('figures/04_psms.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphapept.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679cf7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = alphapept.fasta.read_database(os.path.join(test_folder,'database.hdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a20e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pept_dict = db['pept_dict'].item()\n",
    "fasta_dict = db['fasta_dict'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_cp = df_ml.copy()\n",
    "\n",
    "proteins = df_ml['sequence'].apply(lambda x: [fasta_dict[y]['name'] for y in pept_dict[x]])\n",
    "\n",
    "list_ = []\n",
    "\n",
    "\n",
    "for _ in proteins:\n",
    "    hum = 0\n",
    "    ara = 0\n",
    "    for k in _:\n",
    "        if 'HUM' in k:\n",
    "            hum +=1\n",
    "        if 'ARA' in k:\n",
    "            ara +=1\n",
    "\n",
    "    if (ara == 0) and (hum > 0):\n",
    "        list_.append('HUM')\n",
    "    elif (hum == 0) and (ara > 0):\n",
    "        list_.append('ARA')\n",
    "    else:\n",
    "\n",
    "        list_.append('X')\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac95574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_cp['species'] = list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27584a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = df_ml_cp[['species','score','decoy']].sort_values('score')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9441085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_['HUM_cum'] = np.cumsum(sorted_['species'] == 'HUM')\n",
    "sorted_['ARA_cum'] = np.cumsum(sorted_['species'] == 'ARA')\n",
    "sorted_['X_cum'] = np.cumsum(sorted_['species'] == 'X')\n",
    "sorted_['decoy_cum'] = np.cumsum(sorted_['decoy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a48546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_fdr_ = df_ml_fdr.copy()\n",
    "\n",
    "proteins = df_ml_fdr_['sequence'].apply(lambda x: [fasta_dict[y]['name'] for y in pept_dict[x]])\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for _ in proteins:\n",
    "    hum = 0\n",
    "    ara = 0\n",
    "    for k in _:\n",
    "        if 'HUM' in k:\n",
    "            hum +=1\n",
    "        if 'ARA' in k:\n",
    "            ara +=1\n",
    "\n",
    "    if (ara == 0) and (hum > 0):\n",
    "        list_.append('HUM')\n",
    "    elif (hum == 0) and (ara > 0):\n",
    "        list_.append('ARA')\n",
    "    else:\n",
    "        list_.append('X')\n",
    "        \n",
    "df_ml_fdr_['species'] = list_ \n",
    "\n",
    "\n",
    "df_ml_fdr_['ARA_cum'] = np.cumsum(df_ml_fdr_['species'] == 'ARA')\n",
    "df_ml_fdr_['ARA_cum_q'] = get_q_values(df_ml_fdr_['ARA_cum'].values/ np.arange(1, len(df_ml_fdr_)+1))\n",
    "\n",
    "df_x_fdr_ = df_x_fdr.copy()\n",
    "\n",
    "proteins = df_x_fdr_['sequence'].apply(lambda x: [fasta_dict[y]['name'] for y in pept_dict[x]])\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for _ in proteins:\n",
    "    hum = 0\n",
    "    ara = 0\n",
    "    for k in _:\n",
    "        if 'HUM' in k:\n",
    "            hum +=1\n",
    "        if 'ARA' in k:\n",
    "            ara +=1\n",
    "\n",
    "    if (ara == 0) and (hum > 0):\n",
    "        list_.append('HUM')\n",
    "    elif (hum == 0) and (ara > 0):\n",
    "        list_.append('ARA')\n",
    "    else:\n",
    "        list_.append('X')\n",
    "        \n",
    "df_x_fdr_['species'] = list_ \n",
    "\n",
    "\n",
    "df_x_fdr_['ARA_cum'] = np.cumsum(df_x_fdr_['species'] == 'ARA')\n",
    "df_x_fdr_['ARA_cum_q'] = get_q_values(df_x_fdr_['ARA_cum'].values/ np.arange(1, len(df_x_fdr_)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphapept.score import get_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ce332",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.363, 2.363)) #60x60\n",
    "\n",
    "plt.plot(df_ml_fdr_['ARA_cum_q'], df_ml_fdr_.index, label='ML', color = colors[3])\n",
    "plt.plot(df_x_fdr_['ARA_cum_q'], df_x_fdr_.index, label='X!', color = colors[0])\n",
    "#plt.plot(df_x_fdr['q_value'], df_x_fdr.index, label ='X!', color = colors[0])\n",
    "plt.xlabel('q-value')\n",
    "plt.ylabel('Identified PSMs')\n",
    "\n",
    "plt.yticks([0, 1e4, 2e4, 3e4, 4e4, 5e4, 6e4])\n",
    "plt.xticks([0.00, 0.005, 0.01])\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(**hfont)\n",
    "plt.yticks(**hfont)\n",
    "plt.savefig('figures/04_q.pdf')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-alphapept] *",
   "language": "python",
   "name": "conda-env-.conda-alphapept-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
