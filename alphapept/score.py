# AUTOGENERATED! DO NOT EDIT! File to edit: 06_score.ipynb (unless otherwise specified).

__all__ = ['filter_seq', 'filter_score', 'get_q_values', 'cut_fdr', 'score_x_tandem', 'get_protein_groups',
           'perform_protein_grouping', 'cut_global_fdr', 'save_report_as_npz']

# Cell
from numba import njit
import numpy as np
import pandas as pd

def filter_seq(df):
    """
    Filter df by sequence

    """
    df["rank_sequence"] = (
        df.groupby("sequence")["score"].rank("dense", ascending=False).astype("int")
    )
    df_filtered = df[df["rank_sequence"] == 1]

    return df_filtered


def filter_score(df):
    """
    Filter df by score
    TODO: PSMS could get the same score when having modifications. Only keep one

    """
    df["rank"] = df.groupby("query_idx")["score"].rank("dense", ascending=False).astype("int")

    df_filtered = df[df["rank"] == 1]
    # in case two hits have the same score and therfore rank only accept the first one
    df_filtered = df_filtered.drop_duplicates("query_idx")

    # TOD: this needs to be sorted out, for modifications -> What if we have MoxM -> oxMM, this will screw up with the filter sequence part
    return df_filtered

@njit
def get_q_values(fdr_values):
    """
    Calculate q values from fdr_values
    """
    q_values = np.zeros_like(fdr_values)
    min_q_value = np.max(fdr_values)
    for i in range(len(fdr_values) - 1, -1, -1):
        fdr = fdr_values[i]
        if fdr < min_q_value:
            min_q_value = fdr
        q_values[i] = min_q_value

    return q_values

# Cell
def cut_fdr(df, fdr_level=0.01, plot=True, verbose=True):
    """
    Cuts a dataframe with a given fdr level

    Args:
        fdr_level: fdr level that should be used
        plot: flag to enable plot
        verbose: flag to enable printing of results

    Returns:
        cutoff: df with psms within fdr
        cutoff_value: numerical value of score cutoff

    Raises:

    """

    df["target"] = ~df["decoy"]

    df = df.sort_values(by=["score","decoy"], ascending=False)
    df = df.reset_index()

    df["target_cum"] = np.cumsum(df["target"])
    df["decoys_cum"] = np.cumsum(df["decoy"])

    df["fdr"] = df["decoys_cum"] / df["target_cum"]
    df["q_value"] = get_q_values(df["fdr"].values)

    last_q_value = df["q_value"].iloc[-1]
    first_q_value = df["q_value"].iloc[0]

    if last_q_value < fdr_level:
        if verbose:
            print('Last q_value {:.3f} of dataset is smaller than fdr_level {:.3f}'.format(last_q_value, fdr_level))
        cutoff_index = len(df)-1

    elif first_q_value > fdr_level:
        if verbose:
            print('First q_value {:.3f} of dataset is larger than fdr_level {:.3f}'.format(last_q_value, fdr_level))
        cutoff_index = 0

    else:
        cutoff_index = df[df["q_value"].gt(fdr_level)].index[0] - 1

    cutoff_value = df.loc[cutoff_index]["score"]
    cutoff = df[df["score"] >= cutoff_value]

    targets = df.loc[cutoff_index, "target_cum"]
    decoy = df.loc[cutoff_index, "decoys_cum"]

    fdr = df.loc[cutoff_index, "fdr"]

    if verbose:
        print(
            "{:,} target ({:,} decoy) of {} PSM. fdr {:.6f} for a cutoff of {:.2f} ".format(
                targets, decoy, len(df), fdr, cutoff_value
            )
        )

    if plot:
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.figure(figsize=(10, 5))
        plt.plot(df["score"], df["fdr"])
        plt.axhline(0.01, color="k", linestyle="--")

        plt.axvline(cutoff_value, color="r", linestyle="--")
        plt.title("fdr vs Cutoff value")
        plt.xlabel("Score")
        plt.ylabel("fdr")
        # plt.savefig('fdr.png')
        plt.show()

        bins = np.linspace(np.min(df["score"]), np.max(df["score"]), 100)
        plt.figure(figsize=(10, 5))
        sns.distplot(df[df["decoy"]]["score"].values, label="decoy", bins=bins)
        sns.distplot(df[~df["decoy"]]["score"].values, label="target", bins=bins)
        plt.xlabel("Score")
        plt.ylabel("Frequency")
        plt.title("Score vs Class")
        plt.legend()
        plt.show()

    cutoff = cutoff.reset_index(drop=True)
    return cutoff_value, cutoff

# Cell

import networkx as nx

def score_x_tandem(df, fdr_level = 0.01, plot = True, verbose=True, **kwargs):
    df['b_hits'] = df['b_hits'].astype('int')
    df['y_hits'] = df['y_hits'].astype('int')

    df['b_hits_fac'] = df['b_hits'].apply(lambda x: np.math.factorial(x))
    df['y_hits_fac'] = df['y_hits'].apply(lambda x: np.math.factorial(x))

    df['score'] = df['matched_int']*df['b_hits_fac']*df['y_hits_fac']
    df['score'] = df['score'].apply(lambda x: np.log(x))
    df['decoy'] = df['sequence'].str[-1].str.islower()

    df = filter_score(df)
    df = filter_seq(df)

    cval, cutoff = cut_fdr(df, fdr_level, plot, verbose)

    return cutoff


def get_protein_groups(data, pept_dict, fasta_dict, callback = None, **kwargs):
    """
    Function to perform protein grouping by razor approach
    ToDo: implement callback for solving
    """

    G=nx.Graph()

    found_proteins = {}

    for i in range(len(data)):
        line = data.iloc[i]
        seq = line['sequence']
        score = line['score']
        if seq in pept_dict:
            proteins = pept_dict[seq]
            if len(proteins) > 1:
                for protein in proteins:
                    G.add_edge(i, str(protein), score=score)
            else: #if there is only one PSM just add to this protein
                if proteins[0] in found_proteins.keys():
                    found_proteins[proteins[0]] = found_proteins[proteins[0]] + [i]
                else:
                    found_proteins[proteins[0]] = [i]

        if callback:
            callback(i/len(data))

    print('A total of {:,} proteins with unique PSMs found'.format(len(found_proteins)))

    connected_groups = np.array([list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)])
    n_groups = len(connected_groups)
    print('A total of {} ambigious proteins'.format(len(connected_groups)))

    #Solving with razor:
    found_proteins_razor = {}
    for a in connected_groups:
        H = G.subgraph(a)

        nodes = list(np.array(a)[np.array(list(isinstance(i, str) for i in a))])

        removed = []


        while len(nodes) > 0:

            neighbors_list = []

            for node in nodes:
                neighbors = list(H.neighbors(node))
                n_neigbhors = len(neighbors)

                if node in G:
                    if node in found_proteins.keys():
                        n_neigbhors+= len(found_proteins[node])

                neighbors_list.append((n_neigbhors, node, neighbors))

            neighbors_list.sort()

            #Remove the last entry:

            count, node, psms = neighbors_list[-1]

            nodes.remove(node)

            psms = [_ for _ in psms if _ not in removed]

            removed+= psms

            found_proteins_razor[node] = psms

    #Put back in Df
    report = data.copy()
    report['protein'] = ''

    for protein in found_proteins.keys():
        indexes = found_proteins[protein]
        report.loc[indexes, 'protein'] = fasta_dict[protein]['name']

    report['razor'] = False
    for protein in found_proteins_razor.keys():
        indexes = found_proteins_razor[protein]
        report.loc[indexes, 'protein'] = fasta_dict[int(protein)]['name']
        report.loc[indexes, 'razor'] = True

    return report

def perform_protein_grouping(data, pept_dict, fasta_dict, **kwargs):
    """
    Wrapper function to perform protein grouping by razor approach

    """
    data_sub = data[['sequence','score','decoy']]
    data_sub_unique = data_sub.groupby(['sequence','decoy'], as_index=False).agg({"score": "max"})

    targets = data_sub_unique[data_sub_unique.decoy == False]
    protein_targets = get_protein_groups(targets, pept_dict, fasta_dict, **kwargs)

    decoys = data_sub_unique[data_sub_unique.decoy == True]
    protein_decoys = get_protein_groups(decoys, pept_dict, fasta_dict, **kwargs)

    protein_groups = protein_targets.append(protein_decoys)
    protein_groups_app = protein_groups[['sequence','decoy','protein','Razor']]
    protein_report = pd.merge(data,
                                protein_groups_app,
                                how = 'inner',
                                on = ['sequence','decoy'],
                                validate="many_to_one")
    return protein_report

def cut_global_fdr(data, analyte_level='sequence', fdr_level=0.01, plot=True, verbose=True, **kwargs):
    """
    Function to estimate and filter by global peptide or protein fdr

    """
    data_sub = data[[analyte_level,'score','decoy']]
    data_sub_unique = data_sub.groupby([analyte_level,'decoy'], as_index=False).agg({"score": "max"})
    #print(data_sub_unique)

    if analyte_level=='sequence':
        agg_score = data_sub_unique.groupby([analyte_level,'decoy'])['score'].max().reset_index()
    elif analyte_level=='protein':
        agg_score = data_sub_unique.groupby([analyte_level,'decoy'])['score'].sum().reset_index()
    else:
        raise Exception('analyte_level should be either sequence or protein. The selected analyte_level was: {}'.format(analyte_level))

    agg_cval, agg_cutoff = cut_fdr(agg_score, fdr_level=fdr_level, plot=plot, verbose=verbose)
    #print(agg_cval)
    agg_report = pd.merge(data,
                          agg_cutoff,
                          how = 'inner',
                          on = [analyte_level,'decoy'],
                          suffixes=('', '_'+analyte_level),
                          validate="many_to_one")
    return agg_report

# Cell
def save_report_as_npz(
    df,
    fasta_dict,
    pept_dict,
    report_path_npz
):

    to_save = {}
    to_save["df"] = df
    to_save["fasta_dict"] = fasta_dict
    to_save["pept_dict"] = np.array(pept_dict)

    np.savez(report_path_npz, **to_save)

    print("Raw File saved to {}".format(report_path_npz))