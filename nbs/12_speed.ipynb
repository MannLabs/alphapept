{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-fields",
   "metadata": {},
   "source": [
    "# Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import multiprocessing\n",
    "import threading\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import psutil\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as numpy_\n",
    "cupy = numpy_\n",
    "from numba import cuda as cuda_\n",
    "cuda = cuda_\n",
    "import numba as numba_\n",
    "numba = numba_\n",
    "\n",
    "# We use jit_fun and jit_fun_gpu.\n",
    "# This is to be able too distinguish GPU device functions and numba optimized functions in a GPU setting\n",
    "\n",
    "jit_fun = None\n",
    "jit_fun_gpu = None\n",
    "speed_mode = None\n",
    "\n",
    "\n",
    "try:\n",
    "    import cupy as cupy_\n",
    "except ModuleNotFoundError:\n",
    "    cupy_ = None\n",
    "\n",
    "def dummy_decorator(func):\n",
    "    \"\"\"\n",
    "    Dummy decorator that does nothing\n",
    "    \"\"\"\n",
    "    return func\n",
    "\n",
    "def set_speed_mode(mode):\n",
    "    \"\"\"\n",
    "    Function to change \n",
    "    \n",
    "    \"\"\"\n",
    "    global jit_fun\n",
    "    global jit_fun_gpu\n",
    "    global speed_mode\n",
    "    global cupy\n",
    "    \n",
    "    speed_mode = mode\n",
    "    \n",
    "    if mode == 'python':\n",
    "        jit_fun = dummy_decorator\n",
    "        jit_fun_gpu = dummy_decorator\n",
    "        cupy = numpy_\n",
    "    elif mode == 'numba':\n",
    "        jit_fun = njit\n",
    "        jit_fun_gpu = njit\n",
    "        cupy = numpy_\n",
    "    elif mode == 'numba_gpu':\n",
    "        jit_fun = njit\n",
    "        jit_fun_gpu = cuda.jit(device=True)\n",
    "        if cupy_ is not None:\n",
    "            cupy = cupy_\n",
    "        else:\n",
    "            raise ModuleNotFoundError('Cupy not installed.')\n",
    "    else:\n",
    "        raise NotImplementedError(mode)\n",
    "        \n",
    "        \n",
    "if cupy_ is not None:\n",
    "    set_speed_mode('numba_gpu')\n",
    "else:\n",
    "    set_speed_mode('numba')\n",
    "    \n",
    "@numba.njit\n",
    "def grid_1d(x): return -1\n",
    "@numba.njit\n",
    "def grid_2d(x): return -1, -1\n",
    "\n",
    "def set_cuda_grid(dimensions=0):\n",
    "    global cuda\n",
    "    if dimensions == 0:\n",
    "        cuda = cuda_\n",
    "        cuda.grid = cuda_.grid\n",
    "    if dimensions == 1:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_1d\n",
    "    if dimensions == 2:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_2d\n",
    "        \n",
    "        \n",
    "def numba_threaded(_func=None, *, cpu_threads=0):\n",
    "    if cpu_threads <= 0:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "        \n",
    "    def parallel_compiled_func_inner(func):\n",
    "        if speed_mode == 'python':\n",
    "            numba_func = func\n",
    "        else:\n",
    "            numba_func = numba.njit(nogil=True)(func)\n",
    "\n",
    "        def numba_func_parallel(thread, iterable, *args):\n",
    "            for i in range(thread, len(iterable), cpu_threads):\n",
    "                numba_func(i, iterable, *args)\n",
    "\n",
    "        if speed_mode == 'python':\n",
    "            numba_func_parallel = numba_func_parallel\n",
    "        else:\n",
    "            numba_func_parallel = numba.njit(nogil=True)(numba_func_parallel)\n",
    "\n",
    "        def wrapper(iterable, *args):\n",
    "            threads = []\n",
    "            for thread_id in range(cpu_threads):\n",
    "                t = threading.Thread(\n",
    "                    target=numba_func_parallel,\n",
    "                    args=(thread_id, iterable, *args)\n",
    "                )\n",
    "                t.start()\n",
    "                threads.append(t)\n",
    "            for t in threads:\n",
    "                t.join()\n",
    "                del t\n",
    "        return functools.wraps(func)(wrapper)\n",
    "    \n",
    "    if _func is None:\n",
    "        return parallel_compiled_func_inner\n",
    "    else:\n",
    "        return parallel_compiled_func_inner(_func)\n",
    "    \n",
    "     \n",
    "def parallel_compiled_func(\n",
    "    _func=None,\n",
    "    *,\n",
    "    cpu_threads=None,\n",
    "    dimensions=1,\n",
    "):\n",
    "    #set_cuda_grid()\n",
    "    if dimensions not in (1, 2):\n",
    "        raise ValueError(\"Only 1D and 2D are supported\")\n",
    "\n",
    "    if cpu_threads is not None:\n",
    "        use_gpu = False\n",
    "    else:\n",
    "        try:\n",
    "            cuda_.get_current_device()\n",
    "        except cuda_.CudaSupportError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "        else:\n",
    "            use_gpu = True\n",
    "        try:\n",
    "            import cupy\n",
    "        except ModuleNotFoundError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "            \n",
    "    if cpu_threads is None:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "        \n",
    "    if cpu_threads <= 0:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "\n",
    "    if speed_mode == 'numba_gpu':\n",
    "        use_gpu = True\n",
    "    elif speed_mode == 'numba':\n",
    "        use_gpu = False\n",
    "    elif speed_mode == 'python':\n",
    "        use_gpu = False\n",
    "                \n",
    "    if use_gpu:\n",
    "        set_cuda_grid()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            cuda_func = cuda.jit(func)\n",
    "            if dimensions == 1:\n",
    "                def wrapper(iterable_1d, *args):\n",
    "                    cuda_func.forall(iterable_1d.shape[0], 1)(\n",
    "                        -1,\n",
    "                        iterable_1d,\n",
    "                        *args\n",
    "                    )\n",
    "            elif dimensions == 2:\n",
    "                def wrapper(iterable_2d, *args):\n",
    "                    threadsperblock = (\n",
    "                        min(iterable_2d.shape[0], 16),\n",
    "                        min(iterable_2d.shape[0], 16)\n",
    "                    )\n",
    "                    blockspergrid_x = math.ceil(\n",
    "                        iterable_2d.shape[0] / threadsperblock[0]\n",
    "                    )\n",
    "                    blockspergrid_y = math.ceil(\n",
    "                        iterable_2d.shape[1] / threadsperblock[1]\n",
    "                    )\n",
    "                    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "                    cuda_func[blockspergrid, threadsperblock](\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        iterable_2d,\n",
    "                        *args\n",
    "                    )\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    else:\n",
    "        set_cuda_grid(dimensions)\n",
    "        if cpu_threads <= 0:\n",
    "            cpu_threads = multiprocessing.cpu_count()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            \n",
    "            if speed_mode == 'python':\n",
    "                numba_func = func\n",
    "            else:\n",
    "                numba_func = numba.njit(nogil=True)(func)\n",
    "\n",
    "            if dimensions == 1:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_1d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        len(iterable_1d),\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        numba_func(i, iterable_1d, *args)\n",
    "            elif dimensions == 2:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_2d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        iterable_2d.shape[0],\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        for j in range(iterable_2d.shape[1]):\n",
    "                            numba_func(i, j, iterable_2d, *args)\n",
    "                            \n",
    "            if speed_mode == 'python':\n",
    "                numba_func_parallel = numba_func_parallel\n",
    "            else:\n",
    "                numba_func_parallel = numba.njit(nogil=True)(numba_func_parallel)\n",
    "\n",
    "            def wrapper(iterable, *args):\n",
    "                threads = []\n",
    "                for thread_id in range(cpu_threads):\n",
    "                    t = threading.Thread(\n",
    "                        target=numba_func_parallel,\n",
    "                        args=(thread_id, iterable, *args)\n",
    "                    )\n",
    "                    t.start()\n",
    "                    threads.append(t)\n",
    "                for t in threads:\n",
    "                    t.join()\n",
    "                    del t\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    if _func is None:\n",
    "        return parallel_compiled_func_inner\n",
    "    else:\n",
    "        return parallel_compiled_func_inner(_func)\n",
    "    \n",
    "def set_max_process(a):\n",
    "    max_processes = psutil.cpu_count()\n",
    "    new_max = min(a, max_processes)\n",
    "    \n",
    "    return new_max\n",
    "\n",
    "def AlphaPool(a, *args, **kwargs):  \n",
    "    max_processes = psutil.cpu_count()\n",
    "    if a == -1:\n",
    "        a = max_processes\n",
    "    new_max = min(a, 50, max_processes)\n",
    "    print(f\"AlphaPool was set to {a} processes. Setting max to {new_max}.\")\n",
    "\n",
    "    return Pool(new_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 04_feature_finding2.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_interface.ipynb.\n",
      "Converted 12_speed.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted minimal_example.ipynb.\n",
      "Converted minimal_example_2.ipynb.\n",
      "Converted minimal_example_3.ipynb.\n",
      "Converted test.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted Untitled2.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-alphapept] *",
   "language": "python",
   "name": "conda-env-.conda-alphapept-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
