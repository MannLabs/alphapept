{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-fields",
   "metadata": {},
   "source": [
    "# Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "# A decorator for writing GPU/CPU agnostic code\n",
    "import multiprocessing\n",
    "import threading\n",
    "import functools\n",
    "import math\n",
    "import numba as numba_\n",
    "numba = numba_\n",
    "import numpy as np\n",
    "from numba import cuda as cuda_\n",
    "cuda = cuda_\n",
    "from numba import njit\n",
    "\n",
    "try:\n",
    "    import cupy\n",
    "    jit_fun = cuda.jit(device=True) #Device Function\n",
    "except ModuleNotFoundError:\n",
    "    import numpy as cupy\n",
    "    jit_fun = njit\n",
    "    \n",
    "@numba.njit\n",
    "def grid_1d(x): return -1\n",
    "@numba.njit\n",
    "def grid_2d(x): return -1, -1\n",
    "\n",
    "\n",
    "def set_cuda_grid(dimensions=0):\n",
    "    global cuda\n",
    "    if dimensions == 0:\n",
    "        cuda = cuda_\n",
    "        cuda.grid = cuda_.grid\n",
    "    if dimensions == 1:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_1d\n",
    "    if dimensions == 2:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_2d\n",
    "      \n",
    "def parallel_compiled_func(\n",
    "    _func=None,\n",
    "    *,\n",
    "    cpu_threads=None,\n",
    "    dimensions=1,\n",
    "    cpu_only = False,\n",
    "):\n",
    "    set_cuda_grid()\n",
    "    if dimensions not in (1, 2):\n",
    "        raise ValueError(\"Only 1D and 2D are supported\")\n",
    "\n",
    "    if cpu_threads is not None:\n",
    "        use_gpu = False\n",
    "    else:\n",
    "        try:\n",
    "            cuda.get_current_device()\n",
    "        except cuda.CudaSupportError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "        else:\n",
    "            use_gpu = True\n",
    "        try:\n",
    "            import cupy\n",
    "        except ModuleNotFoundError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "    \n",
    "    if cpu_only:\n",
    "        use_gpu = False\n",
    "        if cpu_threads is None: \n",
    "            cpu_threads = 0\n",
    "    \n",
    "    if use_gpu:\n",
    "        set_cuda_grid()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            cuda_func = cuda.jit(func)\n",
    "            if dimensions == 1:\n",
    "                def wrapper(iterable_1d, *args):\n",
    "                    cuda_func.forall(iterable_1d.shape[0], 1)(\n",
    "                        -1,\n",
    "                        iterable_1d,\n",
    "                        *args\n",
    "                    )\n",
    "            elif dimensions == 2:\n",
    "                def wrapper(iterable_2d, *args):\n",
    "                    threadsperblock = (\n",
    "                        min(iterable_2d.shape[0], 16),\n",
    "                        min(iterable_2d.shape[0], 16)\n",
    "                    )\n",
    "                    blockspergrid_x = math.ceil(\n",
    "                        iterable_2d.shape[0] / threadsperblock[0]\n",
    "                    )\n",
    "                    blockspergrid_y = math.ceil(\n",
    "                        iterable_2d.shape[1] / threadsperblock[1]\n",
    "                    )\n",
    "                    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "                    cuda_func[blockspergrid, threadsperblock](\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        iterable_2d,\n",
    "                        *args\n",
    "                    )\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    else:\n",
    "        set_cuda_grid(dimensions)\n",
    "        if cpu_threads <= 0:\n",
    "            cpu_threads = multiprocessing.cpu_count()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            numba_func = numba.njit(nogil=True)(func)\n",
    "            if dimensions == 1:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_1d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        len(iterable_1d),\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        numba_func(i, iterable_1d, *args)\n",
    "            elif dimensions == 2:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_2d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        iterable_2d.shape[0],\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        for j in range(iterable_2d.shape[1]):\n",
    "                            numba_func(i, j, iterable_2d, *args)\n",
    "            numba_func_parallel = numba.njit(nogil=True)(numba_func_parallel)\n",
    "            def wrapper(iterable, *args):\n",
    "                threads = []\n",
    "                for thread_id in range(cpu_threads):\n",
    "                    t = threading.Thread(\n",
    "                        target=numba_func_parallel,\n",
    "                        args=(thread_id, iterable, *args)\n",
    "                    )\n",
    "                    t.start()\n",
    "                    threads.append(t)\n",
    "                for t in threads:\n",
    "                    t.join()\n",
    "                    del t\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    if _func is None:\n",
    "        return parallel_compiled_func_inner\n",
    "    else:\n",
    "        return parallel_compiled_func_inner(_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_interface.ipynb.\n",
      "Converted 12_speed.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphapept]",
   "language": "python",
   "name": "conda-env-alphapept-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
