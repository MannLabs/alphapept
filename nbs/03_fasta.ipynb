{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA\n",
    "\n",
    "> Functions related to generating spectra from FASTA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to creating spectra from FASTA files. In brief, what we are doing is the following:\n",
    "\n",
    "1. Read a FASTA file and digest the sequences\n",
    "2. For each peptide, calculate a synthetic spectrum and precursor mass\n",
    "3. Save spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "from numba import NumbaPendingDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaving\n",
    "\n",
    "For cleaving, we use regular expressions to find potential cleavages sites and write the wrapper `cleave_sequence` to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept import constants\n",
    "import re\n",
    "\n",
    "def get_missed_cleavages(sequences, n_missed_cleavages):\n",
    "    \"\"\"\n",
    "    Combine cleaved sequences to get sequences with missed cleavages\n",
    "    \"\"\"\n",
    "    missed = []\n",
    "    for k in range(len(sequences)-n_missed_cleavages):\n",
    "        missed.append(''.join(sequences[k-1:k+n_missed_cleavages]))\n",
    "        \n",
    "    return missed\n",
    "\n",
    "\n",
    "def cleave_sequence(\n",
    "    sequence=\"\",\n",
    "    num_missed_cleavages=0,\n",
    "    protease=\"trypsin\",\n",
    "    min_length=6,\n",
    "    max_length=65,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    proteases = constants.protease_dict\n",
    "    pattern = proteases[protease]\n",
    "    \n",
    "    p = re.compile(pattern)\n",
    "\n",
    "    cutpos = [m.start()+1 for m in p.finditer(sequence)]\n",
    "    cutpos.insert(0,0)\n",
    "    cutpos.append(len(sequence))\n",
    "    \n",
    "    base_sequences = [sequence[cutpos[i]:cutpos[i+1]] for i in range(len(cutpos)-1)]\n",
    "\n",
    "    sequences = base_sequences.copy()\n",
    "\n",
    "    for i in range(1, num_missed_cleavages+1):\n",
    "        sequences.extend(get_missed_cleavages(base_sequences, i))\n",
    "    \n",
    "    sequences = [_ for _ in sequences if len(_)>=min_length and len(_)<=max_length]\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCDEFGHIJK', 'LMNOPQR']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "num_missed_cleavages = 0\n",
    "min_length, max_length = 6, 65\n",
    "\n",
    "cleave_sequence('ABCDEFGHIJKLMNOPQRST', num_missed_cleavages, protease, min_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_cleave_sequence():\n",
    "    \n",
    "    protease = \"trypsin\"\n",
    "    min_length, max_length = 6, 65\n",
    "\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 0, protease, min_length, max_length)) == set(['ABCDEFGHIJK', 'LMNOPQR'])\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 1, protease, min_length, max_length)) == set(['ABCDEFGHIJK', 'LMNOPQR', 'ABCDEFGHIJKLMNOPQR'])\n",
    "\n",
    "    test_cleave_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missed and internal cleavages\n",
    "The following are helper functions to retrieve the number of missed cleavages and internal cleavage sites for each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "from alphapept import constants\n",
    "\n",
    "def count_missed_cleavages(sequence=\"\", protease=\"trypsin\",**kwargs):\n",
    "    \"\"\"\n",
    "    Counts the number of missed cleavages for a given sequence and protease\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    p = re.compile(protease)\n",
    "    n_missed = len(p.findall(sequence))\n",
    "    return n_missed\n",
    "\n",
    "def count_internal_cleavages(sequence=\"\", protease=\"trypsin\",**kwargs):\n",
    "    \"\"\"\n",
    "    Counts the number of internal cleavage sites for a given sequence and protease\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    match = re.search(protease,sequence[-1]+'_')\n",
    "    if match:\n",
    "        n_internal = 0\n",
    "    else:\n",
    "        n_internal = 1\n",
    "    return n_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "print(count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', protease))\n",
    "\n",
    "protease = \"trypsin\"\n",
    "print(count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', protease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_missed_cleavages():  \n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 2\n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'clostripain') == 1\n",
    "    \n",
    "test_get_missed_cleavages()\n",
    "\n",
    "def test_get_internal_cleavages():\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 1\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRSTK', 'trypsin') == 0\n",
    "\n",
    "test_get_internal_cleavages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Peptides are composed out of amino acids that are written in capital letters - `PEPTIDE`. to distinguish modifications, they are written in lowercase such as `PEPTIoxDE` and can be of arbitrary length. For a modified amino acid, the modification preceds the letter of the amino acid. Decoys are indicated with a underscore, hence the `parse` function splits after `_`. When parsing, the peptide string is converted into a numba-compatible list so that each element can be determined with the `mass_dict` from `alphapept.constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "@njit\n",
    "def parse(peptide):\n",
    "    \"\"\"\n",
    "    Parser to parse peptide strings\n",
    "    \"\"\"\n",
    "    if \"_\" in peptide:\n",
    "        peptide = peptide.split(\"_\")[0]\n",
    "    parsed = List()\n",
    "    string = \"\"\n",
    "\n",
    "    for i in peptide:\n",
    "        string += i\n",
    "        if i.isupper():\n",
    "            parsed.append(string)\n",
    "            string = \"\"\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def list_to_numba(a_list):\n",
    "    numba_list = List()\n",
    "\n",
    "    for element in a_list:\n",
    "        numba_list.append(element)\n",
    "\n",
    "    return numba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P, E, P, T, I, D, E]\n",
      "[P, E, P, oxT, I, D, E]\n"
     ]
    }
   ],
   "source": [
    "print(parse('PEPTIDE'))\n",
    "print(parse('PEPoxTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_parse():\n",
    "    peptide = \"PEPTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPoxTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"oxT\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPTIDE_decoy\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    \n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoy\n",
    "\n",
    "The decoy strategy that is employed is a pseudo-reversal of the peptide sequence, keeping only the terminal amino-acid and reversing the rest. Additionally, we can call the functions `swap_KR` and and `swap_AL` that will swap the respective AAs. The function `swap_KR` will only swap terminal AAs. The swapping functions only work if the AA is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_decoy_sequence(peptide, pseudoReverse=True, AL_swap=False, KR_swap = False):\n",
    "    \"\"\"\n",
    "    Reverses a sequence and adds the '_decoy' tag.\n",
    "\n",
    "    \"\"\"\n",
    "    pep = parse(peptide)\n",
    "    if pseudoReverse:\n",
    "        str_pep = \"\".join(pep)\n",
    "        str_rev_pep = str_pep[:-1][::-1]+str_pep[-1:]\n",
    "        \n",
    "        rev_pep = List()\n",
    "        string = \"\"\n",
    "\n",
    "        for i in str_rev_pep:\n",
    "            string += i\n",
    "            rev_pep.append(string)\n",
    "            string = \"\"\n",
    "\n",
    "    else:\n",
    "        rev_pep = pep[::-1]\n",
    "\n",
    "    if AL_swap:\n",
    "        rev_pep = swap_AL(rev_pep)\n",
    "\n",
    "    if KR_swap:\n",
    "        rev_pep = swap_KR(rev_pep)\n",
    "\n",
    "    rev_pep = \"\".join(rev_pep)\n",
    "\n",
    "    return rev_pep\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_KR(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a terminal K or R. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    if peptide[-1] == 'K':\n",
    "        peptide[-1] = 'R'\n",
    "    elif peptide[-1] == 'R':\n",
    "        peptide[-1] = 'K'\n",
    "\n",
    "    return peptide\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_AL(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a A with L. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(range(len(peptide) - 1)):\n",
    "        if peptide[i] == \"A\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"A\"\n",
    "            i += 1\n",
    "        elif peptide[i] == \"L\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"L\"\n",
    "            i += 1\n",
    "        i += 1\n",
    "\n",
    "    return peptide\n",
    "\n",
    "def get_decoys(peptide_list):\n",
    "    \"\"\"\n",
    "    Wrapper to get decoys for lists of peptides\n",
    "    \"\"\"\n",
    "    decoys = []\n",
    "    decoys.extend([get_decoy_sequence(peptide) for peptide in peptide_list])\n",
    "    return decoys\n",
    "\n",
    "def add_decoy_tag(peptides):\n",
    "    \"\"\"\n",
    "    Adds a _decoy tag to a list of peptides\n",
    "    \"\"\"\n",
    "    return [peptide + \"_decoy\" for peptide in peptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[K, K, K, L, A, K, K, K]\n",
      "[A, A, A, K, R, A, A, A]\n"
     ]
    }
   ],
   "source": [
    "print(swap_AL(parse('KKKALKKK')))\n",
    "print(swap_KR(parse('AAAKRAAA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DITPEPE\n"
     ]
    }
   ],
   "source": [
    "print(get_decoy_sequence('PEPTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAC', 'EDF', 'HGI']\n"
     ]
    }
   ],
   "source": [
    "print(get_decoys(['ABC','DEF','GHI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_swap_AL():\n",
    "    assert swap_AL(parse(\"ABCDEF\")) == parse(\"BACDEF\")\n",
    "    assert swap_AL(parse(\"GHIKLM\")) == parse(\"GHIKML\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "    assert swap_AL(parse(\"GHIKL\")) == parse(\"GHIKL\")\n",
    "    assert swap_AL(parse(\"ABCDEFGHIKLM\")) == parse(\"BACDEFGHIKML\")\n",
    "    assert swap_AL(parse(\"BBAcCD\")) == parse(\"BBcCAD\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "\n",
    "test_swap_AL()\n",
    "\n",
    "def test_swapKR():\n",
    "    assert swap_KR(parse(\"ABCDEK\")) == parse(\"ABCDER\")\n",
    "    assert swap_KR(parse(\"ABCDER\")) == parse(\"ABCDEK\")\n",
    "    assert swap_KR(parse(\"ABCDEF\")) == parse(\"ABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCDEF\")) == parse(\"KABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCRDEF\")) == parse(\"KABCRDEF\")\n",
    "    assert swap_KR(parse(\"KABCKDEF\")) == parse(\"KABCKDEF\")\n",
    "\n",
    "test_swapKR()\n",
    "    \n",
    "def test_get_decoy_sequence():\n",
    "    peptide = \"PEPTIDER\"\n",
    "    assert get_decoy_sequence(peptide, pseudoReverse=False) == \"REDITPEP\"\n",
    "    assert get_decoy_sequence(peptide) == \"EDITPEPR\"\n",
    "    assert get_decoy_sequence(peptide, KR_swap=True) == \"EDITPEPK\"\n",
    "    \n",
    "test_get_decoy_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "\n",
    "To add modifications to the peptides we distinguish fixed and variable modifications. Additionally, we make a distinciton between whether the modification is only terminal or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Modifications\n",
    "Fixed modifications are implemented by passing a list with modified AAs that should be replaced. As we only have one letter AAs the remainder is the modification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mods(seqs, mods_fixed, **kwargs):\n",
    "    \"\"\"\n",
    "    Adds fixed modifications to sequences.\n",
    "    \"\"\"\n",
    "    if not mods_fixed:\n",
    "        return seqs\n",
    "    else:\n",
    "        for mod_aa in mods_fixed:\n",
    "            seqs = [seq.replace(mod_aa[-1], mod_aa) for seq in seqs]\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbBcCDEF']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_fixed = ['cC','bB']\n",
    "peptide_list = ['ABCDEF']\n",
    "\n",
    "add_fixed_mods(peptide_list, mods_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_fixed_mods():\n",
    "    mods_fixed = ['cC']\n",
    "    peptide_list = ['ABCDEF']\n",
    "\n",
    "    peptides_new = add_fixed_mods(peptide_list, [])\n",
    "    assert peptides_new == peptide_list\n",
    "    \n",
    "    peptides_new = add_fixed_mods(peptide_list, mods_fixed)\n",
    "    assert peptides_new == ['ABcCDEF']\n",
    "    \n",
    "test_add_fixed_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Modifications\n",
    "\n",
    "To employ variable modifications, we use the function `get_mod_pos` that returns a list of tuples with all possible modifications when giving a dicitionary with variable modifications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_mod_pos(variable_mods_r, sequence):\n",
    "    \"\"\"\n",
    "    Returns a list with of tuples with all possibilities for modified an unmodified AAs.\n",
    "    \"\"\"\n",
    "    modvar = []\n",
    "    for c in sequence:\n",
    "        if c in variable_mods_r.keys():\n",
    "            modvar.append((c, variable_mods_r[c]))\n",
    "        else:\n",
    "            modvar.append((c,))\n",
    "\n",
    "    return modvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "get_mod_pos(mods_variable_dict, peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_get_mod_pos():\n",
    "    \n",
    "    mods_variable_dict = {'M':'oxM'}\n",
    "    peptide = 'AMAMA'\n",
    "    assert set(get_mod_pos(mods_variable_dict, peptide)) == set([('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)])\n",
    "    \n",
    "test_get_mod_pos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To now generate all isoforms, we employ the function `get_isoforms` that generates all isoforms for a given peptide. As the number of isoforms can become large, we restrict it with the parameter `max_isoforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from itertools import product\n",
    "def get_isoforms(variable_mods_r, sequence, max_isoforms):\n",
    "    \"\"\"\n",
    "    Function to generate isoforms for a given peptide - returns a list of isoforms.\n",
    "    The original sequence is included in the list\n",
    "    \"\"\"\n",
    "    modvar = get_mod_pos(variable_mods_r, sequence)\n",
    "    isoforms = []\n",
    "    i = 0\n",
    "    for o in product(*modvar):\n",
    "        if i < max_isoforms:\n",
    "            i += 1\n",
    "            isoforms.append(\"\".join(o))\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "max_isoforms = 1024\n",
    "get_isoforms(mods_variable_dict, peptide, max_isoforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the wrapper `add_variable_mods` so that the functions can be called for lists of peptides and a list of variable modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from itertools import chain\n",
    "\n",
    "def add_variable_mods(peptide_list, mods_variable, max_isoforms, **kwargs):\n",
    "    if not mods_variable:\n",
    "        return peptide_list\n",
    "    else:\n",
    "        mods_variable_r = {}\n",
    "        for _ in mods_variable:\n",
    "            mods_variable_r[_[-1]] = _\n",
    "\n",
    "        peptide_list = [get_isoforms(mods_variable_r, peptide, max_isoforms) for peptide in peptide_list]\n",
    "        return list(chain.from_iterable(peptide_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMA', 'AoxMA', 'AAC', 'AAamC']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMA', 'AAC']\n",
    "mods_variable = ['oxM','amC']\n",
    "max_isoforms = 1024\n",
    "\n",
    "add_variable_mods(peptide_list, mods_variable, max_isoforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods():\n",
    "    mods_variable = ['oxM']\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, [], 1024)\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 1024)\n",
    "\n",
    "    assert set(['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']) == set(peptides_new)\n",
    "\n",
    "    # Check if number of isoforms is correct\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 2)\n",
    "\n",
    "    assert len(peptides_new) == 2\n",
    "    \n",
    "test_add_variable_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Fixed\n",
    "\n",
    "To handle terminal modifications, we use the following convention:\n",
    "\n",
    "* `<` for the left side (N-terminal)\n",
    "* `>` for the right side (C-Terminal)\n",
    "\n",
    "Additionally, if we want to have a terminal modification on any AA we indicate this `^`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mod_terminal(peptides, mod):\n",
    "    \"\"\"\n",
    "    Adds fixed terminal modifications\n",
    "    \"\"\"\n",
    "    # < for left side (N-Term), > for right side (C-Term)\n",
    "    if \"<^\" in mod: #Any n-term, e.g. a<^\n",
    "        peptides = [mod[:-2] + peptide for peptide in peptides]\n",
    "    elif \">^\" in mod: #Any c-term, e.g. a>^\n",
    "        peptides = [peptide[:-1] + mod[:-2] + peptide[-1] for peptide in peptides]\n",
    "    elif \"<\" in mod: #only if specific AA, e.g. ox<C\n",
    "        peptides = [peptide[0].replace(mod[-1], mod[:-2]+mod[-1]) + peptide[1:] for peptide in peptides]\n",
    "    elif \">\" in mod:\n",
    "        peptides = [peptide[:-1] + peptide[-1].replace(mod[-1], mod[:-2]+mod[-1]) for peptide in peptides]\n",
    "    else:\n",
    "        # This should not happen\n",
    "        raise (\"Invalid fixed terminal modification {}.\".format(key))\n",
    "    return peptides\n",
    "\n",
    "def add_fixed_mods_terminal(peptides, mods_fixed_terminal, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to add fixed mods on sequences and lists of mods\n",
    "    \"\"\"\n",
    "    if mods_fixed_terminal == []:\n",
    "        return peptides\n",
    "    else:\n",
    "        # < for left side (N-Term), > for right side (C-Term)\n",
    "        for key in mods_fixed_terminal:\n",
    "            peptides = add_fixed_mod_terminal(peptides, key)\n",
    "        return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any n-term modified with x (x<^): ['xAMAMA']\n",
      "Any c-term modified with x (x>^): ['AMAMxA']\n",
      "Only A on n-term modified with x (x<A): ['xAMAMA']\n",
      "Only A on c-term modified with x (x<A): ['AMAMxA']\n"
     ]
    }
   ],
   "source": [
    "peptide = ['AMAMA']\n",
    "\n",
    "print('Any n-term modified with x (x<^):', add_fixed_mods_terminal(peptide, ['x<^']))\n",
    "print('Any c-term modified with x (x>^):', add_fixed_mods_terminal(peptide, ['x>^']))\n",
    "print('Only A on n-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x<A']))\n",
    "print('Only A on c-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x>A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_fixed_mods_terminal():\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<^'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    #Any C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>^'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    #Selected N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<A'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<C'])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Selected C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>A'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>C'])\n",
    "    assert peptides_new == peptide\n",
    "    \n",
    "test_add_fixed_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Variable\n",
    "\n",
    "Lastly, to handle terminal variable modifications we use the function `add_variable_mods_terminal`. As the modifcation can only be at the terminal end this function only adds a peptide where the terminal end is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_variable_mods_terminal(peptides, mods_variable_terminal, **kwargs):\n",
    "    \"Function to add variable terminal modifications\"\n",
    "    if not mods_variable_terminal:\n",
    "        return peptides\n",
    "    else:\n",
    "        new_peptides_n = peptides.copy()\n",
    "\n",
    "        for key in mods_variable_terminal:\n",
    "            if \"<\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_n.extend(\n",
    "                    add_fixed_mod_terminal(peptides, key)\n",
    "                )\n",
    "        new_peptides_n = get_unique_peptides(new_peptides_n)\n",
    "        # N complete, let's go for c-terminal\n",
    "        new_peptides_c = new_peptides_n\n",
    "        for key in mods_variable_terminal:\n",
    "            if \">\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_c.extend(\n",
    "                    add_fixed_mod_terminal(new_peptides_n, key)\n",
    "                )\n",
    "\n",
    "        return get_unique_peptides(new_peptides_c)\n",
    "\n",
    "def get_unique_peptides(peptides):\n",
    "    return list(set(peptides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAMA', 'xAMAMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMAMA']\n",
    "add_variable_mods_terminal(peptide_list, ['x<^'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods_terminal():\n",
    "    peptide_list = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, ['x<^'])\n",
    "    assert set(peptides_new) == set(['xAMAMA', 'AMAMA'])\n",
    "    \n",
    "test_add_variable_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Peptides\n",
    "\n",
    "Lastly we put all the functions into a wrapper `generate_peptides`. It will accept a peptide and a dictionary with settings so that we can get all modified peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_peptides(peptide, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to get modified peptides from a peptide\n",
    "    \"\"\"\n",
    "    mod_peptide = add_fixed_mods_terminal([peptide], kwargs['mods_fixed_terminal_prot'])\n",
    "\n",
    "    mod_peptide = add_variable_mods_terminal(mod_peptide, kwargs['mods_variable_terminal_prot'])\n",
    "\n",
    "    peptides = []\n",
    "    [peptides.extend(cleave_sequence(_, **kwargs)) for _ in mod_peptide]\n",
    "\n",
    "    #Regular peptides\n",
    "    mod_peptides = add_fixed_mods(peptides, **kwargs)\n",
    "    mod_peptides = add_fixed_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods(mod_peptides, **kwargs)\n",
    "\n",
    "    #Decoys:\n",
    "    decoy_peptides = get_decoys(peptides)\n",
    "\n",
    "    mod_peptides_decoy = add_fixed_mods(decoy_peptides, **kwargs)\n",
    "    mod_peptides_decoy = add_fixed_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods(mod_peptides_decoy, **kwargs)\n",
    "\n",
    "    mod_peptides_decoy = add_decoy_tag(mod_peptides_decoy)\n",
    "\n",
    "    mod_peptides.extend(mod_peptides_decoy)\n",
    "\n",
    "    return mod_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEPTIDEM', 'PEPTIDEoxM', 'EDITPEPM_decoy', 'EDITPEPoxM_decoy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs[\"protease\"] = \"trypsin\"\n",
    "kwargs[\"num_missed_cleavages\"] = 2\n",
    "kwargs[\"min_length\"] = 6\n",
    "kwargs[\"max_length\"] = 27\n",
    "kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "kwargs[\"mods_variable_terminal\"] = []\n",
    "kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "kwargs[\"mods_fixed_terminal\"] = []\n",
    "kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "generate_peptides('PEPTIDEM', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEPTIDEM']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleave_sequence('PEPTIDEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_generate_peptides():\n",
    "    kwargs = {}\n",
    "\n",
    "    kwargs[\"protease\"] = \"trypsin\"\n",
    "    kwargs[\"num_missed_cleavages\"] = 2\n",
    "    kwargs[\"min_length\"] = 6\n",
    "    kwargs[\"max_length\"] = 27\n",
    "    kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "    kwargs[\"mods_variable_terminal\"] = []\n",
    "    kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "    kwargs[\"mods_fixed_terminal\"] = []\n",
    "    kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "    kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "    kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "    peps = generate_peptides('PEPTIDEM', **kwargs)\n",
    "    \n",
    "    assert set(peps) == set(['PEPTIDEM', 'PEPTIDEoxM', 'EDITPEPM_decoy', 'EDITPEPoxM_decoy'])\n",
    "    \n",
    "test_generate_peptides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass Calculations\n",
    "\n",
    "Using the `mass_dict` from `constants` and being able to parse sequences with `parse` we can simply look up the masses for each modified or unmodified amino acid and add everything up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor\n",
    "\n",
    "To calculate the mass of the neutral precursor we start with the mass of an $H_2O$ and add the masses of all amino acids of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def get_precmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the mass of the neutral precursor\n",
    "    \"\"\"\n",
    "    tmass = mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep:\n",
    "        tmass += mass_dict[_]\n",
    "\n",
    "    return tmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799.3599642034599"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_precmass():\n",
    "    \n",
    "    precmass = get_precmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "test_get_precmass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragments\n",
    "\n",
    "Likewise, we can calculate the masses of the fragment ions. We employ two functions: `get_fragmass` and `get_frag_dict`. \n",
    "\n",
    "`get_fragmass` is a fast, `numba`-compatible function that calculates the fragmasses and returns an array indicating wheter the iontype was `b` or `y`. \n",
    "\n",
    "`get_frag_dict` instead is not `numba`-compatible and hence a bit slower. It returns a dictionary with the respective ion and can be used for plotting theoretical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@njit\n",
    "def get_fragmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_masses = np.zeros(n_frags, dtype=np.float64)\n",
    "    frag_type = np.zeros(n_frags, dtype=np.int8)\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 0\n",
    "        n_frag += 1\n",
    "\n",
    "    # y-ions -> 1\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 1\n",
    "        n_frag += 1\n",
    "\n",
    "    return frag_masses, frag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
       "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
       "        376.17144135, 477.21911985, 574.27188371, 703.31447681]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], dtype=int8))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fragmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_fragmass():\n",
    "    \n",
    "    frag_masses, frag_type = get_fragmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    ref_masses = np.array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
    "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
    "        376.17144135, 477.21911985, 574.27188371, 703.31447681])\n",
    "    \n",
    "    assert np.allclose(frag_masses, ref_masses)\n",
    "                          \n",
    "test_get_fragmass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_frag_dict(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_dict = {}\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "\n",
    "        frag_dict['b' + str(n_frag)] = frag_m\n",
    "\n",
    "    # y-ions -> 1\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "        frag_dict['y' + str(n_frag)] = frag_m\n",
    "\n",
    "    return frag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': 98.06004032687,\n",
       " 'b2': 227.10263342686997,\n",
       " 'b3': 324.15539728686997,\n",
       " 'y1': 120.06551965033,\n",
       " 'y2': 217.11828351033,\n",
       " 'y3': 346.16087661033}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frag_dict(parse('PEPT'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_frag_dict():\n",
    "    \n",
    "    refdict = {'b1': 98.06004032687,\n",
    " 'b2': 227.10263342686997,\n",
    " 'b3': 324.15539728686997,\n",
    " 'y1': 120.06551965033,\n",
    " 'y2': 217.11828351033,\n",
    " 'y3': 346.16087661033}\n",
    "    \n",
    "    newdict = get_frag_dict(parse('PEPT'), constants.mass_dict)\n",
    "    \n",
    "    for key in newdict.keys():\n",
    "        \n",
    "        assert np.allclose(refdict[key], newdict[key])\n",
    "        \n",
    "test_get_frag_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us also to generate the theorteical isotopes for a fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "peptide = 'PEPTIDE'\n",
    "\n",
    "frag_dict = get_frag_dict(parse(peptide), constants.mass_dict)\n",
    "\n",
    "db_frag = list(frag_dict.values())\n",
    "db_int = [100 for _ in db_frag]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.vlines(db_frag, 0, db_int, \"k\", label=\"DB\", alpha=0.2)\n",
    "\n",
    "for _ in frag_dict.keys():\n",
    "    plt.text(frag_dict[_], 104, _, fontsize=12, alpha = 0.8)\n",
    "    \n",
    "plt.title('Theoretical Spectrum for {}'.format(peptide))\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.ylim([0,110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra\n",
    "\n",
    "The function `get_spectrum` returns a tuple with the following content:\n",
    "\n",
    "* precursor mass\n",
    "* peptide sequence\n",
    "* fragmasses\n",
    "* fragtypes\n",
    "\n",
    "Likewise, `get_spectra` returns a list of tuples. We employ a list of tuples here as this way we can sort them easily by precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_spectrum(peptide, mass_dict):\n",
    "    parsed_peptide = parse(peptide)\n",
    "\n",
    "    fragmasses, fragtypes = get_fragmass(parsed_peptide, mass_dict)\n",
    "    sortindex = np.argsort(fragmasses)\n",
    "    fragmasses = fragmasses[sortindex]\n",
    "    fragtypes = fragtypes[sortindex]\n",
    "\n",
    "    precmass = get_precmass(parsed_peptide, mass_dict)\n",
    "\n",
    "    return (precmass, peptide, fragmasses, fragtypes)\n",
    "\n",
    "@njit\n",
    "def get_spectra(peptides, mass_dict):\n",
    "    spectra = []\n",
    "\n",
    "    for i in range(len(peptides)):\n",
    "        spectra.append(get_spectrum(peptides[i], mass_dict))\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(799.3599642034599, 'PEPTIDE', array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
      "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
      "       538.28713979, 574.27188371, 653.31408289, 703.31447681]), array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], dtype=int8))]\n"
     ]
    }
   ],
   "source": [
    "print(get_spectra(['PEPTIDE'], constants.mass_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_spectra():\n",
    "    \n",
    "    spectra = get_spectra(['PEPTIDE'], constants.mass_dict)\n",
    "    \n",
    "    precmass, peptide, frags, fragtypes = spectra[0]\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "    assert peptide == 'PEPTIDE'\n",
    "    \n",
    "    assert np.allclose(frags, np.array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
    "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
    "       538.28713979, 574.27188371, 653.31408289, 703.31447681]))\n",
    "\n",
    "test_get_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading FASTA\n",
    "\n",
    "To read FASTA files we use the `SeqIO` module from the `Biopython` library.\n",
    "Generator expression so that we can read it one by one\n",
    "\n",
    "Additionally we define the wrapper `read_fasta` that allows to read multiple FASTA files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def read_fasta_file(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    given a fasta_file read fasta file line by line, return progress\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                parts = record.id.split(\"|\")  # pipe char\n",
    "                if len(parts) > 1:\n",
    "                    id = parts[1]\n",
    "                else:\n",
    "                    id = record.name\n",
    "                sequence = str(record.seq)\n",
    "                entry = {\n",
    "                    \"id\": id,\n",
    "                    \"name\": record.name,\n",
    "                    \"description\": record.description,\n",
    "                    \"sequence\": sequence,\n",
    "                }\n",
    "\n",
    "                yield entry\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "\n",
    "def read_fasta_file_entries(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    Function to count entries in fasta file\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        count = 0\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                count+=1\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "\n",
    "def read_fasta(path):\n",
    "    \"\"\"\n",
    "    Wrapper to read multiple files.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(path):\n",
    "        paths = glob(path + \"/*.fasta\")\n",
    "    else:\n",
    "        paths = glob(path)\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        raise KeyError(\"Not a valid Fasta Path: {}.\".format(path))\n",
    "\n",
    "    for fasta_file in paths:\n",
    "        for entry in read_fasta_file(fasta_file):\n",
    "            yield entry\n",
    "\n",
    "def check_sequence(element, AAs):\n",
    "    \"\"\"\n",
    "    Checks wheter a sequence from a FASTA entry contains valid AAs\n",
    "    \"\"\"\n",
    "    if not set(element['sequence']).issubset(AAs):\n",
    "        print('Error. This FASTA Entry contains unknown AAs and will be skipped: \\n {}\\n'.format(element))\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'A0PJZ0',\n",
       " 'name': 'sp|A0PJZ0|A20A5_HUMAN',\n",
       " 'description': 'sp|A0PJZ0|A20A5_HUMAN Putative ankyrin repeat domain-containing protein 20A5 OS=Homo sapiens OX=9606 GN=ANKRD20A5P PE=5 SV=1',\n",
       " 'sequence': 'MKLFGFRSRRGQTVLGSIDHLYTGSGYRIRYSELQKIHKAAVKGDAAEMERCLARRSGDLDALDKQHRTALHLACASGHVKVVTLLVNRKCQIDIYDKENRTPLIQAVHCQEEACAVILLEHGANPNLKDIYGNTALHYAVYSESTSLAEKLLFHGENIEALDKV'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load example fasta file\n",
    "\n",
    "fasta_path = '../testfiles/test.fasta'\n",
    "\n",
    "list(read_fasta(fasta_path))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Dictionary\n",
    "\n",
    "In order to efficiently store peptides we rely on the python in dictionary. The idea is to have a dictionary with peptides as keys and indicies to proteins as values. This way we can quickly look up to which protein a peptide belongs to. The function `add_to_pept_dict` uses a regular python dictionary and allows to add peptides and stores indicies to the originating proteins as a list. If a peptide is already present in the dictionary the list is appended. The function returns a list of `added_peptides` which were not present in the dictionary yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_to_pept_dict(pept_dict, new_peptides, i):\n",
    "    \"\"\"\n",
    "    Add peptides to the peptide dictionary\n",
    "    \"\"\"\n",
    "    added_peptides = List()\n",
    "    for peptide in new_peptides:\n",
    "        if peptide in pept_dict:\n",
    "            pept_dict[peptide].append(i)\n",
    "        else:\n",
    "            pept_dict[peptide] = [i]\n",
    "            added_peptides.append(peptide)\n",
    "\n",
    "    return pept_dict, added_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n"
     ]
    }
   ],
   "source": [
    "pept_dict = {}\n",
    "new_peptides = ['ABC','DEF']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 0)\n",
    "\n",
    "new_peptides = ['DEF','GHI']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 1)\n",
    "\n",
    "print(pept_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a library\n",
    "\n",
    "To wrap everything up, we employ two functions `generate_library` and `generate_spectra`. The first one reads a FASTA file and generates a list of peptides, as well as the peptide dictionary and an ordered FASTA dictionary to be able to look up the protein indices laster. For the `callback` we first read the whole FASTA file to determine the total number of entries in the FASTA file.  For a typical FASTA file of 30 Mb with 40k entries, this should take less than a second. The progress of the digestion is monitored by processing the FASTA file one by one.\n",
    "The function `generate_spectra` then calculates precursor masses and fragment ions. Here, we split the total_number of sequences in `1000` steps to be able to track progress with the `callback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generate_library(mass_dict, fasta_path, callback = None, contaminants_path = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "    to_add = List()\n",
    "    fasta_dict = OrderedDict()\n",
    "    fasta_index = 0\n",
    "\n",
    "    pept_dict = {}\n",
    "    \n",
    "    if type(fasta_path) is str:\n",
    "        fasta_path = [fasta_path]\n",
    "        n_fastas = 1\n",
    "        \n",
    "    elif type(fasta_path) is list:\n",
    "        n_fastas = len(fasta_path)\n",
    "    \n",
    "    for f_id, fasta_file in enumerate(fasta_path):\n",
    "        n_entries = read_fasta_file_entries(fasta_file)\n",
    "\n",
    "        fasta_generator = read_fasta(fasta_file)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            if check_sequence(element, constants.AAs):\n",
    "                fasta_dict[fasta_index] = element\n",
    "                mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "                pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "                if len(added_seqs) > 0:\n",
    "                    to_add.extend(added_seqs)\n",
    "\n",
    "            fasta_index += 1\n",
    "\n",
    "            if callback:\n",
    "                callback(fasta_index/n_entries/n_fastas+f_id)\n",
    "            \n",
    "    if contaminants_path:\n",
    "        fasta_generator = read_fasta(contaminants_path)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            if check_sequence(element, constants.AAs):\n",
    "                fasta_dict[fasta_index] = element\n",
    "                mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "                pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "                if len(added_seqs) > 0:\n",
    "                    to_add.extend(added_seqs)\n",
    "\n",
    "            fasta_index += 1\n",
    "        \n",
    "    return to_add, pept_dict, fasta_dict\n",
    "\n",
    "\n",
    "def generate_spectra(to_add, mass_dict, callback = None):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "\n",
    "    if len(to_add) > 0:\n",
    "\n",
    "        if callback: #Chunk the spectra to get a progress_bar\n",
    "            spectra = []\n",
    "\n",
    "            stepsize = int(np.ceil(len(to_add)/1000))\n",
    "\n",
    "            for i in range(0, len(to_add), stepsize):\n",
    "                sub = to_add[i:i + stepsize]\n",
    "                spectra.extend(get_spectra(sub, mass_dict))\n",
    "                callback((i+1)/len(to_add))\n",
    "\n",
    "        else:\n",
    "            spectra = get_spectra(to_add, mass_dict)\n",
    "    else:\n",
    "        raise ValueError(\"No spectra to generate.\")\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "To save the generated spectra, we rely on NumPy's NPZ format. For this we create a dictionary and save all the generated elements. The container will contain the following elements:\n",
    "\n",
    "* `precursors`: An array containing the precursor masses\n",
    "* `seqs`: An array containing the peptide sequences for the precursor masses\n",
    "* `pept_dict`: A peptide dictionary to look up the peptides and return their FASTA index\n",
    "* `fasta_dict`: A fasta dictionary to look up the FASTA entry based on a pept_dict index\n",
    "* `fragmasses`: An array containing the fragment masses. Unoccupied cells are filled with -1\n",
    "* `fragtypes:`: An array containg the fragment types. 0 equals b-ions and 1 equals y-ions. Unoccupied cells are filled with -1\n",
    "* `bounds`: An integer array containing the upper bounds for the fragment masses / types array. This is needed to quickly slice the data.\n",
    "\n",
    "All arrays are sorted according to the precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept.io import list_to_numpy_f32\n",
    "\n",
    "\n",
    "def save_library(spectra, pept_dict, fasta_dict, library_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to save a library to the *.npz format.\n",
    "    \"\"\"\n",
    "\n",
    "    precmasses, seqs, fragmasses, fragtypes = zip(*spectra)\n",
    "    sortindex = np.argsort(precmasses)\n",
    "\n",
    "    to_save = {}\n",
    "\n",
    "    to_save[\"precursors\"] = np.array(precmasses)[sortindex]\n",
    "    to_save[\"seqs\"] = np.array(seqs)[sortindex]\n",
    "    to_save[\"pept_dict\"] = pept_dict\n",
    "    to_save[\"fasta_dict\"] = fasta_dict\n",
    "    to_save[\"fragmasses\"] = list_to_numpy_f32(np.array(fragmasses)[sortindex])\n",
    "    to_save[\"fragtypes\"] = list_to_numpy_f32(np.array(fragtypes)[sortindex])\n",
    "\n",
    "    to_save[\"bounds\"] = np.sum(to_save['fragmasses']>=0,axis=0).astype(np.int64)\n",
    "\n",
    "    np.savez(library_path, **to_save)\n",
    "\n",
    "    return library_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_settings.ipynb.\n",
      "Converted 12_runner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
