{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA\n",
    "\n",
    "> Functions related to generating spectra from FASTA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to creating spectra from FASTA files. In brief, what we are doing is the following:\n",
    "\n",
    "1. Read a FASTA file and in silico digest the proteins to generate peptides\n",
    "2. For each peptide, calculate a theoretical spectrum and precursor mass\n",
    "3. Save spectra\n",
    "\n",
    "Currently, `numba` has only limited string support. A lot of the functions are therefore Python-native."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaving\n",
    "\n",
    "We use regular expressions to find potential cleavage sites for cleaving and write the wrapper `cleave_sequence` to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept import constants\n",
    "import re\n",
    "\n",
    "def get_missed_cleavages(sequences:list, n_missed_cleavages:int) -> list:\n",
    "    \"\"\"\n",
    "    Combine cleaved sequences to get sequences with missed cleavages\n",
    "    Args:\n",
    "        seqeuences (list of str): the list of cleaved sequences, no missed cleavages are there.\n",
    "        n_missed_cleavages (int): the number of miss cleavage sites.\n",
    "    Returns:\n",
    "        list (of str): the sequences with missed cleavages.\n",
    "    \"\"\"\n",
    "    missed = []\n",
    "    for k in range(len(sequences)-n_missed_cleavages):\n",
    "        missed.append(''.join(sequences[k-1:k+n_missed_cleavages]))\n",
    "\n",
    "    return missed\n",
    "\n",
    "\n",
    "def cleave_sequence(\n",
    "    sequence:str=\"\",\n",
    "    n_missed_cleavages:int=0,\n",
    "    protease:str=\"trypsin\",\n",
    "    pep_length_min:int=6,\n",
    "    pep_length_max:int=65,\n",
    "    **kwargs\n",
    ")->list:\n",
    "    \"\"\"\n",
    "    Cleave a sequence with a given protease. Filters to have a minimum and maximum length.\n",
    "    Args:\n",
    "        sequence (str): the given (protein) sequence.\n",
    "        n_missed_cleavages (int): the number of max missed cleavages.\n",
    "        protease (str): the protease/enzyme name, the regular expression can be found in alphapept.constants.protease_dict.\n",
    "        pep_length_min (int): min peptide length.\n",
    "        pep_length_max (int): max peptide length.\n",
    "    Returns:\n",
    "        list (of str): cleaved peptide sequences with missed cleavages.\n",
    "    \"\"\"\n",
    "\n",
    "    proteases = constants.protease_dict\n",
    "    pattern = proteases[protease]\n",
    "\n",
    "    p = re.compile(pattern)\n",
    "\n",
    "    cutpos = [m.start()+1 for m in p.finditer(sequence)]\n",
    "    cutpos.insert(0,0)\n",
    "    cutpos.append(len(sequence))\n",
    "\n",
    "    base_sequences = [sequence[cutpos[i]:cutpos[i+1]] for i in range(len(cutpos)-1)]\n",
    "\n",
    "    sequences = base_sequences.copy()\n",
    "\n",
    "    for i in range(1, n_missed_cleavages+1):\n",
    "        sequences.extend(get_missed_cleavages(base_sequences, i))\n",
    "\n",
    "    sequences = [_ for _ in sequences if len(_)>=pep_length_min and len(_)<=pep_length_max]\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCDEFGHIJK', 'LMNOPQR']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "n_missed_cleavages = 0\n",
    "pep_length_min, pep_length_max = 6, 65\n",
    "\n",
    "cleave_sequence('ABCDEFGHIJKLMNOPQRST', n_missed_cleavages, protease, pep_length_min, pep_length_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_cleave_sequence():\n",
    "    \n",
    "    protease = \"trypsin\"\n",
    "    pep_length_min, pep_length_max = 6, 65\n",
    "\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 0, protease, pep_length_min, pep_length_max)) == set(['ABCDEFGHIJK', 'LMNOPQR'])\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 1, protease, pep_length_min, pep_length_max)) == set(['ABCDEFGHIJK', 'LMNOPQR', 'ABCDEFGHIJKLMNOPQR'])\n",
    "\n",
    "test_cleave_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting missed and internal cleavages\n",
    "The following are helper functions to retrieve the number of missed cleavages and internal cleavage sites for each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "from alphapept import constants\n",
    "\n",
    "def count_missed_cleavages(sequence:str=\"\", protease:str=\"trypsin\", **kwargs) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of missed cleavages for a given sequence and protease\n",
    "    Args:\n",
    "        sequence (str): the given (peptide) sequence.\n",
    "        protease (str): the protease/enzyme name, the regular expression can be found in alphapept.constants.protease_dict.\n",
    "    Returns:\n",
    "        int: the number of miss cleavages\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    p = re.compile(protease)\n",
    "    n_missed = len(p.findall(sequence))\n",
    "    return n_missed\n",
    "\n",
    "def count_internal_cleavages(sequence:str=\"\", protease:str=\"trypsin\", **kwargs) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of internal cleavage sites for a given sequence and protease\n",
    "    Args:\n",
    "        sequence (str): the given (peptide) sequence.\n",
    "        protease (str): the protease/enzyme name, the regular expression can be found in alphapept.constants.protease_dict.\n",
    "    Returns:\n",
    "        int (0 or 1): if the sequence is from internal cleavage.\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    match = re.search(protease,sequence[-1]+'_')\n",
    "    if match:\n",
    "        n_internal = 0\n",
    "    else:\n",
    "        n_internal = 1\n",
    "    return n_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "print(count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', protease))\n",
    "\n",
    "protease = \"trypsin\"\n",
    "print(count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', protease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_missed_cleavages():  \n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 2\n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'clostripain') == 1\n",
    "    \n",
    "test_get_missed_cleavages()\n",
    "\n",
    "def test_get_internal_cleavages():\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 1\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRSTK', 'trypsin') == 0\n",
    "\n",
    "test_get_internal_cleavages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Peptides are composed out of amino acids that are written in capital letters - `PEPTIDE`. To distinguish modifications, they are written in lowercase such as `PEPTIoxDE` and can be of arbitrary length. For a modified amino acid (AA), the modification precedes the letter of the amino acid. Decoys are indicated with an underscore. Therefore, the `parse` function splits after `_`. When parsing, the peptide string is converted into a `numba`-compatible list, like so: `PEPoxTIDE` -> `[P, E, P, oxT, I, D, E]`. This allows that we can use the `mass_dict` from `alphapept.constants` to directly determine the masses for the corresponding amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "@njit\n",
    "def parse(peptide:str)->List:\n",
    "    \"\"\"\n",
    "    Parser to parse peptide strings\n",
    "    Args: \n",
    "        peptide (str): modified peptide sequence.\n",
    "    Return:\n",
    "        List (numba.typed.List): a list of animo acids and modified amono acids\n",
    "    \"\"\"\n",
    "    if \"_\" in peptide:\n",
    "        peptide = peptide.split(\"_\")[0]\n",
    "    parsed = List()\n",
    "    string = \"\"\n",
    "\n",
    "    for i in peptide:\n",
    "        string += i\n",
    "        if i.isupper():\n",
    "            parsed.append(string)\n",
    "            string = \"\"\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def list_to_numba(a_list) -> List:\n",
    "    \"\"\"\n",
    "    Convert Python list to numba.typed.List\n",
    "    Args: \n",
    "        a_list (list): Python list.\n",
    "    Return:\n",
    "        List (numba.typed.List): Numba typed list.\n",
    "    \"\"\"\n",
    "    numba_list = List()\n",
    "\n",
    "    for element in a_list:\n",
    "        numba_list.append(element)\n",
    "\n",
    "    return numba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P, E, P, T, I, D, E, ...]\n",
      "[P, E, P, oxT, I, D, E, ...]\n"
     ]
    }
   ],
   "source": [
    "print(parse('PEPTIDE'))\n",
    "print(parse('PEPoxTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_parse():\n",
    "    peptide = \"PEPTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPoxTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"oxT\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPTIDE_decoy\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    \n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoy\n",
    "\n",
    "The decoy strategy employed is a pseudo-reversal of the peptide sequence, keeping only the terminal amino acid and reversing the rest. Additionally, we can call the functions `swap_KR` and and `swap_AL` that will swap the respective AAs. The function `swap_KR` will only swap terminal AAs. The swapping functions only work if the AA is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_decoy_sequence(peptide:str, pseudo_reverse:bool=False, AL_swap:bool=False, KR_swap:bool = False)->str:\n",
    "    \"\"\"\n",
    "    Reverses a sequence and adds the '_decoy' tag.\n",
    "    Args:\n",
    "        peptide (str): modified peptide to be reversed.\n",
    "        pseudo_reverse (bool): If True, reverse the peptide bug keep the C-terminal amino acid; otherwise reverse the whole peptide. (Default: False)\n",
    "        AL_swap (bool): replace A with L, and vice versa. (Default: False)\n",
    "        KR_swap (bool): replace K with R at the C-terminal, and vice versa. (Default: False)\n",
    "    Returns:\n",
    "        str: reversed peptide ending with the '_decoy' tag.\n",
    "    \"\"\"\n",
    "    pep = parse(peptide)\n",
    "    if pseudo_reverse:\n",
    "        rev_pep = pep[:-1][::-1]\n",
    "        rev_pep.append(pep[-1])\n",
    "    else:\n",
    "        rev_pep = pep[::-1]\n",
    "\n",
    "    if AL_swap:\n",
    "        rev_pep = swap_AL(rev_pep)\n",
    "\n",
    "    if KR_swap:\n",
    "        rev_pep = swap_KR(rev_pep)\n",
    "\n",
    "    rev_pep = \"\".join(rev_pep)\n",
    "\n",
    "    return rev_pep\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_KR(peptide:str)->str:\n",
    "    \"\"\"\n",
    "    Swaps a terminal K or R. Note: Only if AA is not modified.\n",
    "    \n",
    "    Args:\n",
    "        peptide (str): peptide.\n",
    "\n",
    "    Returns:\n",
    "        str: peptide with swapped KRs.\n",
    "    \"\"\"\n",
    "    if peptide[-1] == 'K':\n",
    "        peptide[-1] = 'R'\n",
    "    elif peptide[-1] == 'R':\n",
    "        peptide[-1] = 'K'\n",
    "\n",
    "    return peptide\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_AL(peptide:str)->str:\n",
    "    \"\"\"\n",
    "    Swaps a A with L. Note: Only if AA is not modified.\n",
    "    Args:\n",
    "        peptide (str): peptide.\n",
    "\n",
    "    Returns:\n",
    "        str: peptide with swapped ALs.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(range(len(peptide) - 1)):\n",
    "        if peptide[i] == \"A\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"A\"\n",
    "            i += 1\n",
    "        elif peptide[i] == \"L\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"L\"\n",
    "            i += 1\n",
    "        i += 1\n",
    "\n",
    "    return peptide\n",
    "\n",
    "def get_decoys(peptide_list, pseudo_reverse=False, AL_swap=False, KR_swap = False, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Wrapper to get decoys for lists of peptides\n",
    "    Args:\n",
    "        peptide_list (list): the list of peptides to be reversed.\n",
    "        pseudo_reverse (bool): If True, reverse the peptide bug keep the C-terminal amino acid; otherwise reverse the whole peptide. (Default: False)\n",
    "        AL_swap (bool): replace A with L, and vice versa. (Default: False)\n",
    "        KR_swap (bool): replace K with R at the C-terminal, and vice versa. (Default: False)\n",
    "    Returns:\n",
    "        list (of str): a list of decoy peptides\n",
    "    \"\"\"\n",
    "    decoys = []\n",
    "    decoys.extend([get_decoy_sequence(peptide, pseudo_reverse, AL_swap, KR_swap) for peptide in peptide_list])\n",
    "    return decoys\n",
    "\n",
    "def add_decoy_tag(peptides):\n",
    "    \"\"\"\n",
    "    Adds a '_decoy' tag to a list of peptides\n",
    "    \"\"\"\n",
    "    return [peptide + \"_decoy\" for peptide in peptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[K, K, K, L, A, K, K, K, ...]\n",
      "[A, A, A, K, R, A, A, A, ...]\n"
     ]
    }
   ],
   "source": [
    "print(swap_AL(parse('KKKALKKK')))\n",
    "print(swap_KR(parse('AAAKRAAA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDITPEP\n"
     ]
    }
   ],
   "source": [
    "print(get_decoy_sequence('PEPTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_decoys(['ABC','DEF','GHI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_swap_AL():\n",
    "    assert swap_AL(parse(\"ABCDEF\")) == parse(\"BACDEF\")\n",
    "    assert swap_AL(parse(\"GHIKLM\")) == parse(\"GHIKML\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "    assert swap_AL(parse(\"GHIKL\")) == parse(\"GHIKL\")\n",
    "    assert swap_AL(parse(\"ABCDEFGHIKLM\")) == parse(\"BACDEFGHIKML\")\n",
    "    assert swap_AL(parse(\"BBAcCD\")) == parse(\"BBcCAD\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "\n",
    "test_swap_AL()\n",
    "\n",
    "def test_swapKR():\n",
    "    assert swap_KR(parse(\"ABCDEK\")) == parse(\"ABCDER\")\n",
    "    assert swap_KR(parse(\"ABCDER\")) == parse(\"ABCDEK\")\n",
    "    assert swap_KR(parse(\"ABCDEF\")) == parse(\"ABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCDEF\")) == parse(\"KABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCRDEF\")) == parse(\"KABCRDEF\")\n",
    "    assert swap_KR(parse(\"KABCKDEF\")) == parse(\"KABCKDEF\")\n",
    "\n",
    "test_swapKR()\n",
    "    \n",
    "def test_get_decoy_sequence():\n",
    "    peptide = \"PEPTIDER\"\n",
    "    assert get_decoy_sequence(peptide, pseudo_reverse=True) == \"EDITPEPR\"\n",
    "    assert get_decoy_sequence(peptide) == \"REDITPEP\"\n",
    "    assert get_decoy_sequence(peptide, KR_swap=True, pseudo_reverse=True) == \"EDITPEPK\"\n",
    "    \n",
    "test_get_decoy_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "\n",
    "To add modifications to the peptides, we distinguish fixed and variable modifications. Additionally, we make a distinction between whether the modification is only terminal or not. \n",
    "\n",
    "### Fixed Modifications\n",
    "Fixed modifications are implemented by passing a list with modified AAs that should be replaced. As a AA is only one letter, the remainder is the modification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mods(seqs:list, mods_fixed:list, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Adds fixed modifications to sequences.\n",
    "    Args:\n",
    "        seqs (list of str): sequences to add fixed modifications\n",
    "        mods_fixed (list of str): the string list of fixed modifications. Each modification string must be in lower case, except for that the last letter must be the modified amino acid (e.g. oxidation on M should be oxM).\n",
    "    Returns:\n",
    "        list (of str): the list of the modified sequences. 'ABCDEF' with fixed mod 'cC' will be 'ABcCDEF'.\n",
    "    \"\"\"\n",
    "    if not mods_fixed:\n",
    "        return seqs\n",
    "    else:\n",
    "        for mod_aa in mods_fixed:\n",
    "            seqs = [seq.replace(mod_aa[-1], mod_aa) for seq in seqs]\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_fixed = ['cC','bB']\n",
    "peptide_list = ['ABCDEF']\n",
    "\n",
    "add_fixed_mods(peptide_list, mods_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_fixed = ['aA','cC','bB']\n",
    "peptide_list = ['cABCDEF']\n",
    "\n",
    "add_fixed_mods(peptide_list, mods_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_fixed_mods():\n",
    "    mods_fixed = ['cC']\n",
    "    peptide_list = ['ABCDEF']\n",
    "\n",
    "    peptides_new = add_fixed_mods(peptide_list, [])\n",
    "    assert peptides_new == peptide_list\n",
    "    \n",
    "    peptides_new = add_fixed_mods(peptide_list, mods_fixed)\n",
    "    assert peptides_new == ['ABcCDEF']\n",
    "    \n",
    "test_add_fixed_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Modifications\n",
    "\n",
    "To employ variable modifications, we loop through each variable modification and each position of the peptide and add them to the peptide list. For each iteration in get_isoforms, one more variable modification will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_variable_mod(peps:list, mods_variable_dict:dict)->list:\n",
    "    \"\"\"\n",
    "    Function to add variable modification to a list of peptides.\n",
    "    Args:\n",
    "        peps (list): List of peptides.\n",
    "        mods_variable_dict (dict): Dicitionary with modifications. The key is AA, and value is the modified form (e.g. oxM). \n",
    "    Returns:\n",
    "        list : the list of peptide forms for the given peptide.\n",
    "    \"\"\"\n",
    "    peptides = []\n",
    "    for pep_ in peps:\n",
    "        pep, min_idx = pep_\n",
    "        for mod in mods_variable_dict:\n",
    "            for i in range(len(pep)):\n",
    "                if i >= min_idx:\n",
    "                    c = pep[i]\n",
    "                    if c == mod:\n",
    "                        peptides.append((pep[:i]+[mods_variable_dict[c]]+pep[i+1:], i))   \n",
    "    return peptides\n",
    "\n",
    "\n",
    "def get_isoforms(mods_variable_dict:dict, peptide:str, isoforms_max:int, n_modifications_max:int=None)->list:\n",
    "    \"\"\"\n",
    "    Function to generate modified forms (with variable modifications) for a given peptide - returns a list of modified forms.\n",
    "    The original sequence is included in the list\n",
    "    Args:\n",
    "        mods_variable_dict (dict): Dicitionary with modifications. The key is AA, and value is the modified form (e.g. oxM).\n",
    "        peptide (str): the peptide sequence to generate modified forms.\n",
    "        isoforms_max (int): max number of modified forms to generate per peptide.\n",
    "        n_modifications_max (int, optional): max number of variable modifications per peptide.\n",
    "    Returns:\n",
    "        list (of str): the list of peptide forms for the given peptide\n",
    "    \"\"\"\n",
    "    pep = list(parse(peptide))\n",
    "\n",
    "    peptides = [pep]\n",
    "    new_peps = [(pep, 0)]\n",
    "    \n",
    "    iteration = 0\n",
    "    while len(peptides) < isoforms_max:\n",
    "        \n",
    "        \n",
    "        if n_modifications_max:\n",
    "            if iteration >= n_modifications_max:\n",
    "                break\n",
    "\n",
    "        new_peps = add_variable_mod(new_peps, mods_variable_dict)\n",
    "\n",
    "        if len(new_peps) == 0:\n",
    "            break\n",
    "        if len(new_peps) > 1:\n",
    "            if new_peps[0][0] == new_peps[1][0]:\n",
    "                new_peps = new_peps[0:1]\n",
    "                \n",
    "        for _ in new_peps:\n",
    "            if len(peptides) < isoforms_max:\n",
    "                peptides.append(_[0])\n",
    "                \n",
    "        iteration +=1 \n",
    "                \n",
    "        \n",
    "\n",
    "    peptides = [''.join(_) for _ in peptides]\n",
    "\n",
    "    return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_variable_dict = {'S':'pS','P':'pP','M':'oxM'}\n",
    "isoforms_max = 1024\n",
    "\n",
    "print(get_isoforms(mods_variable_dict, 'PEPTIDE', isoforms_max))\n",
    "print(get_isoforms(mods_variable_dict, 'AMAMA', isoforms_max))\n",
    "print(get_isoforms(mods_variable_dict, 'AMAMA', isoforms_max, n_modifications_max=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the wrapper `add_variable_mods` so that the functions can be called for lists of peptides and a list of variable modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_isoforms():\n",
    "\n",
    "    mods_variable_dict = {'S':'pS','P':'pP'}\n",
    "    peptide = 'PEPTIDE'\n",
    "    isoforms_max = 1024\n",
    "    get_isoforms(mods_variable_dict, peptide, isoforms_max)\n",
    "\n",
    "    assert len(get_isoforms(mods_variable_dict, peptide, isoforms_max)) == 4\n",
    "    \n",
    "test_get_isoforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from itertools import chain\n",
    "\n",
    "def add_variable_mods(peptide_list:list, mods_variable:list, isoforms_max:int, n_modifications_max:int, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Add variable modifications to the peptide list\n",
    "    Args:\n",
    "        peptide_list (list of str): peptide list.\n",
    "        mods_variable (list of str): modification list.\n",
    "        isoforms_max (int): max number of modified forms per peptide sequence.\n",
    "        n_modifications_max (int): max number of variable modifications per peptide.\n",
    "    Returns:\n",
    "        list (of str): list of modified sequences for the given peptide list.\n",
    "    \"\"\"\n",
    "\n",
    "    #the peptide_list originates from one peptide already -> limit isoforms here\n",
    "    \n",
    "    max_ = isoforms_max - len(peptide_list) + 1\n",
    "    \n",
    "    if max_ < 0:\n",
    "        max_ = 0\n",
    "    \n",
    "    if not mods_variable:\n",
    "        return peptide_list\n",
    "    else:\n",
    "        mods_variable_r = {}\n",
    "        for _ in mods_variable:\n",
    "            mods_variable_r[_[-1]] = _\n",
    "\n",
    "        peptide_list = [get_isoforms(mods_variable_r, peptide, max_, n_modifications_max) for peptide in peptide_list]\n",
    "        return list(chain.from_iterable(peptide_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_list = ['AMA', 'AAC']\n",
    "mods_variable = ['oxM','amC']\n",
    "isoforms_max = 1024\n",
    "n_modifications_max = 10\n",
    "\n",
    "add_variable_mods(peptide_list, mods_variable, isoforms_max, n_modifications_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods():\n",
    "    mods_variable = ['oxM']\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, [], 1024, None)\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 1024, None)\n",
    "\n",
    "    assert set(['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']) == set(peptides_new)\n",
    "\n",
    "    # Check if number of isoforms is correct\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 3, None)\n",
    "    assert len(peptides_new) == 3\n",
    "    \n",
    "    \n",
    "    peptide_list = ['PEPTIDE']\n",
    "    mods_variable = ['pP','pS']\n",
    "    isoforms_max = 1024\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide_list, mods_variable, isoforms_max, None)\n",
    "    \n",
    "    assert len(peptides_new) == 4\n",
    "    \n",
    "test_add_variable_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Fixed\n",
    "\n",
    "To handle terminal modifications, we use the following convention:\n",
    "\n",
    "* `<` for the left side (N-terminal)\n",
    "* `>` for the right side (C-Terminal)\n",
    "\n",
    "Additionally, if we want to have a terminal modification on any AA we indicate this `^`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mod_terminal(peptides:list, mod:str)->list:\n",
    "    \"\"\"\n",
    "    Adds fixed terminal modifications\n",
    "    Args:\n",
    "        peptides (list of str): peptide list.\n",
    "        mod (str): n-term mod contains '<^' (e.g. a<^ for Acetyl@N-term); c-term mod contains '>^'.\n",
    "    Raises:\n",
    "        \"Invalid fixed terminal modification 'mod name'\" for the given mod.\n",
    "    Returns:\n",
    "        list (of str): list of peptides with modification added.\n",
    "    \"\"\"\n",
    "    # < for left side (N-Term), > for right side (C-Term)\n",
    "    if \"<^\" in mod: #Any n-term, e.g. a<^\n",
    "        peptides = [mod[:-2] + peptide for peptide in peptides]\n",
    "    elif \">^\" in mod: #Any c-term, e.g. a>^\n",
    "        peptides = [peptide[:-1] + mod[:-2] + peptide[-1] for peptide in peptides]\n",
    "    elif \"<\" in mod: #only if specific AA, e.g. ox<C\n",
    "        peptides = [peptide[0].replace(mod[-1], mod[:-2]+mod[-1]) + peptide[1:] for peptide in peptides]\n",
    "    elif \">\" in mod:\n",
    "        peptides = [peptide[:-1] + peptide[-1].replace(mod[-1], mod[:-2]+mod[-1]) for peptide in peptides]\n",
    "    else:\n",
    "        # This should not happen\n",
    "        raise (\"Invalid fixed terminal modification {}.\".format(mod))\n",
    "    return peptides\n",
    "\n",
    "def add_fixed_mods_terminal(peptides:list, mods_fixed_terminal:list, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Wrapper to add fixed mods on sequences and lists of mods\n",
    "    Args:\n",
    "        peptides (list of str): peptide list.\n",
    "        mods_fixed_terminal (list of str): list of fixed terminal mods.\n",
    "    Raises:\n",
    "        \"Invalid fixed terminal modification {mod}\" exception for the given mod.\n",
    "    Returns:\n",
    "        list (of str): list of peptides with modification added.\n",
    "    \"\"\"\n",
    "    if mods_fixed_terminal == []:\n",
    "        return peptides\n",
    "    else:\n",
    "        # < for left side (N-Term), > for right side (C-Term)\n",
    "        for key in mods_fixed_terminal:\n",
    "            peptides = add_fixed_mod_terminal(peptides, key)\n",
    "        return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide = ['AMAMA']\n",
    "\n",
    "print(f'Starting with peptide {peptide}')\n",
    "print('Any n-term modified with x (x<^):', add_fixed_mods_terminal(peptide, ['x<^']))\n",
    "print('Any c-term modified with x (x>^):', add_fixed_mods_terminal(peptide, ['x>^']))\n",
    "print('Only A on n-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x<A']))\n",
    "print('Only A on c-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x>A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_fixed_mods_terminal():\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<^'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    #Any C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>^'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    #Selected N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<A'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<C'])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Selected C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>A'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>C'])\n",
    "    assert peptides_new == peptide\n",
    "    \n",
    "test_add_fixed_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Variable\n",
    "\n",
    "Lastly, to handle terminal variable modifications, we use the function `add_variable_mods_terminal`. As the modification can only be at the terminal end, this function only adds a peptide where the terminal end is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_variable_mods_terminal(peptides:list, mods_variable_terminal:list, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Function to add variable terminal modifications.\n",
    "    Args:\n",
    "        peptides (list of str): peptide list.\n",
    "        mods_variable_terminal (list of str): list of variable terminal mods.\n",
    "    Returns:\n",
    "        list (of str): list of peptides with modification added.\n",
    "    \"\"\"\n",
    "    if not mods_variable_terminal:\n",
    "        return peptides\n",
    "    else:\n",
    "        new_peptides_n = peptides.copy()\n",
    "\n",
    "        for key in mods_variable_terminal:\n",
    "            if \"<\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_n.extend(\n",
    "                    add_fixed_mod_terminal(peptides, key)\n",
    "                )\n",
    "        new_peptides_n = get_unique_peptides(new_peptides_n)\n",
    "        # N complete, let's go for c-terminal\n",
    "        new_peptides_c = new_peptides_n\n",
    "        for key in mods_variable_terminal:\n",
    "            if \">\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_c.extend(\n",
    "                    add_fixed_mod_terminal(new_peptides_n, key)\n",
    "                )\n",
    "\n",
    "        return get_unique_peptides(new_peptides_c)\n",
    "\n",
    "def get_unique_peptides(peptides:list) -> list:\n",
    "    \"\"\"\n",
    "    Function to return unique elements from list.\n",
    "    Args:\n",
    "        peptides (list of str): peptide list.\n",
    "    Returns:\n",
    "        list (of str): list of peptides (unique).\n",
    "    \"\"\" \n",
    "    return list(set(peptides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_list = ['AMAMA']\n",
    "add_variable_mods_terminal(peptide_list, ['x<^'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods_terminal():\n",
    "    peptide_list = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, ['x<^'])\n",
    "    assert set(peptides_new) == set(['xAMAMA', 'AMAMA'])\n",
    "    \n",
    "test_add_variable_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Peptides\n",
    "\n",
    "Lastly, we put all the functions into a wrapper `generate_peptides`. It will accept a peptide and a dictionary with settings so that we can get all modified peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_peptides(peptide:str, **kwargs)->list:\n",
    "    \"\"\"\n",
    "    Wrapper to get modified peptides (fixed and variable mods) from a peptide.\n",
    "\n",
    "    Args:\n",
    "        peptide (str): the given peptide sequence.\n",
    "    Returns:\n",
    "        list (of str): all modified peptides.\n",
    "    \n",
    "    TODO:\n",
    "        There can be some edge-cases which are not defined yet.\n",
    "        Example:\n",
    "        Setting the same fixed modification - once for all peptides and once for only terminal for the protein.\n",
    "        The modification will then be applied twice.\n",
    "    \"\"\"\n",
    "    mod_peptide = add_fixed_mods_terminal([peptide], kwargs['mods_fixed_terminal_prot'])\n",
    "    mod_peptide = add_variable_mods_terminal(mod_peptide, kwargs['mods_variable_terminal_prot'])\n",
    "    \n",
    "    peptides = []\n",
    "    [peptides.extend(cleave_sequence(_, **kwargs)) for _ in mod_peptide]\n",
    "\n",
    "    peptides = [_ for _ in peptides if check_peptide(_, constants.AAs)]\n",
    "    \n",
    "    isoforms_max = kwargs['isoforms_max']\n",
    "\n",
    "    all_peptides = []\n",
    "    for peptide in peptides: #1 per, limit the number of isoforms\n",
    "\n",
    "        #Regular peptides\n",
    "        mod_peptides = add_fixed_mods([peptide], **kwargs)\n",
    "        mod_peptides = add_fixed_mods_terminal(mod_peptides, **kwargs)\n",
    "        mod_peptides = add_variable_mods_terminal(mod_peptides, **kwargs)\n",
    "        \n",
    "        kwargs['isoforms_max'] = isoforms_max - len(mod_peptides)\n",
    "        mod_peptides = add_variable_mods(mod_peptides, **kwargs)\n",
    "        \n",
    "        all_peptides.extend(mod_peptides)\n",
    "\n",
    "        #Decoys:\n",
    "        decoy_peptides = get_decoys([peptide], **kwargs)\n",
    "\n",
    "        mod_peptides_decoy = add_fixed_mods(decoy_peptides, **kwargs)\n",
    "        mod_peptides_decoy = add_fixed_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "        mod_peptides_decoy = add_variable_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "        \n",
    "        kwargs['isoforms_max'] = isoforms_max - len(mod_peptides_decoy)\n",
    "        \n",
    "        mod_peptides_decoy = add_variable_mods(mod_peptides_decoy, **kwargs)\n",
    "\n",
    "        mod_peptides_decoy = add_decoy_tag(mod_peptides_decoy)\n",
    "\n",
    "        all_peptides.extend(mod_peptides_decoy)\n",
    "\n",
    "    return all_peptides\n",
    "\n",
    "def check_peptide(peptide:str, AAs:set)->bool:\n",
    "    \"\"\"\n",
    "    Check if the peptide contains non-AA letters.\n",
    "    Args:\n",
    "        peptide (str): peptide sequence.\n",
    "        AAs (set): the set of legal amino acids. See alphapept.constants.AAs\n",
    "    Returns:\n",
    "        bool: True if all letters in the peptide is the subset of AAs, otherwise False\n",
    "    \"\"\"\n",
    "    if set([_ for _ in peptide if _.isupper()]).issubset(AAs):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs[\"protease\"] = \"trypsin\"\n",
    "kwargs[\"n_missed_cleavages\"] = 2\n",
    "kwargs[\"pep_length_min\"] = 6\n",
    "kwargs[\"pep_length_max\"] = 27\n",
    "kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "kwargs[\"mods_variable_terminal\"] = []\n",
    "kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "kwargs[\"mods_fixed_terminal\"] = []\n",
    "kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "kwargs[\"mods_variable_terminal_prot\"]  = ['a<^']\n",
    "kwargs[\"isoforms_max\"] = 1024\n",
    "kwargs[\"n_modifications_max\"] = None\n",
    "\n",
    "generate_peptides('PEPTIDEM', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_generate_peptides():\n",
    "    kwargs = {}\n",
    "\n",
    "    kwargs[\"protease\"] = \"trypsin\"\n",
    "    kwargs[\"n_missed_cleavages\"] = 2\n",
    "    kwargs[\"pep_length_min\"] = 6\n",
    "    kwargs[\"pep_length_max\"] = 27\n",
    "    kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "    kwargs[\"mods_variable_terminal\"] = []\n",
    "    kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "    kwargs[\"mods_fixed_terminal\"] = []\n",
    "    kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "    kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "    kwargs[\"isoforms_max\"] = 1024\n",
    "    kwargs['pseudo_reverse'] = True\n",
    "    kwargs[\"n_modifications_max\"] = None\n",
    "\n",
    "    peps = generate_peptides('PEPTIDEM', **kwargs)\n",
    "    assert set(peps) == set(['PEPTIDEM', 'PEPTIDEoxM', 'EDITPEPM_decoy', 'EDITPEPoxM_decoy'])\n",
    "    \n",
    "test_generate_peptides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass Calculations\n",
    "\n",
    "Using the `mass_dict` from `constants` and being able to parse sequences with `parse`, one can simply look up the masses for each modified or unmodified amino acid and add everything up.\n",
    "\n",
    "### Precursor\n",
    "\n",
    "To calculate the mass of the neutral precursor, we start with the mass of an $H_2O$ and add the masses of all amino acids of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "@njit\n",
    "def get_precmass(parsed_pep:list, mass_dict:numba.typed.Dict)->float:\n",
    "    \"\"\"\n",
    "    Calculate the mass of the neutral precursor\n",
    "    Args:\n",
    "        parsed_pep (list or numba.typed.List of str): the list of amino acids and modified amono acids.\n",
    "        mass_dict (numba.typed.Dict): key is the amino acid or the modified amino acid, and the value is the mass.\n",
    "    Returns:\n",
    "        float: the peptide neutral mass.\n",
    "    \"\"\"\n",
    "    tmass = mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep:\n",
    "        tmass += mass_dict[_]\n",
    "\n",
    "    return tmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_precmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_precmass():\n",
    "    \n",
    "    precmass = get_precmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "test_get_precmass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragments\n",
    "\n",
    "Likewise, we can calculate the masses of the fragment ions. We employ two functions: `get_fragmass` and `get_frag_dict`. \n",
    "\n",
    "`get_fragmass` is a fast, `numba`-compatible function that calculates the fragment masses and returns an array indicating whether the ion-type was `b` or `y`. \n",
    "\n",
    "`get_frag_dict` instead is not `numba`-compatible and hence a bit slower. It returns a dictionary with the respective ion and can be used for plotting theoretical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numba\n",
    "\n",
    "@njit\n",
    "def get_fragmass(parsed_pep:list, mass_dict:numba.typed.Dict)->tuple:\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    Args:\n",
    "        parsed_pep (numba.typed.List of str): the list of amino acids and modified amono acids.\n",
    "        mass_dict (numba.typed.Dict): key is the amino acid or the modified amino acid, and the value is the mass.\n",
    "    Returns:\n",
    "        Tuple[np.ndarray(np.float64), np.ndarray(np.int8)]: the fragment masses and the fragment types (represented as np.int8). \n",
    "        For a fragment type, positive value means the b-ion, the value indicates the position (b1, b2, b3...); the negative value means\n",
    "        the y-ion, the absolute value indicates the position (y1, y2, ...).\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_masses = np.zeros(n_frags, dtype=np.float64)\n",
    "    frag_type = np.zeros(n_frags, dtype=np.int8)\n",
    "\n",
    "    # b-ions > 0\n",
    "    n_frag = 0\n",
    "    \n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "    for idx, _ in enumerate(parsed_pep[:-1]):\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = (idx+1)\n",
    "        n_frag += 1\n",
    "        \n",
    "    # y-ions < 0\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for idx, _ in enumerate(parsed_pep[::-1][:-1]):\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = -(idx+1)\n",
    "        n_frag += 1\n",
    "\n",
    "    return frag_masses, frag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fragmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_fragmass():\n",
    "    \n",
    "    frag_masses, frag_type = get_fragmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    ref_masses = np.array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
    "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
    "        376.17144135, 477.21911985, 574.27188371, 703.31447681])\n",
    "    \n",
    "    assert np.allclose(frag_masses, ref_masses)\n",
    "                          \n",
    "test_get_fragmass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_frag_dict(parsed_pep:list, mass_dict:dict)->dict:\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    Args:\n",
    "        parsed_pep (list or numba.typed.List of str): the list of amino acids and modified amono acids.\n",
    "        mass_dict (numba.typed.Dict): key is the amino acid or the modified amino acid, and the value is the mass.\n",
    "    Returns:\n",
    "        dict{str:float}: key is the fragment type (b1, b2, ..., y1, y2, ...), value is fragment mass.\n",
    "    \"\"\"\n",
    "    frag_dict = {}\n",
    "    frag_masses, frag_type = get_fragmass(parsed_pep, mass_dict)\n",
    "    \n",
    "    for idx, _ in enumerate(frag_masses):\n",
    "        \n",
    "        cnt = frag_type[idx]\n",
    "        if cnt > 0:\n",
    "            identifier = 'b'\n",
    "        else:\n",
    "            identifier = 'y'\n",
    "            cnt = -cnt\n",
    "        frag_dict[identifier+str(cnt)] = _\n",
    "           \n",
    "    return frag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_frag_dict(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_frag_dict():\n",
    "    \n",
    "    refdict = {'b1': 98.06004032687,\n",
    " 'b2': 227.10263342686997,\n",
    " 'b3': 324.15539728686997,\n",
    " 'y1': 120.06551965033,\n",
    " 'y2': 217.11828351033,\n",
    " 'y3': 346.16087661033}\n",
    "    \n",
    "    newdict = get_frag_dict(parse('PEPT'), constants.mass_dict)\n",
    "    \n",
    "    for key in newdict.keys():\n",
    "        \n",
    "        assert np.allclose(refdict[key], newdict[key])\n",
    "        \n",
    "test_get_frag_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us also to generate the theoretical isotopes for a fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "peptide = 'PEPTIDE'\n",
    "\n",
    "frag_dict = get_frag_dict(parse(peptide), constants.mass_dict)\n",
    "\n",
    "db_frag = list(frag_dict.values())\n",
    "db_int = [100 for _ in db_frag]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.vlines(db_frag, 0, db_int, \"k\", label=\"DB\", alpha=0.2)\n",
    "\n",
    "for _ in frag_dict.keys():\n",
    "    plt.text(frag_dict[_], 104, _, fontsize=12, alpha = 0.8)\n",
    "    \n",
    "plt.title('Theoretical Spectrum for {}'.format(peptide))\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.ylim([0,110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra\n",
    "\n",
    "The function `get_spectrum` returns a tuple with the following content:\n",
    "\n",
    "* precursor mass\n",
    "* peptide sequence\n",
    "* fragmasses\n",
    "* fragtypes\n",
    "\n",
    "Likewise, `get_spectra` returns a list of tuples. We employ a list of tuples here as this way, we can sort them easily by precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_spectrum(peptide:str, mass_dict:numba.typed.Dict)->tuple:\n",
    "    \"\"\"\n",
    "    Get neutral peptide mass, fragment masses and fragment types for a peptide\n",
    "    Args:\n",
    "        peptide (str): the (modified) peptide.\n",
    "        mass_dict (numba.typed.Dict): key is the amino acid or modified amino acid, and the value is the mass.\n",
    "    Returns:\n",
    "        Tuple[float, str, np.ndarray(np.float64), np.ndarray(np.int8)]: (peptide mass, peptide, fragment masses, fragment_types), for fragment types, see get_fragmass.\n",
    "    \"\"\"\n",
    "    parsed_peptide = parse(peptide)\n",
    "\n",
    "    fragmasses, fragtypes = get_fragmass(parsed_peptide, mass_dict)\n",
    "    sortindex = np.argsort(fragmasses)\n",
    "    fragmasses = fragmasses[sortindex]\n",
    "    fragtypes = fragtypes[sortindex]\n",
    "\n",
    "    precmass = get_precmass(parsed_peptide, mass_dict)\n",
    "\n",
    "    return (precmass, peptide, fragmasses, fragtypes)\n",
    "\n",
    "@njit\n",
    "def get_spectra(peptides:numba.typed.List, mass_dict:numba.typed.Dict)->List:\n",
    "    \"\"\"\n",
    "    Get neutral peptide mass, fragment masses and fragment types for a list of peptides\n",
    "    Args:\n",
    "        peptides (list of str): the (modified) peptide list.\n",
    "        mass_dict (numba.typed.Dict): key is the amino acid or modified amino acid, and the value is the mass.\n",
    "    Raises:\n",
    "        Unknown exception and pass.\n",
    "    Returns:\n",
    "        list of Tuple[float, str, np.ndarray(np.float64), np.ndarray(np.int8)]: See get_spectrum.\n",
    "    \"\"\"\n",
    "    spectra = List()\n",
    "\n",
    "    for i in range(len(peptides)):\n",
    "        try:\n",
    "            spectra.append(get_spectrum(peptides[i], mass_dict))\n",
    "        except Exception: #TODO: This is to fix edge cases when having multiple modifications on the same AA.  \n",
    "            pass\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_spectra(List(['PEPTIDE']), constants.mass_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_spectra():\n",
    "    \n",
    "    spectra = get_spectra(List(['PEPTIDE']), constants.mass_dict)\n",
    "    \n",
    "    precmass, peptide, frags, fragtypes = spectra[0]\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "    assert peptide == 'PEPTIDE'\n",
    "    \n",
    "    assert np.allclose(frags, np.array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
    "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
    "       538.28713979, 574.27188371, 653.31408289, 703.31447681]))\n",
    "\n",
    "test_get_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading FASTA\n",
    "\n",
    "To read FASTA files, we use the `SeqIO` module from the `Biopython` library. This is a generator expression so that we read one FASTA entry after another until the `StopIteration` is reached, which is implemented in `read_fasta_file`. Additionally, we define the function `read_fasta_file_entries` that simply counts the number of FASTA entries.\n",
    "\n",
    "All FASTA entries that contain AAs which are not in the mass_dict can be checked with `check_sequence` and will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "def read_fasta_file(fasta_filename:str=\"\"):\n",
    "    \"\"\"\n",
    "    Read a FASTA file line by line\n",
    "    Args:\n",
    "        fasta_filename (str): fasta.\n",
    "    Yields:\n",
    "        dict {id:str, name:str, description:str, sequence:str}: protein information.\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                parts = record.id.split(\"|\")  # pipe char\n",
    "                if len(parts) > 1:\n",
    "                    id = parts[1]\n",
    "                else:\n",
    "                    id = record.name\n",
    "                sequence = str(record.seq)\n",
    "                entry = {\n",
    "                    \"id\": id,\n",
    "                    \"name\": record.name,\n",
    "                    \"description\": record.description,\n",
    "                    \"sequence\": sequence,\n",
    "                }\n",
    "\n",
    "                yield entry\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "\n",
    "def read_fasta_file_entries(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    Function to count entries in fasta file\n",
    "    Args:\n",
    "        fasta_filename (str): fasta.\n",
    "    Returns:\n",
    "        int: number of entries.\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        count = 0\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                count+=1\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "def check_sequence(element:dict, AAs:set, verbose:bool = False)->bool:\n",
    "    \"\"\"\n",
    "    Checks wheter a sequence from a FASTA entry contains valid AAs\n",
    "    Args:\n",
    "        element (dict): fasta entry of the protein information.\n",
    "        AAs (set): a set of amino acid letters.\n",
    "        verbose (bool): logging the invalid amino acids.\n",
    "    Returns:\n",
    "        bool: False if the protein sequence contains non-AA letters, otherwise True.\n",
    "    \"\"\"\n",
    "    if not set(element['sequence']).issubset(AAs):\n",
    "        unknown = set(element['sequence']) - set(AAs)\n",
    "        if verbose:\n",
    "            logging.error(f'This FASTA entry contains unknown AAs {unknown} - Peptides with unknown AAs will be skipped: \\n {element}\\n')\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load example fasta file\n",
    "\n",
    "fasta_path = '../testfiles/test.fasta'\n",
    "\n",
    "list(read_fasta_file(fasta_path))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Dictionary\n",
    "\n",
    "In order to efficiently store peptides, we rely on the Python dictionary. The idea is to have a dictionary with peptides as keys and indices to proteins as values. This way, one can quickly look up to which protein a peptide belongs to. The function `add_to_pept_dict` uses a regular python dictionary and allows to add peptides and stores indices to the originating proteins as a list. If a peptide is already present in the dictionary, the list is appended. The function returns a list of `added_peptides`, which were not present in the dictionary yet. One can use the function `merge_pept_dicts` to merge multiple peptide dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_to_pept_dict(pept_dict:dict, new_peptides:list, i:int)->tuple:\n",
    "    \"\"\"\n",
    "    Add peptides to the peptide dictionary\n",
    "    Args:\n",
    "        pept_dict (dict): the key is peptide sequence, and the value is protein id list indicating where the peptide is from.\n",
    "        new_peptides (list): the list of peptides to be added to pept_dict.\n",
    "        i (int): the protein id where new_peptides are from.\n",
    "    Returns:\n",
    "        dict: same as the pept_dict in the arguments.\n",
    "        list (of str): the peptides from new_peptides that not in the pept_dict.\n",
    "    \"\"\"\n",
    "    added_peptides = List()\n",
    "    for peptide in new_peptides:\n",
    "        if peptide in pept_dict:\n",
    "            if i not in pept_dict[peptide]:\n",
    "                pept_dict[peptide].append(i)\n",
    "        else:\n",
    "            pept_dict[peptide] = [i]\n",
    "            added_peptides.append(peptide)\n",
    "\n",
    "    return pept_dict, added_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pept_dict = {}\n",
    "new_peptides = ['ABC','DEF']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 0)\n",
    "\n",
    "new_peptides = ['DEF','GHI']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 1)\n",
    "\n",
    "print(pept_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_to_pept_dict():\n",
    "    pept_dict = {}\n",
    "    new_peptides = ['ABC','DEF']\n",
    "\n",
    "    pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 0)\n",
    "\n",
    "    new_peptides = ['DEF','GHI']\n",
    "\n",
    "    pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 1)\n",
    "    \n",
    "    assert pept_dict == {'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n",
    "    \n",
    "test_add_to_pept_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def merge_pept_dicts(list_of_pept_dicts:list)->dict:\n",
    "    \"\"\"\n",
    "    Merge a list of peptide dict into a single dict.\n",
    "    Args:\n",
    "        list_of_pept_dicts (list of dict): the key of the pept_dict is peptide sequence, and the value is protein id list indicating where the peptide is from.\n",
    "    Returns:\n",
    "        dict: the key is peptide sequence, and the value is protein id list indicating where the peptide is from.\n",
    "    \"\"\"\n",
    "    if len(list_of_pept_dicts) == 0:\n",
    "        raise ValueError('Need to pass at least 1 element.')\n",
    "    \n",
    "    new_pept_dict = list_of_pept_dicts[0]\n",
    "\n",
    "    for pept_dict in list_of_pept_dicts[1:]:\n",
    "\n",
    "        for key in pept_dict.keys():\n",
    "            if key in new_pept_dict:\n",
    "                for element in pept_dict[key]:\n",
    "                    new_pept_dict[key].append(element)\n",
    "            else:\n",
    "                new_pept_dict[key] = pept_dict[key]\n",
    "\n",
    "    return new_pept_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pept_dict_1 = {'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n",
    "pept_dict_2 = {'ABC': [3,4], 'JKL': [5, 6], 'MNO': [7]}\n",
    "\n",
    "merge_pept_dicts([pept_dict_1, pept_dict_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_merge_pept_dicts():\n",
    "    pept_dict_1 = {'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n",
    "    pept_dict_2 = {'ABC': [3,4], 'JKL': [5, 6], 'MNO': [7]}\n",
    "\n",
    "    assert merge_pept_dicts([pept_dict_1, pept_dict_2]) == {'ABC': [0, 3, 4], 'DEF': [0, 1], 'GHI': [1], 'JKL': [5, 6], 'MNO': [7]}\n",
    "    \n",
    "test_merge_pept_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a database\n",
    "\n",
    "To wrap everything up, we employ two functions, `generate_database` and `generate_spectra`. The first one reads a FASTA file and generates a list of peptides, as well as the peptide dictionary and an ordered FASTA dictionary to be able to look up the protein indices later. For the `callback` we first read the whole FASTA file to determine the total number of entries in the FASTA file.  For a typical FASTA file of 30 Mb with 40k entries, this should take less than a second. The progress of the digestion is monitored by processing the FASTA file one by one.\n",
    "The function `generate_spectra` then calculates precursor masses and fragment ions. Here, we split the total_number of sequences in `1000` steps to be able to track progress with the `callback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generate_fasta_list(fasta_paths:list, callback = None, **kwargs)->tuple:\n",
    "    \"\"\"\n",
    "    Function to generate a database from a fasta file\n",
    "    Args:\n",
    "        fasta_paths (str or list of str): fasta path or a list of fasta paths.\n",
    "        callback (function, optional): callback function.\n",
    "    Returns:\n",
    "        fasta_list (list of dict): list of protein entry dict {id:str, name:str, description:str, sequence:str}.\n",
    "        fasta_dict (dict{int:dict}): the key is the protein id, the value is the protein entry dict.\n",
    "    \"\"\"\n",
    "    fasta_list = []\n",
    "\n",
    "    fasta_dict = OrderedDict()\n",
    "\n",
    "    fasta_index = 0\n",
    "\n",
    "    if type(fasta_paths) is str:\n",
    "        fasta_paths = [fasta_paths]\n",
    "        n_fastas = 1\n",
    "\n",
    "    elif type(fasta_paths) is list:\n",
    "        n_fastas = len(fasta_paths)\n",
    "\n",
    "    for f_id, fasta_file in enumerate(fasta_paths):\n",
    "        n_entries = read_fasta_file_entries(fasta_file)\n",
    "\n",
    "        fasta_generator = read_fasta_file(fasta_file)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            check_sequence(element, constants.AAs)\n",
    "            fasta_list.append(element)\n",
    "            fasta_dict[fasta_index] = element\n",
    "            fasta_index += 1\n",
    "            \n",
    "                \n",
    "    return fasta_list, fasta_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_generate_fasta_list():\n",
    "    fasta_list, fasta_dict = generate_fasta_list('../testfiles/test.fasta')\n",
    "    assert len(fasta_list) == 17\n",
    "    assert fasta_dict[0]['name'] == 'sp|A0PJZ0|A20A5_HUMAN'\n",
    "    \n",
    "test_generate_fasta_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def generate_database(mass_dict:dict, fasta_paths:list, callback = None, **kwargs)->tuple:\n",
    "    \"\"\"\n",
    "    Function to generate a database from a fasta file\n",
    "    Args:\n",
    "        mass_dict (dict): not used, will be removed in the future.\n",
    "        fasta_paths (str or list of str): fasta path or a list of fasta paths.\n",
    "        callback (function, optional): callback function.\n",
    "    Returns:\n",
    "        to_add (list of str): non-redundant (modified) peptides to be added.\n",
    "        pept_dict (dict{str:list of int}): the key is peptide sequence, and the value is protein id list indicating where the peptide is from.\n",
    "        fasta_dict (dict{int:dict}): the key is the protein id, the value is the protein entry dict {id:str, name:str, description:str, sequence:str}.\n",
    "    \"\"\"\n",
    "    to_add = List()\n",
    "    fasta_dict = OrderedDict()\n",
    "    fasta_index = 0\n",
    "\n",
    "    pept_dict = {}\n",
    "\n",
    "    if type(fasta_paths) is str:\n",
    "        fasta_paths = [fasta_paths]\n",
    "        n_fastas = 1\n",
    "\n",
    "    elif type(fasta_paths) is list:\n",
    "        n_fastas = len(fasta_paths)\n",
    "\n",
    "    for f_id, fasta_file in enumerate(fasta_paths):\n",
    "        n_entries = read_fasta_file_entries(fasta_file)\n",
    "\n",
    "        fasta_generator = read_fasta_file(fasta_file)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            \n",
    "            fasta_dict[fasta_index] = element\n",
    "            mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "            pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "            if len(added_seqs) > 0:\n",
    "                to_add.extend(added_seqs)\n",
    "\n",
    "            fasta_index += 1\n",
    "\n",
    "            if callback:\n",
    "                callback(fasta_index/n_entries/n_fastas+f_id)\n",
    "\n",
    "    return to_add, pept_dict, fasta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_generate_database():\n",
    "\n",
    "    from alphapept.constants import mass_dict\n",
    "    from alphapept.settings import load_settings\n",
    "    from alphapept.paths import DEFAULT_SETTINGS_PATH\n",
    "\n",
    "    settings = load_settings(DEFAULT_SETTINGS_PATH)\n",
    "\n",
    "    to_add, pept_dict, fasta_dict = generate_database(mass_dict, ['../testfiles/test.fasta'], **settings['fasta'])\n",
    "    \n",
    "    assert len(to_add) == 3078 #This will break if the deafult settings are changed\n",
    "    assert 'GQTVLGSIDHLYTGSGYR' in pept_dict\n",
    "    assert fasta_dict[0]['name'] == 'sp|A0PJZ0|A20A5_HUMAN'\n",
    "    \n",
    "test_generate_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def generate_spectra(to_add:list, mass_dict:dict, callback = None)->list:\n",
    "    \"\"\"\n",
    "    Function to generate spectra list database from a fasta file\n",
    "    Args:\n",
    "        to_add (list): \n",
    "        mass_dict (dict{str:float}): amino acid mass dict.\n",
    "        callback (function, optional): callback function. (Default: None)\n",
    "    Returns:\n",
    "        list (of tuple): list of (peptide mass, peptide, fragment masses, fragment_types), see get_fragmass.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(to_add) > 0:\n",
    "\n",
    "        if callback: #Chunk the spectra to get a progress_bar\n",
    "            spectra = []\n",
    "\n",
    "            stepsize = int(np.ceil(len(to_add)/1000))\n",
    "\n",
    "            for i in range(0, len(to_add), stepsize):\n",
    "                sub = to_add[i:i + stepsize]\n",
    "                spectra.extend(get_spectra(sub, mass_dict))\n",
    "                callback((i+1)/len(to_add))\n",
    "\n",
    "        else:\n",
    "            spectra = get_spectra(to_add, mass_dict)\n",
    "    else:\n",
    "        raise ValueError(\"No spectra to generate.\")\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_generate_spectra():\n",
    "    from alphapept.constants import mass_dict\n",
    "    from numba.typed import List\n",
    "\n",
    "    to_add = List(['PEPTIDE'])\n",
    "    spectra = generate_spectra(to_add, mass_dict)\n",
    "    assert np.allclose(spectra[0][0], 799.35996420346)\n",
    "    assert spectra[0][1] == 'PEPTIDE'\n",
    "\n",
    "test_generate_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelized version\n",
    "\n",
    "To speed up spectra generated, one can use the parallelized version. The function `generate_database_parallel` reads an entire FASTA file and splits it into multiple blocks. Each block will be processed, and the generated pept_dicts will be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Generator\n",
    "\n",
    "def block_idx(len_list:int, block_size:int = 1000)->list:\n",
    "    \"\"\"\n",
    "    Helper function to split length into blocks\n",
    "    Args:\n",
    "        len_list (int): list length.\n",
    "        block_size (int, optional, default 1000): size per block.\n",
    "    Returns:\n",
    "        list[(int, int)]: list of (start, end) positions of blocks.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    while end <= len_list:\n",
    "        end += block_size\n",
    "        blocks.append((start, end))\n",
    "        start = end\n",
    "\n",
    "    return blocks\n",
    "\n",
    "def blocks(l:int, n:int)->Generator[list, None, None]:\n",
    "    \"\"\"\n",
    "    Helper function to create blocks from a given list\n",
    "    Args:\n",
    "        l (list): the list\n",
    "        n (int): size per block\n",
    "    Returns:\n",
    "        Generator: List with splitted elements\n",
    "    \"\"\"\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_block_idx():\n",
    "    assert block_idx(100, 50) == [(0, 50), (50, 100), (100, 150)]\n",
    "    \n",
    "test_block_idx()\n",
    "\n",
    "def test_blocks():\n",
    "    assert list(blocks([1,2,3,4], 2)) == [[1, 2], [3, 4]]\n",
    "\n",
    "test_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from alphapept import constants\n",
    "mass_dict = constants.mass_dict\n",
    "\n",
    "#This function is a wrapper function and to be tested by the integration test\n",
    "def digest_fasta_block(to_process:tuple)-> (list, dict):\n",
    "    \"\"\"\n",
    "    Digest and create spectra for a whole fasta_block for multiprocessing. See generate_database_parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    fasta_index, fasta_block, settings = to_process\n",
    "\n",
    "    to_add = List()\n",
    "\n",
    "    f_index = 0\n",
    "\n",
    "    pept_dict = {}\n",
    "    for element in fasta_block:\n",
    "        sequence = element[\"sequence\"]\n",
    "        mod_peptides = generate_peptides(sequence, **settings['fasta'])\n",
    "        pept_dict, added_peptides = add_to_pept_dict(pept_dict, mod_peptides, fasta_index+f_index)\n",
    "        if len(added_peptides) > 0:\n",
    "            to_add.extend(added_peptides)\n",
    "        f_index += 1\n",
    "\n",
    "    spectra = []\n",
    "    if len(to_add) > 0:\n",
    "        for specta_block in blocks(to_add, settings['fasta']['spectra_block']):\n",
    "            spectra.extend(generate_spectra(specta_block, mass_dict))\n",
    "\n",
    "    return (spectra, pept_dict)\n",
    "\n",
    "import alphapept.performance\n",
    "\n",
    "#This function is a wrapper function and to be tested by the integration test\n",
    "def generate_database_parallel(settings:dict, callback = None):\n",
    "    \"\"\"\n",
    "    Function to generate a database from a fasta file in parallel.\n",
    "    Args:\n",
    "        settings: alphapept settings.\n",
    "    Returns:\n",
    "        list: theoretical spectra. See generate_spectra()\n",
    "        dict: peptide dict. See add_to_pept_dict()\n",
    "        dict: fasta_dict. See generate_fasta_list()\n",
    "    \"\"\"\n",
    "    \n",
    "    n_processes = alphapept.performance.set_worker_count(\n",
    "        worker_count=settings['general']['n_processes'],\n",
    "        set_global=False\n",
    "    )\n",
    "\n",
    "    fasta_list, fasta_dict = generate_fasta_list(fasta_paths = settings['experiment']['fasta_paths'], **settings['fasta'])\n",
    "    \n",
    "    logging.info(f'FASTA contains {len(fasta_list):,} entries.')\n",
    "        \n",
    "    blocks = block_idx(len(fasta_list), settings['fasta']['fasta_block'])\n",
    "\n",
    "    to_process = [(idx_start, fasta_list[idx_start:idx_end], settings) for idx_start, idx_end in  blocks]\n",
    "\n",
    "    spectra = []\n",
    "    pept_dicts = []\n",
    "    with Pool(n_processes) as p:\n",
    "        max_ = len(to_process)\n",
    "        for i, _ in enumerate(p.imap_unordered(digest_fasta_block, to_process)):\n",
    "            if callback:\n",
    "                callback((i+1)/max_)\n",
    "            spectra.extend(_[0])\n",
    "            pept_dicts.append(_[1])\n",
    "\n",
    "    spectra = sorted(spectra, key=lambda x: x[1])\n",
    "    spectra_set = [spectra[idx] for idx in range(len(spectra)-1) if spectra[idx][1] != spectra[idx+1][1]]\n",
    "    spectra_set.append(spectra[-1])\n",
    "\n",
    "    pept_dict = merge_pept_dicts(pept_dicts)\n",
    "\n",
    "    return spectra_set, pept_dict, fasta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel search on large files\n",
    "\n",
    "In some cases (e.g., a lot of modifications or very large FASTA files), it will not be useful to save the database as it will consume too much memory. Here, we use the function `search_parallel` from search. It creates theoretical spectra on the fly and directly searches against them. As we cannot create a pept_dict here, we need to create one from the search results. For this, we group peptides by their FASTA index and generate a lookup dictionary that can be used as a pept_dict.\n",
    "\n",
    "> Note that we are passing the settings argument here. Search results should be stored in the corresponding path in the `*.hdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#This function is a wrapper function and to be tested by the integration test\n",
    "def pept_dict_from_search(settings:dict):\n",
    "    \"\"\"\n",
    "    Generates a peptide dict from a large search.\n",
    "    \"\"\"\n",
    "\n",
    "    paths = settings['experiment']['file_paths']\n",
    "    bases = [os.path.splitext(_)[0]+'.ms_data.hdf' for _ in paths]\n",
    "\n",
    "    all_dfs = []\n",
    "    for _ in bases:\n",
    "        try:\n",
    "            df = alphapept.io.MS_Data_File(_).read(dataset_name=\"peptide_fdr\")\n",
    "        except KeyError:\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "        if len(df) > 0:\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    if sum([len(_) for _ in all_dfs]) == 0:\n",
    "        raise ValueError(\"No sequences present to concatenate.\")\n",
    "\n",
    "    df = pd.concat(all_dfs)\n",
    "\n",
    "    df['fasta_index'] = df['fasta_index'].str.split(',')\n",
    "\n",
    "    lst_col = 'fasta_index'\n",
    "\n",
    "    df_ = pd.DataFrame({\n",
    "          col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "          for col in df.columns.drop(lst_col)}\n",
    "        ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]\n",
    "\n",
    "    df_['fasta_index'] = df_['fasta_index'].astype('int')\n",
    "    df_grouped = df_.groupby(['sequence'])['fasta_index'].unique()\n",
    "\n",
    "    pept_dict = {}\n",
    "    for keys, vals in zip(df_grouped.index, df_grouped.values):\n",
    "        pept_dict[keys] = vals.tolist()\n",
    "\n",
    "    return pept_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "To save the generated spectra, we rely on the HDF format. For this, we create a dictionary and save all the generated elements. The container will contain the following elements:\n",
    "\n",
    "* `precursors`: An array containing the precursor masses\n",
    "* `seqs`: An array containing the peptide sequences for the precursor masses\n",
    "* `pept_dict`: A peptide dictionary to look up the peptides and return their FASTA index\n",
    "* `fasta_dict`: A FASTA dictionary to look up the FASTA entry based on a pept_dict index\n",
    "* `fragmasses`: An array containing the fragment masses. Unoccupied cells are filled with -1\n",
    "* `fragtypes:`: An array containing the fragment types. 0 equals b-ions, and 1 equals y-ions. Unoccupied cells are filled with -1\n",
    "* `bounds`: An integer array containing the upper bounds for the fragment masses/types array. This is needed to quickly slice the data.\n",
    "\n",
    "All arrays are sorted according to the precursor mass.\n",
    "\n",
    "> Note: To access the dictionaries such as `pept_dict` or `fasta_dict`, one needs to extract them using the `.item()` method like so: `container[\"pept_dict\"].item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import alphapept.io\n",
    "import pandas as pd\n",
    "\n",
    "def save_database(spectra:list, pept_dict:dict, fasta_dict:dict, database_path:str, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to save a database to the *.hdf format. Write the database into hdf.\n",
    "    \n",
    "    Args:\n",
    "        spectra (list): list: theoretical spectra. See generate_spectra().\n",
    "        pept_dict (dict): peptide dict. See add_to_pept_dict().\n",
    "        fasta_dict (dict): fasta_dict. See generate_fasta_list().\n",
    "        database_path (str): Path to database.\n",
    "    \"\"\"\n",
    "    \n",
    "    precmasses, seqs, fragmasses, fragtypes = zip(*spectra)\n",
    "    sortindex = np.argsort(precmasses)\n",
    "    fragmasses = np.array(fragmasses, dtype=object)[sortindex]\n",
    "    fragtypes = np.array(fragtypes, dtype=object)[sortindex]\n",
    "\n",
    "    lens = [len(_) for _ in fragmasses]\n",
    "\n",
    "    n_frags = sum(lens)\n",
    "\n",
    "    frags = np.zeros(n_frags, dtype=fragmasses[0].dtype)\n",
    "    frag_types = np.zeros(n_frags, dtype=fragtypes[0].dtype)\n",
    "\n",
    "    indices = np.zeros(len(lens) + 1, np.int64)\n",
    "    indices[1:] = lens\n",
    "    indices = np.cumsum(indices)\n",
    "\n",
    "    #Fill data\n",
    "\n",
    "    for _ in range(len(indices)-1):\n",
    "\n",
    "        start = indices[_]\n",
    "        end = indices[_+1]\n",
    "        frags[start:end] = fragmasses[_]\n",
    "        frag_types[start:end] = fragtypes[_]\n",
    "    \n",
    "    to_save = {}\n",
    "    \n",
    "    to_save[\"precursors\"] = np.array(precmasses)[sortindex]\n",
    "    to_save[\"seqs\"] = np.array(seqs, dtype=object)[sortindex]\n",
    "    to_save[\"proteins\"] = pd.DataFrame(fasta_dict).T\n",
    "\n",
    "    to_save[\"fragmasses\"] = frags\n",
    "    to_save[\"fragtypes\"] = frag_types\n",
    "    to_save[\"indices\"] = indices\n",
    "\n",
    "    db_file = alphapept.io.HDF_File(database_path, is_new_file=True)\n",
    "    for key, value in to_save.items():\n",
    "        db_file.write(value, dataset_name=key)\n",
    "    \n",
    "    peps = np.array(list(pept_dict), dtype=object)\n",
    "    indices = np.empty(len(peps) + 1, dtype=np.int64)\n",
    "    indices[0] = 0\n",
    "    indices[1:] = np.cumsum([len(pept_dict[i]) for i in peps])\n",
    "    proteins = np.concatenate([pept_dict[i] for i in peps])\n",
    "    \n",
    "    db_file.write(\"peptides\")\n",
    "    db_file.write(\n",
    "        peps,\n",
    "        dataset_name=\"sequences\",\n",
    "        group_name=\"peptides\"\n",
    "    )\n",
    "    db_file.write(\n",
    "        indices,\n",
    "        dataset_name=\"protein_indptr\",\n",
    "        group_name=\"peptides\"\n",
    "    )\n",
    "    db_file.write(\n",
    "        proteins,\n",
    "        dataset_name=\"protein_indices\",\n",
    "        group_name=\"peptides\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import collections\n",
    "\n",
    "def read_database(database_path:str, array_name:str=None)->dict:\n",
    "    \"\"\"\n",
    "    Read database from hdf file.\n",
    "    Args:\n",
    "        database_path (str): hdf database file generate by alphapept.\n",
    "        array_name (str): the dataset name to read\n",
    "    return:\n",
    "        dict: key is the dataset_name in hdf file, value is the python object read from the dataset_name\n",
    "    \"\"\"\n",
    "    db_file = alphapept.io.HDF_File(database_path)\n",
    "    if array_name is None:\n",
    "        db_data = {\n",
    "            key: db_file.read(\n",
    "                dataset_name=key\n",
    "            ) for key in db_file.read() if key not in (\n",
    "                \"proteins\",\n",
    "                \"peptides\"\n",
    "            )\n",
    "        }\n",
    "        db_data[\"fasta_dict\"] = np.array(\n",
    "            collections.OrderedDict(db_file.read(dataset_name=\"proteins\").T)\n",
    "        )\n",
    "        peps = db_file.read(dataset_name=\"sequences\", group_name=\"peptides\")\n",
    "        protein_indptr = db_file.read(\n",
    "            dataset_name=\"protein_indptr\",\n",
    "            group_name=\"peptides\"\n",
    "        )\n",
    "        protein_indices = db_file.read(\n",
    "            dataset_name=\"protein_indices\",\n",
    "            group_name=\"peptides\"\n",
    "        )\n",
    "        db_data[\"pept_dict\"] = np.array(\n",
    "            {\n",
    "                pep: (protein_indices[s: e]).tolist() for pep, s, e in zip(\n",
    "                    peps,\n",
    "                    protein_indptr[:-1],\n",
    "                    protein_indptr[1:],\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        db_data[\"seqs\"] = db_data[\"seqs\"].astype(str)\n",
    "    else:\n",
    "        db_data = db_file.read(dataset_name=array_name)\n",
    "    return db_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_database_io():\n",
    "    from alphapept.constants import mass_dict\n",
    "    from numba.typed import List\n",
    "\n",
    "    to_add = List(['PEPTIDE'])\n",
    "    spectra = generate_spectra(to_add, mass_dict)\n",
    "\n",
    "    fasta_list, fasta_dict = generate_fasta_list('../testfiles/test.fasta')\n",
    "\n",
    "    database_path = '../testfiles/testdb.hdf'\n",
    "\n",
    "    save_database(spectra, pept_dict, fasta_dict, database_path)\n",
    "\n",
    "    assert list(read_database(database_path, 'seqs')) == ['PEPTIDE']\n",
    "    assert np.allclose(list(read_database(database_path, 'precursors'))[0], spectra[0][0])\n",
    "\n",
    "test_database_io()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-alphapept2]",
   "language": "python",
   "name": "conda-env-.conda-alphapept2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
