{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA\n",
    "\n",
    "> Functions related to generating spectra from FASTA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to creating spectra from FASTA files. In brief, what we are doing is the following:\n",
    "\n",
    "1. Read a FASTA file and digest the sequences\n",
    "2. For each peptide, calculate a synthetic spectrum and precursor mass\n",
    "3. Save spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "from numba import NumbaPendingDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaving\n",
    "\n",
    "For cleaving, we use regular expressions to find potential cleavages sites and write the wrapper `cleave_sequence` to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept import constants\n",
    "import re\n",
    "\n",
    "def get_missed_cleavages(sequences, n_missed_cleavages):\n",
    "    \"\"\"\n",
    "    Combine cleaved sequences to get sequences with missed cleavages\n",
    "    \"\"\"\n",
    "    missed = []\n",
    "    for k in range(len(sequences)-n_missed_cleavages):\n",
    "        missed.append(''.join(sequences[k-1:k+n_missed_cleavages]))\n",
    "        \n",
    "    return missed\n",
    "\n",
    "\n",
    "def cleave_sequence(\n",
    "    sequence=\"\",\n",
    "    num_missed_cleavages=0,\n",
    "    protease=\"trypsin\",\n",
    "    min_length=6,\n",
    "    max_length=65,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    proteases = constants.protease_dict\n",
    "    pattern = proteases[protease]\n",
    "    \n",
    "    p = re.compile(pattern)\n",
    "\n",
    "    cutpos = [m.start()+1 for m in p.finditer(sequence)]\n",
    "    cutpos.insert(0,0)\n",
    "    cutpos.append(len(sequence))\n",
    "    \n",
    "    base_sequences = [sequence[cutpos[i]:cutpos[i+1]] for i in range(len(cutpos)-1)]\n",
    "\n",
    "    sequences = base_sequences.copy()\n",
    "\n",
    "    for i in range(1, num_missed_cleavages+1):\n",
    "        sequences.extend(get_missed_cleavages(base_sequences, i))\n",
    "    \n",
    "    sequences = [_ for _ in sequences if len(_)>=min_length and len(_)<=max_length]\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCDEFGHIJK', 'LMNOPQR']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "num_missed_cleavages = 0\n",
    "min_length, max_length = 6, 65\n",
    "\n",
    "cleave_sequence('ABCDEFGHIJKLMNOPQRST', num_missed_cleavages, protease, min_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_cleave_sequence():\n",
    "    \n",
    "    protease = \"trypsin\"\n",
    "    min_length, max_length = 6, 65\n",
    "\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 0, protease, min_length, max_length)) == set(['ABCDEFGHIJK', 'LMNOPQR'])\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', 1, protease, min_length, max_length)) == set(['ABCDEFGHIJK', 'LMNOPQR', 'ABCDEFGHIJKLMNOPQR'])\n",
    "\n",
    "    test_cleave_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missed and internal cleavages\n",
    "The following are helper functions to retrieve the number of missed cleavages and internal cleavage sites for each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "from alphapept import constants\n",
    "\n",
    "def count_missed_cleavages(sequence=\"\", protease=\"trypsin\",**kwargs):\n",
    "    \"\"\"\n",
    "    Counts the number of missed cleavages for a given sequence and protease\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    p = re.compile(protease)\n",
    "    n_missed = len(p.findall(sequence))\n",
    "    return n_missed\n",
    "\n",
    "def count_internal_cleavages(sequence=\"\", protease=\"trypsin\",**kwargs):\n",
    "    \"\"\"\n",
    "    Counts the number of internal cleavage sites for a given sequence and protease\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    match = re.search(protease,sequence[-1]+'_')\n",
    "    if match:\n",
    "        n_internal = 0\n",
    "    else:\n",
    "        n_internal = 1\n",
    "    return n_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "print(count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', protease))\n",
    "\n",
    "protease = \"trypsin\"\n",
    "print(count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', protease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_missed_cleavages():  \n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 2\n",
    "    assert count_missed_cleavages('ABCDEFGHIJKLMNOPQRST', 'clostripain') == 1\n",
    "    \n",
    "test_get_missed_cleavages()\n",
    "\n",
    "def test_get_internal_cleavages():\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRST', 'trypsin') == 1\n",
    "    assert count_internal_cleavages('ABCDEFGHIJKLMNOPQRSTK', 'trypsin') == 0\n",
    "\n",
    "test_get_internal_cleavages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Peptides are composed out of amino acids that are written in capital letters - `PEPTIDE`. to distinguish modifications, they are written in lowercase such as `PEPTIoxDE` and can be of arbitrary length. For a modified amino acid, the modification preceds the letter of the amino acid. Decoys are indicated with a underscore, hence the `parse` function splits after `_`. When parsing, the peptide string is converted into a numba-compatible list so that each element can be determined with the `mass_dict` from `alphapept.constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "@njit\n",
    "def parse(peptide):\n",
    "    \"\"\"\n",
    "    Parser to parse peptide strings\n",
    "    \"\"\"\n",
    "    if \"_\" in peptide:\n",
    "        peptide = peptide.split(\"_\")[0]\n",
    "    parsed = List()\n",
    "    string = \"\"\n",
    "\n",
    "    for i in peptide:\n",
    "        string += i\n",
    "        if i.isupper():\n",
    "            parsed.append(string)\n",
    "            string = \"\"\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def list_to_numba(a_list):\n",
    "    numba_list = List()\n",
    "\n",
    "    for element in a_list:\n",
    "        numba_list.append(element)\n",
    "\n",
    "    return numba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P, E, P, T, I, D, E]\n",
      "[P, E, P, oxT, I, D, E]\n"
     ]
    }
   ],
   "source": [
    "print(parse('PEPTIDE'))\n",
    "print(parse('PEPoxTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_parse():\n",
    "    peptide = \"PEPTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPoxTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"oxT\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPTIDE_decoy\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    \n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoy\n",
    "\n",
    "The decoy strategy that is employed is a pseudo-reversal of the peptide sequence, keeping only the terminal amino-acid and reversing the rest. Additionally, we can call the functions `swap_KR` and and `swap_AL` that will swap the respective AAs. The function `swap_KR` will only swap terminal AAs. The swapping functions only work if the AA is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_decoy_sequence(peptide, pseudo_reverse=True, AL_swap=False, KR_swap = False):\n",
    "    \"\"\"\n",
    "    Reverses a sequence and adds the '_decoy' tag.\n",
    "\n",
    "    \"\"\"\n",
    "    pep = parse(peptide)\n",
    "    if pseudo_reverse:        \n",
    "        rev_pep = pep[:-1][::-1]\n",
    "        rev_pep.append(pep[-1])\n",
    "    else:\n",
    "        rev_pep = pep[::-1]\n",
    "\n",
    "    if AL_swap:\n",
    "        rev_pep = swap_AL(rev_pep)\n",
    "\n",
    "    if KR_swap:\n",
    "        rev_pep = swap_KR(rev_pep)\n",
    "\n",
    "    rev_pep = \"\".join(rev_pep)\n",
    "\n",
    "    return rev_pep\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_KR(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a terminal K or R. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    if peptide[-1] == 'K':\n",
    "        peptide[-1] = 'R'\n",
    "    elif peptide[-1] == 'R':\n",
    "        peptide[-1] = 'K'\n",
    "\n",
    "    return peptide\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_AL(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a A with L. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(range(len(peptide) - 1)):\n",
    "        if peptide[i] == \"A\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"A\"\n",
    "            i += 1\n",
    "        elif peptide[i] == \"L\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"L\"\n",
    "            i += 1\n",
    "        i += 1\n",
    "\n",
    "    return peptide\n",
    "\n",
    "def get_decoys(peptide_list):\n",
    "    \"\"\"\n",
    "    Wrapper to get decoys for lists of peptides\n",
    "    \"\"\"\n",
    "    decoys = []\n",
    "    decoys.extend([get_decoy_sequence(peptide) for peptide in peptide_list])\n",
    "    return decoys\n",
    "\n",
    "def add_decoy_tag(peptides):\n",
    "    \"\"\"\n",
    "    Adds a _decoy tag to a list of peptides\n",
    "    \"\"\"\n",
    "    return [peptide + \"_decoy\" for peptide in peptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[K, K, K, L, A, K, K, K]\n",
      "[A, A, A, K, R, A, A, A]\n"
     ]
    }
   ],
   "source": [
    "print(swap_AL(parse('KKKALKKK')))\n",
    "print(swap_KR(parse('AAAKRAAA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DITPEPE\n"
     ]
    }
   ],
   "source": [
    "print(get_decoy_sequence('PEPTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAC', 'EDF', 'HGI']\n"
     ]
    }
   ],
   "source": [
    "print(get_decoys(['ABC','DEF','GHI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_swap_AL():\n",
    "    assert swap_AL(parse(\"ABCDEF\")) == parse(\"BACDEF\")\n",
    "    assert swap_AL(parse(\"GHIKLM\")) == parse(\"GHIKML\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "    assert swap_AL(parse(\"GHIKL\")) == parse(\"GHIKL\")\n",
    "    assert swap_AL(parse(\"ABCDEFGHIKLM\")) == parse(\"BACDEFGHIKML\")\n",
    "    assert swap_AL(parse(\"BBAcCD\")) == parse(\"BBcCAD\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "\n",
    "test_swap_AL()\n",
    "\n",
    "def test_swapKR():\n",
    "    assert swap_KR(parse(\"ABCDEK\")) == parse(\"ABCDER\")\n",
    "    assert swap_KR(parse(\"ABCDER\")) == parse(\"ABCDEK\")\n",
    "    assert swap_KR(parse(\"ABCDEF\")) == parse(\"ABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCDEF\")) == parse(\"KABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCRDEF\")) == parse(\"KABCRDEF\")\n",
    "    assert swap_KR(parse(\"KABCKDEF\")) == parse(\"KABCKDEF\")\n",
    "\n",
    "test_swapKR()\n",
    "    \n",
    "def test_get_decoy_sequence():\n",
    "    peptide = \"PEPTIDER\"\n",
    "    assert get_decoy_sequence(peptide, pseudo_reverse=False) == \"REDITPEP\"\n",
    "    assert get_decoy_sequence(peptide) == \"EDITPEPR\"\n",
    "    assert get_decoy_sequence(peptide, KR_swap=True) == \"EDITPEPK\"\n",
    "    \n",
    "test_get_decoy_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "\n",
    "To add modifications to the peptides we distinguish fixed and variable modifications. Additionally, we make a distinciton between whether the modification is only terminal or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Modifications\n",
    "Fixed modifications are implemented by passing a list with modified AAs that should be replaced. As we only have one letter AAs the remainder is the modification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mods(seqs, mods_fixed, **kwargs):\n",
    "    \"\"\"\n",
    "    Adds fixed modifications to sequences.\n",
    "    \"\"\"\n",
    "    if not mods_fixed:\n",
    "        return seqs\n",
    "    else:\n",
    "        for mod_aa in mods_fixed:\n",
    "            seqs = [seq.replace(mod_aa[-1], mod_aa) for seq in seqs]\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbBcCDEF']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_fixed = ['cC','bB']\n",
    "peptide_list = ['ABCDEF']\n",
    "\n",
    "add_fixed_mods(peptide_list, mods_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_fixed_mods():\n",
    "    mods_fixed = ['cC']\n",
    "    peptide_list = ['ABCDEF']\n",
    "\n",
    "    peptides_new = add_fixed_mods(peptide_list, [])\n",
    "    assert peptides_new == peptide_list\n",
    "    \n",
    "    peptides_new = add_fixed_mods(peptide_list, mods_fixed)\n",
    "    assert peptides_new == ['ABcCDEF']\n",
    "    \n",
    "test_add_fixed_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Modifications\n",
    "\n",
    "To employ variable modifications, we use the function `get_mod_pos` that returns a list of tuples with all possible modifications when giving a dicitionary with variable modifications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_mod_pos(variable_mods_r, sequence):\n",
    "    \"\"\"\n",
    "    Returns a list with of tuples with all possibilities for modified an unmodified AAs.\n",
    "    \"\"\"\n",
    "    modvar = []\n",
    "    for c in sequence:\n",
    "        if c in variable_mods_r.keys():\n",
    "            modvar.append((c, variable_mods_r[c]))\n",
    "        else:\n",
    "            modvar.append((c,))\n",
    "\n",
    "    return modvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "get_mod_pos(mods_variable_dict, peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_get_mod_pos():\n",
    "    \n",
    "    mods_variable_dict = {'M':'oxM'}\n",
    "    peptide = 'AMAMA'\n",
    "    assert set(get_mod_pos(mods_variable_dict, peptide)) == set([('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)])\n",
    "    \n",
    "test_get_mod_pos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To now generate all isoforms, we employ the function `get_isoforms` that generates all isoforms for a given peptide. As the number of isoforms can become large, we restrict it with the parameter `max_isoforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from itertools import product\n",
    "def get_isoforms(variable_mods_r, sequence, max_isoforms):\n",
    "    \"\"\"\n",
    "    Function to generate isoforms for a given peptide - returns a list of isoforms.\n",
    "    The original sequence is included in the list\n",
    "    \"\"\"\n",
    "    modvar = get_mod_pos(variable_mods_r, sequence)\n",
    "    isoforms = []\n",
    "    i = 0\n",
    "    for o in product(*modvar):\n",
    "        if i < max_isoforms:\n",
    "            i += 1\n",
    "            isoforms.append(\"\".join(o))\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "max_isoforms = 1024\n",
    "get_isoforms(mods_variable_dict, peptide, max_isoforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the wrapper `add_variable_mods` so that the functions can be called for lists of peptides and a list of variable modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from itertools import chain\n",
    "\n",
    "def add_variable_mods(peptide_list, mods_variable, max_isoforms, **kwargs):\n",
    "    if not mods_variable:\n",
    "        return peptide_list\n",
    "    else:\n",
    "        mods_variable_r = {}\n",
    "        for _ in mods_variable:\n",
    "            mods_variable_r[_[-1]] = _\n",
    "\n",
    "        peptide_list = [get_isoforms(mods_variable_r, peptide, max_isoforms) for peptide in peptide_list]\n",
    "        return list(chain.from_iterable(peptide_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMA', 'AoxMA', 'AAC', 'AAamC']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMA', 'AAC']\n",
    "mods_variable = ['oxM','amC']\n",
    "max_isoforms = 1024\n",
    "\n",
    "add_variable_mods(peptide_list, mods_variable, max_isoforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods():\n",
    "    mods_variable = ['oxM']\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, [], 1024)\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 1024)\n",
    "\n",
    "    assert set(['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']) == set(peptides_new)\n",
    "\n",
    "    # Check if number of isoforms is correct\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 2)\n",
    "\n",
    "    assert len(peptides_new) == 2\n",
    "    \n",
    "test_add_variable_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Fixed\n",
    "\n",
    "To handle terminal modifications, we use the following convention:\n",
    "\n",
    "* `<` for the left side (N-terminal)\n",
    "* `>` for the right side (C-Terminal)\n",
    "\n",
    "Additionally, if we want to have a terminal modification on any AA we indicate this `^`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mod_terminal(peptides, mod):\n",
    "    \"\"\"\n",
    "    Adds fixed terminal modifications\n",
    "    \"\"\"\n",
    "    # < for left side (N-Term), > for right side (C-Term)\n",
    "    if \"<^\" in mod: #Any n-term, e.g. a<^\n",
    "        peptides = [mod[:-2] + peptide for peptide in peptides]\n",
    "    elif \">^\" in mod: #Any c-term, e.g. a>^\n",
    "        peptides = [peptide[:-1] + mod[:-2] + peptide[-1] for peptide in peptides]\n",
    "    elif \"<\" in mod: #only if specific AA, e.g. ox<C\n",
    "        peptides = [peptide[0].replace(mod[-1], mod[:-2]+mod[-1]) + peptide[1:] for peptide in peptides]\n",
    "    elif \">\" in mod:\n",
    "        peptides = [peptide[:-1] + peptide[-1].replace(mod[-1], mod[:-2]+mod[-1]) for peptide in peptides]\n",
    "    else:\n",
    "        # This should not happen\n",
    "        raise (\"Invalid fixed terminal modification {}.\".format(key))\n",
    "    return peptides\n",
    "\n",
    "def add_fixed_mods_terminal(peptides, mods_fixed_terminal, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to add fixed mods on sequences and lists of mods\n",
    "    \"\"\"\n",
    "    if mods_fixed_terminal == []:\n",
    "        return peptides\n",
    "    else:\n",
    "        # < for left side (N-Term), > for right side (C-Term)\n",
    "        for key in mods_fixed_terminal:\n",
    "            peptides = add_fixed_mod_terminal(peptides, key)\n",
    "        return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any n-term modified with x (x<^): ['xAMAMA']\n",
      "Any c-term modified with x (x>^): ['AMAMxA']\n",
      "Only A on n-term modified with x (x<A): ['xAMAMA']\n",
      "Only A on c-term modified with x (x<A): ['AMAMxA']\n"
     ]
    }
   ],
   "source": [
    "peptide = ['AMAMA']\n",
    "\n",
    "print('Any n-term modified with x (x<^):', add_fixed_mods_terminal(peptide, ['x<^']))\n",
    "print('Any c-term modified with x (x>^):', add_fixed_mods_terminal(peptide, ['x>^']))\n",
    "print('Only A on n-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x<A']))\n",
    "print('Only A on c-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x>A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_fixed_mods_terminal():\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<^'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    #Any C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>^'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    #Selected N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<A'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<C'])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Selected C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>A'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>C'])\n",
    "    assert peptides_new == peptide\n",
    "    \n",
    "test_add_fixed_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Variable\n",
    "\n",
    "Lastly, to handle terminal variable modifications we use the function `add_variable_mods_terminal`. As the modifcation can only be at the terminal end this function only adds a peptide where the terminal end is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_variable_mods_terminal(peptides, mods_variable_terminal, **kwargs):\n",
    "    \"Function to add variable terminal modifications\"\n",
    "    if not mods_variable_terminal:\n",
    "        return peptides\n",
    "    else:\n",
    "        new_peptides_n = peptides.copy()\n",
    "\n",
    "        for key in mods_variable_terminal:\n",
    "            if \"<\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_n.extend(\n",
    "                    add_fixed_mod_terminal(peptides, key)\n",
    "                )\n",
    "        new_peptides_n = get_unique_peptides(new_peptides_n)\n",
    "        # N complete, let's go for c-terminal\n",
    "        new_peptides_c = new_peptides_n\n",
    "        for key in mods_variable_terminal:\n",
    "            if \">\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_c.extend(\n",
    "                    add_fixed_mod_terminal(new_peptides_n, key)\n",
    "                )\n",
    "\n",
    "        return get_unique_peptides(new_peptides_c)\n",
    "\n",
    "def get_unique_peptides(peptides):\n",
    "    return list(set(peptides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAMA', 'xAMAMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMAMA']\n",
    "add_variable_mods_terminal(peptide_list, ['x<^'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_add_variable_mods_terminal():\n",
    "    peptide_list = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, ['x<^'])\n",
    "    assert set(peptides_new) == set(['xAMAMA', 'AMAMA'])\n",
    "    \n",
    "test_add_variable_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Peptides\n",
    "\n",
    "Lastly we put all the functions into a wrapper `generate_peptides`. It will accept a peptide and a dictionary with settings so that we can get all modified peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_peptides(peptide, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to get modified peptides from a peptide\n",
    "    \"\"\"\n",
    "    mod_peptide = add_fixed_mods_terminal([peptide], kwargs['mods_fixed_terminal_prot'])\n",
    "\n",
    "    mod_peptide = add_variable_mods_terminal(mod_peptide, kwargs['mods_variable_terminal_prot'])\n",
    "\n",
    "    peptides = []\n",
    "    [peptides.extend(cleave_sequence(_, **kwargs)) for _ in mod_peptide]\n",
    "\n",
    "    #Regular peptides\n",
    "    mod_peptides = add_fixed_mods(peptides, **kwargs)\n",
    "    mod_peptides = add_fixed_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods(mod_peptides, **kwargs)\n",
    "\n",
    "    #Decoys:\n",
    "    decoy_peptides = get_decoys(peptides)\n",
    "\n",
    "    mod_peptides_decoy = add_fixed_mods(decoy_peptides, **kwargs)\n",
    "    mod_peptides_decoy = add_fixed_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods(mod_peptides_decoy, **kwargs)\n",
    "\n",
    "    mod_peptides_decoy = add_decoy_tag(mod_peptides_decoy)\n",
    "\n",
    "    mod_peptides.extend(mod_peptides_decoy)\n",
    "\n",
    "    return mod_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEPTIDEM', 'PEPTIDEoxM', 'EDITPEPM_decoy', 'EDITPEPoxM_decoy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs[\"protease\"] = \"trypsin\"\n",
    "kwargs[\"num_missed_cleavages\"] = 2\n",
    "kwargs[\"min_length\"] = 6\n",
    "kwargs[\"max_length\"] = 27\n",
    "kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "kwargs[\"mods_variable_terminal\"] = []\n",
    "kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "kwargs[\"mods_fixed_terminal\"] = []\n",
    "kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "generate_peptides('PEPTIDEM', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEPTIDEM']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleave_sequence('PEPTIDEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_generate_peptides():\n",
    "    kwargs = {}\n",
    "\n",
    "    kwargs[\"protease\"] = \"trypsin\"\n",
    "    kwargs[\"num_missed_cleavages\"] = 2\n",
    "    kwargs[\"min_length\"] = 6\n",
    "    kwargs[\"max_length\"] = 27\n",
    "    kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "    kwargs[\"mods_variable_terminal\"] = []\n",
    "    kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "    kwargs[\"mods_fixed_terminal\"] = []\n",
    "    kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "    kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "    kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "    peps = generate_peptides('PEPTIDEM', **kwargs)\n",
    "    \n",
    "    assert set(peps) == set(['PEPTIDEM', 'PEPTIDEoxM', 'EDITPEPM_decoy', 'EDITPEPoxM_decoy'])\n",
    "    \n",
    "test_generate_peptides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass Calculations\n",
    "\n",
    "Using the `mass_dict` from `constants` and being able to parse sequences with `parse` we can simply look up the masses for each modified or unmodified amino acid and add everything up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor\n",
    "\n",
    "To calculate the mass of the neutral precursor we start with the mass of an $H_2O$ and add the masses of all amino acids of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def get_precmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the mass of the neutral precursor\n",
    "    \"\"\"\n",
    "    tmass = mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep:\n",
    "        tmass += mass_dict[_]\n",
    "\n",
    "    return tmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799.3599642034599"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_precmass():\n",
    "    \n",
    "    precmass = get_precmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "test_get_precmass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragments\n",
    "\n",
    "Likewise, we can calculate the masses of the fragment ions. We employ two functions: `get_fragmass` and `get_frag_dict`. \n",
    "\n",
    "`get_fragmass` is a fast, `numba`-compatible function that calculates the fragmasses and returns an array indicating wheter the iontype was `b` or `y`. \n",
    "\n",
    "`get_frag_dict` instead is not `numba`-compatible and hence a bit slower. It returns a dictionary with the respective ion and can be used for plotting theoretical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@njit\n",
    "def get_fragmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_masses = np.zeros(n_frags, dtype=np.float64)\n",
    "    frag_type = np.zeros(n_frags, dtype=np.int8)\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 0\n",
    "        n_frag += 1\n",
    "\n",
    "    # y-ions -> 1\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 1\n",
    "        n_frag += 1\n",
    "\n",
    "    return frag_masses, frag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
       "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
       "        376.17144135, 477.21911985, 574.27188371, 703.31447681]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], dtype=int8))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fragmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_fragmass():\n",
    "    \n",
    "    frag_masses, frag_type = get_fragmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    ref_masses = np.array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
    "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
    "        376.17144135, 477.21911985, 574.27188371, 703.31447681])\n",
    "    \n",
    "    assert np.allclose(frag_masses, ref_masses)\n",
    "                          \n",
    "test_get_fragmass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_frag_dict(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_dict = {}\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "\n",
    "        frag_dict['b' + str(n_frag)] = frag_m\n",
    "\n",
    "    # y-ions -> 1\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "        frag_dict['y' + str(n_frag)] = frag_m\n",
    "\n",
    "    return frag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': 98.06004032687,\n",
       " 'b2': 227.10263342686997,\n",
       " 'b3': 324.15539728686997,\n",
       " 'y1': 120.06551965033,\n",
       " 'y2': 217.11828351033,\n",
       " 'y3': 346.16087661033}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frag_dict(parse('PEPT'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_frag_dict():\n",
    "    \n",
    "    refdict = {'b1': 98.06004032687,\n",
    " 'b2': 227.10263342686997,\n",
    " 'b3': 324.15539728686997,\n",
    " 'y1': 120.06551965033,\n",
    " 'y2': 217.11828351033,\n",
    " 'y3': 346.16087661033}\n",
    "    \n",
    "    newdict = get_frag_dict(parse('PEPT'), constants.mass_dict)\n",
    "    \n",
    "    for key in newdict.keys():\n",
    "        \n",
    "        assert np.allclose(refdict[key], newdict[key])\n",
    "        \n",
    "test_get_frag_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us also to generate the theorteical isotopes for a fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "peptide = 'PEPTIDE'\n",
    "\n",
    "frag_dict = get_frag_dict(parse(peptide), constants.mass_dict)\n",
    "\n",
    "db_frag = list(frag_dict.values())\n",
    "db_int = [100 for _ in db_frag]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.vlines(db_frag, 0, db_int, \"k\", label=\"DB\", alpha=0.2)\n",
    "\n",
    "for _ in frag_dict.keys():\n",
    "    plt.text(frag_dict[_], 104, _, fontsize=12, alpha = 0.8)\n",
    "    \n",
    "plt.title('Theoretical Spectrum for {}'.format(peptide))\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.ylim([0,110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra\n",
    "\n",
    "The function `get_spectrum` returns a tuple with the following content:\n",
    "\n",
    "* precursor mass\n",
    "* peptide sequence\n",
    "* fragmasses\n",
    "* fragtypes\n",
    "\n",
    "Likewise, `get_spectra` returns a list of tuples. We employ a list of tuples here as this way we can sort them easily by precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_spectrum(peptide, mass_dict):\n",
    "    parsed_peptide = parse(peptide)\n",
    "\n",
    "    fragmasses, fragtypes = get_fragmass(parsed_peptide, mass_dict)\n",
    "    sortindex = np.argsort(fragmasses)\n",
    "    fragmasses = fragmasses[sortindex]\n",
    "    fragtypes = fragtypes[sortindex]\n",
    "\n",
    "    precmass = get_precmass(parsed_peptide, mass_dict)\n",
    "\n",
    "    return (precmass, peptide, fragmasses, fragtypes)\n",
    "\n",
    "@njit\n",
    "def get_spectra(peptides, mass_dict):\n",
    "    spectra = []\n",
    "\n",
    "    for i in range(len(peptides)):\n",
    "        spectra.append(get_spectrum(peptides[i], mass_dict))\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(799.3599642034599, 'PEPTIDE', array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
      "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
      "       538.28713979, 574.27188371, 653.31408289, 703.31447681]), array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], dtype=int8))]\n"
     ]
    }
   ],
   "source": [
    "print(get_spectra(['PEPTIDE'], constants.mass_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_spectra():\n",
    "    \n",
    "    spectra = get_spectra(['PEPTIDE'], constants.mass_dict)\n",
    "    \n",
    "    precmass, peptide, frags, fragtypes = spectra[0]\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "    assert peptide == 'PEPTIDE'\n",
    "    \n",
    "    assert np.allclose(frags, np.array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
    "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
    "       538.28713979, 574.27188371, 653.31408289, 703.31447681]))\n",
    "\n",
    "test_get_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading FASTA\n",
    "\n",
    "To read FASTA files we use the `SeqIO` module from the `Biopython` library.\n",
    "Generator expression so that we can read it one by one\n",
    "\n",
    "Additionally we define the wrapper `read_fasta` that allows to read multiple FASTA files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def read_fasta_file(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    given a fasta_file read fasta file line by line, return progress\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                parts = record.id.split(\"|\")  # pipe char\n",
    "                if len(parts) > 1:\n",
    "                    id = parts[1]\n",
    "                else:\n",
    "                    id = record.name\n",
    "                sequence = str(record.seq)\n",
    "                entry = {\n",
    "                    \"id\": id,\n",
    "                    \"name\": record.name,\n",
    "                    \"description\": record.description,\n",
    "                    \"sequence\": sequence,\n",
    "                }\n",
    "\n",
    "                yield entry\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "\n",
    "def read_fasta_file_entries(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    Function to count entries in fasta file\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        count = 0\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                count+=1\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "\n",
    "def read_fasta(path):\n",
    "    \"\"\"\n",
    "    Wrapper to read multiple files.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(path):\n",
    "        paths = glob(path + \"/*.fasta\")\n",
    "    else:\n",
    "        paths = glob(path)\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        raise KeyError(\"Not a valid Fasta Path: {}.\".format(path))\n",
    "\n",
    "    for fasta_file in paths:\n",
    "        for entry in read_fasta_file(fasta_file):\n",
    "            yield entry\n",
    "\n",
    "def check_sequence(element, AAs):\n",
    "    \"\"\"\n",
    "    Checks wheter a sequence from a FASTA entry contains valid AAs\n",
    "    \"\"\"\n",
    "    if not set(element['sequence']).issubset(AAs):\n",
    "        print('Error. This FASTA Entry contains unknown AAs and will be skipped: \\n {}\\n'.format(element))\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'A0PJZ0',\n",
       " 'name': 'sp|A0PJZ0|A20A5_HUMAN',\n",
       " 'description': 'sp|A0PJZ0|A20A5_HUMAN Putative ankyrin repeat domain-containing protein 20A5 OS=Homo sapiens OX=9606 GN=ANKRD20A5P PE=5 SV=1',\n",
       " 'sequence': 'MKLFGFRSRRGQTVLGSIDHLYTGSGYRIRYSELQKIHKAAVKGDAAEMERCLARRSGDLDALDKQHRTALHLACASGHVKVVTLLVNRKCQIDIYDKENRTPLIQAVHCQEEACAVILLEHGANPNLKDIYGNTALHYAVYSESTSLAEKLLFHGENIEALDKV'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load example fasta file\n",
    "\n",
    "fasta_path = '../testfiles/test.fasta'\n",
    "\n",
    "list(read_fasta(fasta_path))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Dictionary\n",
    "\n",
    "In order to efficiently store peptides we rely on the python in dictionary. The idea is to have a dictionary with peptides as keys and indicies to proteins as values. This way we can quickly look up to which protein a peptide belongs to. The function `add_to_pept_dict` uses a regular python dictionary and allows to add peptides and stores indicies to the originating proteins as a list. If a peptide is already present in the dictionary the list is appended. The function returns a list of `added_peptides` which were not present in the dictionary yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_to_pept_dict(pept_dict, new_peptides, i):\n",
    "    \"\"\"\n",
    "    Add peptides to the peptide dictionary\n",
    "    \"\"\"\n",
    "    added_peptides = List()\n",
    "    for peptide in new_peptides:\n",
    "        if peptide in pept_dict:\n",
    "            pept_dict[peptide].append(i)\n",
    "        else:\n",
    "            pept_dict[peptide] = [i]\n",
    "            added_peptides.append(peptide)\n",
    "\n",
    "    return pept_dict, added_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n"
     ]
    }
   ],
   "source": [
    "pept_dict = {}\n",
    "new_peptides = ['ABC','DEF']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 0)\n",
    "\n",
    "new_peptides = ['DEF','GHI']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 1)\n",
    "\n",
    "print(pept_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a library\n",
    "\n",
    "To wrap everything up, we employ two functions `generate_library` and `generate_spectra`. The first one reads a FASTA file and generates a list of peptides, as well as the peptide dictionary and an ordered FASTA dictionary to be able to look up the protein indices laster. For the `callback` we first read the whole FASTA file to determine the total number of entries in the FASTA file.  For a typical FASTA file of 30 Mb with 40k entries, this should take less than a second. The progress of the digestion is monitored by processing the FASTA file one by one.\n",
    "The function `generate_spectra` then calculates precursor masses and fragment ions. Here, we split the total_number of sequences in `1000` steps to be able to track progress with the `callback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generate_library(mass_dict, fasta_path, callback = None, contaminants_path = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "    to_add = List()\n",
    "    fasta_dict = OrderedDict()\n",
    "    fasta_index = 0\n",
    "\n",
    "    pept_dict = {}\n",
    "    \n",
    "    if type(fasta_path) is str:\n",
    "        fasta_path = [fasta_path]\n",
    "        n_fastas = 1\n",
    "        \n",
    "    elif type(fasta_path) is list:\n",
    "        n_fastas = len(fasta_path)\n",
    "    \n",
    "    for f_id, fasta_file in enumerate(fasta_path):\n",
    "        n_entries = read_fasta_file_entries(fasta_file)\n",
    "\n",
    "        fasta_generator = read_fasta(fasta_file)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            if check_sequence(element, constants.AAs):\n",
    "                fasta_dict[fasta_index] = element\n",
    "                mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "                pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "                if len(added_seqs) > 0:\n",
    "                    to_add.extend(added_seqs)\n",
    "\n",
    "            fasta_index += 1\n",
    "\n",
    "            if callback:\n",
    "                callback(fasta_index/n_entries/n_fastas+f_id)\n",
    "            \n",
    "    if contaminants_path:\n",
    "        fasta_generator = read_fasta(contaminants_path)\n",
    "\n",
    "        for element in fasta_generator:\n",
    "            if check_sequence(element, constants.AAs):\n",
    "                fasta_dict[fasta_index] = element\n",
    "                mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "                pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "                if len(added_seqs) > 0:\n",
    "                    to_add.extend(added_seqs)\n",
    "\n",
    "            fasta_index += 1\n",
    "        \n",
    "    return to_add, pept_dict, fasta_dict\n",
    "\n",
    "\n",
    "def generate_spectra(to_add, mass_dict, callback = None):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "\n",
    "    if len(to_add) > 0:\n",
    "\n",
    "        if callback: #Chunk the spectra to get a progress_bar\n",
    "            spectra = []\n",
    "\n",
    "            stepsize = int(np.ceil(len(to_add)/1000))\n",
    "\n",
    "            for i in range(0, len(to_add), stepsize):\n",
    "                sub = to_add[i:i + stepsize]\n",
    "                spectra.extend(get_spectra(sub, mass_dict))\n",
    "                callback((i+1)/len(to_add))\n",
    "\n",
    "        else:\n",
    "            spectra = get_spectra(to_add, mass_dict)\n",
    "    else:\n",
    "        raise ValueError(\"No spectra to generate.\")\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "To save the generated spectra, we rely on NumPy's NPZ format. For this we create a dictionary and save all the generated elements. The container will contain the following elements:\n",
    "\n",
    "* `precursors`: An array containing the precursor masses\n",
    "* `seqs`: An array containing the peptide sequences for the precursor masses\n",
    "* `pept_dict`: A peptide dictionary to look up the peptides and return their FASTA index\n",
    "* `fasta_dict`: A fasta dictionary to look up the FASTA entry based on a pept_dict index\n",
    "* `fragmasses`: An array containing the fragment masses. Unoccupied cells are filled with -1\n",
    "* `fragtypes:`: An array containg the fragment types. 0 equals b-ions and 1 equals y-ions. Unoccupied cells are filled with -1\n",
    "* `bounds`: An integer array containing the upper bounds for the fragment masses / types array. This is needed to quickly slice the data.\n",
    "\n",
    "All arrays are sorted according to the precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept.io import list_to_numpy_f32\n",
    "\n",
    "\n",
    "def save_library(spectra, pept_dict, fasta_dict, library_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to save a library to the *.npz format.\n",
    "    \"\"\"\n",
    "\n",
    "    precmasses, seqs, fragmasses, fragtypes = zip(*spectra)\n",
    "    sortindex = np.argsort(precmasses)\n",
    "\n",
    "    to_save = {}\n",
    "\n",
    "    to_save[\"precursors\"] = np.array(precmasses)[sortindex]\n",
    "    to_save[\"seqs\"] = np.array(seqs)[sortindex]\n",
    "    to_save[\"pept_dict\"] = pept_dict\n",
    "    to_save[\"fasta_dict\"] = fasta_dict\n",
    "    to_save[\"fragmasses\"] = list_to_numpy_f32(np.array(fragmasses)[sortindex])\n",
    "    to_save[\"fragtypes\"] = list_to_numpy_f32(np.array(fragtypes)[sortindex])\n",
    "\n",
    "    to_save[\"bounds\"] = np.sum(to_save['fragmasses']>=0,axis=0).astype(np.int64)\n",
    "\n",
    "    np.savez(library_path, **to_save)\n",
    "\n",
    "    return library_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_settings.ipynb.\n",
      "Converted 12_runner.ipynb.\n",
      "Converted FF_parallel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
