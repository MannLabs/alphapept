{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65c3c1-7119-4740-9e19-7354eb68118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1960d0-a701-4bb4-925b-bf3c044908e7",
   "metadata": {},
   "source": [
    "# Display\n",
    "\n",
    "> A collection of functions to do label-based quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fc945-2ecc-41f4-8791-1be3b3cd14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5df6c2",
   "metadata": {},
   "source": [
    "## Label search\n",
    "\n",
    "The label search is implemented based on the compare_frags from the search. \n",
    "We have a fixed number of reporter channels and check if we find a respective peak within the search tolerance.\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "- [IsobaricAnalyzer](https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/TOPP_IsobaricAnalyzer.html)\n",
    "\n",
    "- [TMT Talk from Hupo 2015](https://assets.thermofisher.com/TFS-Assets/CMD/Reference-Materials/PP-TMT-Multiplexed-Protein-Quantification-HUPO2015-EN.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d188bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from alphapept.search import compare_frags\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def label_search(query_frag: np.ndarray, query_int: np.ndarray, label: np.ndarray, reporter_frag_tol:float, ppm:bool)-> (np.ndarray, np.ndarray):\n",
    "    \"\"\"Function to search for a label for a given spectrum.\n",
    "\n",
    "    Args:\n",
    "        query_frag (np.ndarray): Array with query fragments.\n",
    "        query_int (np.ndarray): Array with query intensities.\n",
    "        label (np.ndarray): Array with label masses.\n",
    "        reporter_frag_tol (float): Fragment tolerance for search.\n",
    "        ppm (bool): Flag to use ppm instead of Dalton.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array with intensities for the respective label channel. \n",
    "        np.ndarray: Array with offset masses.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    report = np.zeros(len(label))\n",
    "    off_mass = np.zeros_like(label)\n",
    "    \n",
    "    hits = compare_frags(query_frag, label, reporter_frag_tol, ppm)\n",
    "    for idx, _ in enumerate(hits):\n",
    "        if _ > 0:\n",
    "            report[idx] = query_int[_-1]\n",
    "            off_mass[idx] = query_frag[_-1] - label[idx]\n",
    "\n",
    "            if ppm:\n",
    "                off_mass[idx] = off_mass[idx] / (query_frag[_-1] + label[idx]) *2 * 1e6\n",
    "                    \n",
    "    return report, off_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84339045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_label_search():\n",
    "    query_frag = np.array([1,2,3,4,5])\n",
    "    query_int = np.array([1,2,3,4,5])\n",
    "    label = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "    frag_tolerance = 0.1\n",
    "    ppm= False\n",
    "\n",
    "    assert np.allclose(label_search(query_frag, query_int, label, frag_tolerance, ppm)[0], query_int)\n",
    "\n",
    "    query_frag = np.array([1,2,3,4,6])\n",
    "    query_int = np.array([1,2,3,4,5])\n",
    "\n",
    "    assert np.allclose(label_search(query_frag, query_int, label, frag_tolerance, ppm)[0], np.array([1,2,3,4,0]))\n",
    "    \n",
    "    query_frag = np.array([1,2,3,4,6])\n",
    "    query_int = np.array([5,4,3,2,1])\n",
    "\n",
    "    assert np.allclose(label_search(query_frag, query_int, label, frag_tolerance, ppm)[0], np.array([5,4,3,2,0]))\n",
    "    \n",
    "    query_frag = np.array([1.1, 2.2, 3.3, 4.4, 6.6])\n",
    "    query_int = np.array([1,2,3,4,5])\n",
    "    \n",
    "    frag_tolerance = 0.5\n",
    "    ppm= False\n",
    "    \n",
    "    assert np.allclose(label_search(query_frag, query_int, label, frag_tolerance, ppm)[1], np.array([0.1, 0.2, 0.3, 0.4, 0.0]))\n",
    "    \n",
    "test_label_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d73210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported intensities [100. 200. 300.   0.], Offset [0.  0.  0.1 0. ]\n"
     ]
    }
   ],
   "source": [
    "#Example usage\n",
    "\n",
    "query_frag = np.array([127, 128, 129.1, 132])\n",
    "query_int = np.array([100, 200, 300, 400, 500])\n",
    "\n",
    "label = np.array([127.0, 128.0, 129.0, 130.0])\n",
    "\n",
    "frag_tolerance = 0.1\n",
    "ppm = False\n",
    "\n",
    "report, offset = label_search(query_frag, query_int, label, frag_tolerance, ppm)\n",
    "\n",
    "print(f'Reported intensities {report}, Offset {offset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3ceee-86c1-4e35-a5cd-8df42cb259e4",
   "metadata": {},
   "source": [
    "## MS2 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d692a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from typing import NamedTuple\n",
    "import alphapept.io\n",
    "\n",
    "def search_label_on_ms_file(file_name:str, label:NamedTuple, reporter_frag_tol:float, ppm:bool):\n",
    "    \"\"\"Wrapper function to search labels on an ms_file and write results to the peptide_fdr of the file.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): Path to ms_file:\n",
    "        label (NamedTuple): Label with channels, mod_name and masses.\n",
    "        reporter_frag_tol (float): Fragment tolerance for search.\n",
    "        ppm (bool): Flag to use ppm instead of Dalton.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ms_file = alphapept.io.MS_Data_File(file_name, is_read_only = False)\n",
    "    \n",
    "    df = ms_file.read(dataset_name='peptide_fdr')\n",
    "    label_intensities = np.zeros((len(df), len(label.channels)))\n",
    "    off_masses = np.zeros((len(df), len(label.channels)))\n",
    "    labeled = df['sequence'].str.startswith(label.mod_name).values\n",
    "    query_data = ms_file.read_DDA_query_data()\n",
    "\n",
    "    query_indices = query_data[\"indices_ms2\"]\n",
    "    query_frags = query_data['mass_list_ms2']\n",
    "    query_ints = query_data['int_list_ms2']\n",
    "\n",
    "    for idx, query_idx in enumerate(df['raw_idx']):\n",
    "\n",
    "        query_idx_start = query_indices[query_idx]\n",
    "        query_idx_end = query_indices[query_idx + 1]\n",
    "        query_frag = query_frags[query_idx_start:query_idx_end]\n",
    "        query_int = query_ints[query_idx_start:query_idx_end]\n",
    "\n",
    "        query_frag_idx = query_frag < label.masses[-1]+1\n",
    "        query_frag = query_frag[query_frag_idx]\n",
    "        query_int = query_int[query_frag_idx]\n",
    "\n",
    "        if labeled[idx]:\n",
    "            label_int, off_mass = label_search(query_frag, query_int, label.masses, reporter_frag_tol, ppm)\n",
    "            label_intensities[idx, :] = label_int\n",
    "            off_masses[idx, :] = off_mass\n",
    "            \n",
    "    df[label.channels] = label_intensities\n",
    "    df[[_+'_off_ppm' for _ in label.channels]] = off_masses\n",
    "    \n",
    "    ms_file.write(df, dataset_name=\"peptide_fdr\", overwrite=True) #Overwrite dataframe with label information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a099dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from alphapept.constants import label_dict\n",
    "\n",
    "def find_labels(\n",
    "    to_process: dict,\n",
    "    callback: callable = None,\n",
    "    parallel:bool = False\n",
    ") -> bool:\n",
    "    \"\"\"Wrapper function to search for labels.\n",
    "\n",
    "    Args:\n",
    "        to_process (dict): A dictionary with settings indicating which files are to be processed and how.\n",
    "        callback (callable): A function that accepts a float between 0 and 1 as progress. Defaults to None.\n",
    "        parallel (bool): If True, process multiple files in parallel.\n",
    "            This is not implemented yet!\n",
    "            Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if and only if the label finding was succesful.\n",
    "\n",
    "    \"\"\"\n",
    "    index, settings = to_process\n",
    "    raw_file = settings['experiment']['file_paths'][index]\n",
    "    try:\n",
    "        base, ext = os.path.splitext(raw_file)\n",
    "        file_name = base+'.ms_data.hdf'\n",
    "        label = label_dict[settings['isobaric_label']['label']]\n",
    "        \n",
    "        reporter_frag_tol = settings['isobaric_label']['reporter_frag_tolerance']\n",
    "        ppm = settings['isobaric_label']['reporter_frag_tolerance_ppm']\n",
    "        \n",
    "        search_label_on_ms_file(file_name, label, reporter_frag_tol, ppm)\n",
    "        \n",
    "        logging.info(f'Tag finding of file {file_name} complete.')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f'Tag finding of file {file_name} failed. Exception {e}')\n",
    "        return f\"{e}\" #Can't return exception object, cast as string\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c0e52-44f0-4038-91fb-f13869e62144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_interface.ipynb.\n",
      "Converted 12_performance.ipynb.\n",
      "Converted 13_export.ipynb.\n",
      "Converted 14_display.ipynb.\n",
      "Converted 15_label.ipynb.\n",
      "Converted additional_code.ipynb.\n",
      "Converted contributing.ipynb.\n",
      "Converted file_formats.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted minimal_stuff.ipynb.\n",
      "Converted Untitled.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
