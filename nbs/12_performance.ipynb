{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b389571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1ce2c",
   "metadata": {},
   "source": [
    "# Performance\n",
    "\n",
    "> Paralellization for GPU and CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb161c2e",
   "metadata": {},
   "source": [
    "AlphaPept deals with high-throughput data. As this can be computationally intensive, we try to make all functions as performant as possible. To do so, we rely on two principles:\n",
    "* **Compilation**\n",
    "* **Parallelization**\n",
    "\n",
    "A first step of **compilation** can be achieved by using NumPy arrays which are already heavily c-optimized. Net we consider three kinds of compilation:\n",
    "* **Python** This allows to use no compilation\n",
    "* **Numba** This allows to use just-in-time (JIT) compilation.\n",
    "* **Cuda** This allows compilation on the GPU.\n",
    "\n",
    "All of these compilation approaches can be combined with **parallelization** approaches. We consider the following possibilities:\n",
    "* **No parallelization** Not all functionality can be parallelized.\n",
    "* **Multithreading** This is only performant when Python's global interpreter lock (GIL) is released or when mostly using input-/output (IO) functions.\n",
    "* **GPU** This is only available if an NVIDIA GPU is available and properly configured.\n",
    "\n",
    "Note that not all compilation approaches can sensibly be combined with all parallelization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b133da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "COMPILATION_MODE_OPTIONS = [\n",
    "    \"python\",\n",
    "    \"python-multithread\",\n",
    "    \"numba\",\n",
    "    \"numba-multithread\",\n",
    "    \"cuda\", # Cuda is always multithreaded\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f52608",
   "metadata": {},
   "source": [
    "Next we import all libraries, taking into account that not every machine has a GPU (with NVidia cuda cores) available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0474545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import psutil\n",
    "import ast\n",
    "\n",
    "# Parallelization\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "# Compilation\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "try:\n",
    "    import cupy\n",
    "    cuda.get_current_device()\n",
    "    __GPU_AVAILABLE = True\n",
    "except ModuleNotFoundError:\n",
    "    __GPU_AVAILABLE = False\n",
    "    cupy = None\n",
    "    logging.info(\"Cupy is not available\")\n",
    "except cuda.CudaSupportError:\n",
    "    __GPU_AVAILABLE = False\n",
    "    logging.info(\"Cuda device is not available\")\n",
    "\n",
    "def is_valid_compilation_mode(compilation_mode: str) -> None:\n",
    "    \"\"\"Check if the provided string is a valid compilation mode.\n",
    "\n",
    "    Args:\n",
    "        compilation_mode (str): The compilation mode to verify.\n",
    "\n",
    "    Raises:\n",
    "        ModuleNotFoundError: When trying to use an unavailable GPU.\n",
    "        NotImplementedError: When the compilation mode is not valid.\n",
    "\n",
    "    \"\"\"\n",
    "    if compilation_mode.startswith(\"cuda\") and not __GPU_AVAILABLE:\n",
    "        raise ModuleNotFoundError('Cuda functions are not available.')\n",
    "    if compilation_mode not in COMPILATION_MODE_OPTIONS:\n",
    "        raise NotImplementedError(\n",
    "            f\"Compilation mode '{compilation_mode}' is not available, \"\n",
    "            \"see COMPILATION_MODE_OPTIONS for available options.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792fc6b",
   "metadata": {},
   "source": [
    "By default, we will use `cuda` if it is available. If not, `numba-multithread` will be used as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab19525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "if __GPU_AVAILABLE:\n",
    "    COMPILATION_MODE = \"cuda\"\n",
    "else:\n",
    "    COMPILATION_MODE = \"numba-multithread\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a66302",
   "metadata": {},
   "source": [
    "To consistently use multiple threads or processes, we can set a global MAX_WORKER_COUNT parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2374af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "MAX_WORKER_COUNT = psutil.cpu_count()\n",
    "\n",
    "def set_worker_count(worker_count: int = 1, set_global: bool = True) -> int:\n",
    "    \"\"\"Parse and set the (global) number of threads.\n",
    "\n",
    "    Args:\n",
    "        worker_count (int): The number of workers.\n",
    "            If larger than available cores, it is trimmed to the available maximum.\n",
    "            If 0, it is set to the maximum cores available.\n",
    "            If negative, it indicates how many cores NOT to use.\n",
    "            Default is 1\n",
    "        set_global (bool): If False, the number of workers is only parsed to a valid value.\n",
    "            If True, the number of workers is saved as a global variable.\n",
    "            Default is True.\n",
    "\n",
    "    Returns:\n",
    "        int: The parsed worker_count.\n",
    "\n",
    "    \"\"\"\n",
    "    max_cpu_count = psutil.cpu_count()\n",
    "    if worker_count > max_cpu_count:\n",
    "        worker_count = max_cpu_count\n",
    "    else:\n",
    "        while worker_count <= 0:\n",
    "            worker_count += max_cpu_count\n",
    "    if set_global:\n",
    "        global MAX_WORKER_COUNT\n",
    "        MAX_WORKER_COUNT = worker_count\n",
    "    return worker_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaba8aa",
   "metadata": {},
   "source": [
    "Compiled functions are intended to be very fast. However, they do not have the same flexibility as pure Python functions. In general, we recommend to use staticly defined compilation functions for optimal performance. We provide the option to define a default compilation mode for decorated functions, while also allowing to define the compilation mode for each individual function.\n",
    "\n",
    "**NOTE**: Compiled functions are by default expected to be performed on a single thread. Thus, 'cuda' funtions are always assumed to be device functions which makes them callable from within the GPU, unless explicitly stated otherwise. Similarly, 'numba' functions are always assumed to bo 'nopython' and 'nogil'.\n",
    "\n",
    "**NOTE** If the global compilation mode is set to Python, all decorators default to python, even if a specific compilation_mode is provided.\n",
    "\n",
    "In addition, we allow to enable dynamic compilation, meaning the compilation mode of functions can be changed at runtime. Do note that this comes at the cost of some performance, as compilation needs to be done at runtime as well. Moreover, functions that are defined with dynamic compilation can not be called from within other compiled functions (with the exception of 'python' compilation, which means no compilation is actually performe|d).\n",
    "\n",
    "**NOTE**: Dynamic compilation must be enabled before functions are decorated to take effect at runtime, otherwise they are statically compiled with the current settings at the time they are defined! Alternatively, statically compiled functions of a an 'imported_module' can reloaded (and thus statically be recompiled) with the commands:\n",
    "```\n",
    "import importlib\n",
    "importlib.reload(imported_module)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88f3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "DYNAMIC_COMPILATION_ENABLED = False\n",
    "\n",
    "def set_compilation_mode(\n",
    "    compilation_mode: str = None,\n",
    "    enable_dynamic_compilation: bool = None,\n",
    ") -> None:\n",
    "    \"\"\"Set the global compilation mode to use.\n",
    "\n",
    "    Args:\n",
    "        compilation_mode (str): The compilation mode to use.\n",
    "            Will be checked with `is_valid_compilation_mode`.\n",
    "            Default is None\n",
    "        enable_dynamic_compilation (bool): Enable dynamic compilation.\n",
    "            If enabled, code will generally be slower and no other functions can\n",
    "            be called from within a compiled function anymore, as they are compiled at runtime.\n",
    "            WARNING: Enabling this is strongly disadvised in almost all cases!\n",
    "            Default is None.\n",
    "\n",
    "    \"\"\"\n",
    "    if enable_dynamic_compilation is not None:\n",
    "        global DYNAMIC_COMPILATION_ENABLED\n",
    "        DYNAMIC_COMPILATION_ENABLED = enable_dynamic_compilation\n",
    "    if compilation_mode is not None:\n",
    "        is_valid_compilation_mode(compilation_mode)\n",
    "        global COMPILATION_MODE\n",
    "        COMPILATION_MODE = compilation_mode\n",
    "\n",
    "\n",
    "def compile_function(\n",
    "    _func: callable = None,\n",
    "    *,\n",
    "    compilation_mode: str = None,\n",
    "    **decorator_kwargs,\n",
    ") -> callable:\n",
    "    \"\"\"A decorator to compile a given function.\n",
    "\n",
    "    Numba functions are by default set to use `nogil=True` and `nopython=True`,\n",
    "    unless explicitly defined otherwise.\n",
    "    Cuda functions are by default set to use `device=True`,\n",
    "    unless explicitly defined otherwise..\n",
    "\n",
    "    Args:\n",
    "        compilation_mode (str): The compilation mode to use.\n",
    "            Will be checked with `is_valid_compilation_mode`.\n",
    "            If None, the global COMPILATION_MODE will be used as soon as the function is decorated for static compilation.\n",
    "            If DYNAMIC_COMPILATION_ENABLED, the function will always be compiled at runtime and\n",
    "            thus by default returns a Python function.\n",
    "            Static recompilation can be enforced by reimporting a module containing\n",
    "            the function with importlib.reload(imported_module).\n",
    "            If COMPILATION_MODE is Python and not DYNAMIC_COMPILATION_ENABLED, no compilation will be used.\n",
    "            Default is None\n",
    "        **decorator_kwargs: Keyword arguments that will be passed to numba.jit or cuda.jit compilation decorators.\n",
    "\n",
    "    Returns:\n",
    "        callable: A decorated function that is compiled.\n",
    "\n",
    "    \"\"\"\n",
    "    if compilation_mode is None:\n",
    "        if DYNAMIC_COMPILATION_ENABLED:\n",
    "            compilation_mode = \"dynamic\"\n",
    "        else:\n",
    "            compilation_mode = COMPILATION_MODE\n",
    "    elif COMPILATION_MODE.startswith(\"python\"):\n",
    "        compilation_mode = \"python\"\n",
    "    else:\n",
    "        is_valid_compilation_mode(compilation_mode)\n",
    "    def parse_compilation(current_compilation_mode, func):\n",
    "        if current_compilation_mode.startswith(\"python\"):\n",
    "            compiled_function = __copy_func(func)\n",
    "        elif current_compilation_mode.startswith(\"numba\"):\n",
    "            if \"nogil\" in decorator_kwargs:\n",
    "                if \"nopython\" in decorator_kwargs:\n",
    "                    compiled_function = numba.jit(func, **decorator_kwargs)\n",
    "                else:\n",
    "                    compiled_function = numba.jit(func, **decorator_kwargs, nopython=True)\n",
    "            elif \"nopython\" in decorator_kwargs:\n",
    "                compiled_function = numba.jit(func, **decorator_kwargs, nogil=True)\n",
    "            else:\n",
    "                compiled_function = numba.jit(func, **decorator_kwargs, nogil=True, nopython=True)\n",
    "        elif current_compilation_mode.startswith(\"cuda\"):\n",
    "            if \"device\" in decorator_kwargs:\n",
    "                compiled_function = cuda.jit(func, **decorator_kwargs)\n",
    "            else:\n",
    "                compiled_function = cuda.jit(func, **decorator_kwargs, device=True)\n",
    "        return compiled_function\n",
    "    def decorated_function(func):\n",
    "        if compilation_mode != \"dynamic\":\n",
    "            is_valid_compilation_mode(compilation_mode)\n",
    "            static_compiled_function = parse_compilation(compilation_mode, func)\n",
    "            return functools.wraps(func)(static_compiled_function)\n",
    "        else:\n",
    "            def dynamic_compiled_function(*func_args, **func_kwargs):\n",
    "                compiled_function = parse_compilation(COMPILATION_MODE, func)\n",
    "                return compiled_function(*func_args, **func_kwargs)\n",
    "            return functools.wraps(func)(dynamic_compiled_function)\n",
    "    if _func is None:\n",
    "        return decorated_function\n",
    "    else:\n",
    "        return decorated_function(_func)\n",
    "\n",
    "\n",
    "import types\n",
    "import functools\n",
    "\n",
    "def __copy_func(f):\n",
    "    \"\"\"Based on http://stackoverflow.com/a/6528148/190597 (Glenn Maynard)\"\"\"\n",
    "    g = types.FunctionType(f.__code__, f.__globals__, name=f.__name__,\n",
    "                           argdefs=f.__defaults__,\n",
    "                           closure=f.__closure__)\n",
    "    g = functools.update_wrapper(g, f)\n",
    "    g.__kwdefaults__ = f.__kwdefaults__\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23400b44",
   "metadata": {},
   "source": [
    "Testing yields the expected results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336d8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"numba-multithread\")\n",
    "\n",
    "@compile_function(compilation_mode=\"python\")\n",
    "def test_func_python(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "    \n",
    "@compile_function(compilation_mode=\"numba\")\n",
    "def test_func_numba(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "set_compilation_mode(enable_dynamic_compilation=True)\n",
    "\n",
    "@compile_function\n",
    "def test_func_dynamic_runtime(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "set_compilation_mode(enable_dynamic_compilation=False, compilation_mode=\"numba-multithread\")\n",
    "\n",
    "@compile_function\n",
    "def test_func_static_runtime_numba(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "a = np.zeros(1, dtype=np.int64)\n",
    "assert(isinstance(test_func_python, types.FunctionType))\n",
    "test_func_python(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_numba, numba.core.registry.CPUDispatcher))\n",
    "test_func_numba(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "if __GPU_AVAILABLE:\n",
    "    @compile_function(compilation_mode=\"cuda\", device=None)\n",
    "    def test_func_cuda(x):\n",
    "        \"\"\"Docstring test\"\"\"\n",
    "        x[0] += 1\n",
    "\n",
    "    # Cuda function cannot be tested from outside the GPU\n",
    "    a = np.zeros(1)\n",
    "    assert(isinstance(test_func_cuda, numba.cuda.compiler.Dispatcher))\n",
    "    test_func_cuda.forall(1,1)(a)\n",
    "    assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"python\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_static_runtime_numba, numba.core.registry.CPUDispatcher))\n",
    "test_func_static_runtime_numba(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"python\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "test_func_dynamic_runtime(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"numba\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "test_func_dynamic_runtime(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "# # Cuda function cannot be tested from outside the GPU\n",
    "# set_compilation_mode(compilation_mode=\"cuda\")\n",
    "# a = np.zeros(1)\n",
    "# assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "# test_func_dynamic_runtime.forall(1,1)(a)\n",
    "# assert(np.all(a == np.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f09587",
   "metadata": {},
   "source": [
    "Next, we define the 'performance_function' decorator to take full advantage of both compilation and parallelization for maximal performance. Note that a 'performance_function' can not return values. Instead, it should store results in provided buffer arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf25b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def performance_function(\n",
    "    _func: callable = None,\n",
    "    *,\n",
    "    worker_count: int = None,\n",
    "    compilation_mode: str = None,\n",
    "    **decorator_kwargs,\n",
    ") -> callable:\n",
    "    \"\"\"A decorator to compile a given function and allow multithreading over an multiple indices.\n",
    "\n",
    "    NOTE This should only be used on functions that are compilable.\n",
    "    Functions that need to be decorated need to have an `index` argument as first argument.\n",
    "    If an iterable is provided to the decorated function,\n",
    "    the original (compiled) function will be applied to all elements of this iterable.\n",
    "    The most efficient way to provide iterables are with ranges, but numpy arrays work as well.\n",
    "    Functions can not return values,\n",
    "    results should be stored in buffer arrays inside thge function instead.\n",
    "\n",
    "    Args:\n",
    "        worker_count (int): The number of workers to use for multithreading.\n",
    "            If None, the global MAX_WORKER_COUNT is used at runtime.\n",
    "            Default is None.\n",
    "        compilation_mode (str): The compilation mode to use. Will be forwarded to the `compile_function` decorator.\n",
    "        **decorator_kwargs: Keyword arguments that will be passed to numba.jit or cuda.jit compilation decorators.\n",
    "\n",
    "    Returns:\n",
    "        callable: A decorated function that is compiled and parallelized.\n",
    "\n",
    "    \"\"\"\n",
    "    if worker_count is not None:\n",
    "        worker_count = set_worker_count(worker_count, set_global=False)\n",
    "    if compilation_mode is None:\n",
    "        if DYNAMIC_COMPILATION_ENABLED:\n",
    "            compilation_mode = \"dynamic\"\n",
    "        else:\n",
    "            compilation_mode = COMPILATION_MODE\n",
    "    elif COMPILATION_MODE.startswith(\"python\"):\n",
    "        compilation_mode = \"python\"\n",
    "    else:\n",
    "        is_valid_compilation_mode(compilation_mode)\n",
    "    def _decorated_function(func):\n",
    "        if compilation_mode != \"dynamic\":\n",
    "            compiled_function = compile_function(\n",
    "                func,\n",
    "                compilation_mode=compilation_mode,\n",
    "                **decorator_kwargs\n",
    "            )\n",
    "        def _parallel_python(\n",
    "            compiled_function,\n",
    "            iterable,\n",
    "            start,\n",
    "            stop,\n",
    "            step,\n",
    "            *func_args\n",
    "        ):\n",
    "            if start != -1:\n",
    "                for index in range(start, stop, step):\n",
    "                    compiled_function(index, *func_args)\n",
    "            else:\n",
    "                for index in iterable:\n",
    "                    compiled_function(index, *func_args)\n",
    "        _parallel_numba = numba.njit(nogil=True)(_parallel_python)\n",
    "        def _parallel_cuda(compiled_function, iterable, *func_args):\n",
    "            cuda_func_dict = {\"cuda\": cuda, \"compiled_function\": compiled_function}\n",
    "            # Cuda functions cannot handle tuple unpacking but need a fixed number of arguments.\n",
    "            if isinstance(iterable, range):\n",
    "                func_string = \", \".join(f\"arg{i}\" for i in range(len(func_args) + 3))\n",
    "                cuda_string = (\n",
    "                    f\"@cuda.jit\\n\"\n",
    "                    f\"def cuda_func({func_string}):\\n\"\n",
    "                    f\"    index = arg0 + arg2 * cuda.grid(1)\\n\"\n",
    "                    f\"    compiled_function(index, {func_string[18:]})\\n\"\n",
    "                )\n",
    "                exec(cuda_string, cuda_func_dict)\n",
    "                cuda_func_dict[\"cuda_func\"].forall(len(iterable), 1)(\n",
    "                    iterable.start,\n",
    "                    iterable.stop,\n",
    "                    iterable.step,\n",
    "                    *func_args\n",
    "                )\n",
    "            else:\n",
    "                func_string = \", \".join(f\"arg{i}\" for i in range(len(func_args) + 1))\n",
    "                cuda_string = (\n",
    "                    f\"@cuda.jit\\n\"\n",
    "                    f\"def cuda_func({func_string}):\\n\"\n",
    "                    f\"    index = arg0[cuda.grid(1)]\\n\"\n",
    "                    f\"    compiled_function(index, {func_string[6:]})\\n\"\n",
    "                )\n",
    "                exec(cuda_string, cuda_func_dict)\n",
    "                cuda_func_dict[\"cuda_func\"].forall(len(iterable), 1)(iterable, *func_args)\n",
    "        def _performance_function(iterable, *func_args):\n",
    "            if compilation_mode == \"dynamic\":\n",
    "                selected_compilation_mode = COMPILATION_MODE\n",
    "                _compiled_function = compile_function(\n",
    "                    func,\n",
    "                    compilation_mode=selected_compilation_mode,\n",
    "                    **decorator_kwargs\n",
    "                )\n",
    "            else:\n",
    "                _compiled_function = compiled_function\n",
    "                selected_compilation_mode = compilation_mode\n",
    "            try:\n",
    "                iter(iterable)\n",
    "            except TypeError:\n",
    "                iterable = np.array([iterable])\n",
    "            if worker_count is None:\n",
    "                selected_worker_count = MAX_WORKER_COUNT\n",
    "            else:\n",
    "                selected_worker_count = worker_count\n",
    "            if selected_compilation_mode == \"cuda\":\n",
    "                _parallel_cuda(_compiled_function, iterable, *func_args)\n",
    "            else:\n",
    "                if \"python\" in selected_compilation_mode:\n",
    "                    parallel_function = _parallel_python\n",
    "                elif \"numba\" in selected_compilation_mode:\n",
    "                    parallel_function = _parallel_numba\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        f\"Compilation mode {selected_compilation_mode} is not valid. \"\n",
    "                        \"This error should not be possible, something is seriously wrong!!!\"\n",
    "                    )\n",
    "                if (selected_compilation_mode in [\"python\", \"numba\"]) or (selected_worker_count == 1):\n",
    "                    iterable_is_range = isinstance(iterable, range)\n",
    "                    x = np.empty(0, dtype=np.int64) if iterable_is_range else iterable\n",
    "                    parallel_function(\n",
    "                        _compiled_function,\n",
    "                        np.empty(0, dtype=np.int64) if iterable_is_range else iterable,\n",
    "                        iterable.start if iterable_is_range else -1,\n",
    "                        iterable.stop if iterable_is_range else -1,\n",
    "                        iterable.step if iterable_is_range else -1,\n",
    "                        *func_args\n",
    "                    )\n",
    "                else:\n",
    "                    workers = []\n",
    "                    for worker_id in range(selected_worker_count):\n",
    "                        local_iterable = iterable[worker_id::selected_worker_count]\n",
    "                        iterable_is_range = isinstance(local_iterable, range)\n",
    "                        worker = threading.Thread(\n",
    "                            target=parallel_function,\n",
    "                            args=(\n",
    "                                _compiled_function,\n",
    "                                np.empty(0, dtype=np.int64) if iterable_is_range else local_iterable,\n",
    "                                local_iterable.start if iterable_is_range else -1,\n",
    "                                local_iterable.stop if iterable_is_range else -1,\n",
    "                                local_iterable.step if iterable_is_range else -1,\n",
    "                                *func_args\n",
    "                            )\n",
    "                        )\n",
    "                        worker.start()\n",
    "                        workers.append(worker)\n",
    "                    for worker in workers:\n",
    "                        worker.join()\n",
    "                        del worker\n",
    "        return functools.wraps(func)(_performance_function)\n",
    "    if _func is None:\n",
    "        return _decorated_function\n",
    "    else:\n",
    "        return _decorated_function(_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1faf67",
   "metadata": {},
   "source": [
    "We test this function with a simple smoothing algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b12ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.55 s\n",
      "Wall time: 2.54 s\n",
      "CPU times: total: 7.47 s\n",
      "Wall time: 7.49 s\n",
      "CPU times: total: 11 s\n",
      "Wall time: 887 ms\n"
     ]
    }
   ],
   "source": [
    "def smooth_func(index, in_array, out_array, window_size):\n",
    "    min_index = max(index - window_size, 0)\n",
    "    max_index = min(index + window_size + 1, len(in_array))\n",
    "    smooth_value = 0\n",
    "    for i in range(min_index, max_index):\n",
    "        smooth_value += in_array[i]\n",
    "    out_array[index] += smooth_value / (max_index - min_index)\n",
    "\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"numba-multithread\")\n",
    "set_worker_count(0)\n",
    "array_size = 10**6\n",
    "smooth_factor = 10**4\n",
    "\n",
    "# python test\n",
    "in_array = np.arange(array_size)\n",
    "out_array = np.zeros_like(in_array)\n",
    "\n",
    "func = performance_function(compilation_mode=\"python\")(smooth_func)\n",
    "%time func(range(in_array[::100].shape[0]), in_array[::100], out_array[::100], smooth_factor//10) #too slow to test otherwise\n",
    "\n",
    "# numba test\n",
    "in_array = np.arange(array_size)\n",
    "out_array = np.zeros_like(in_array)\n",
    "\n",
    "func = performance_function(compilation_mode=\"numba\")(smooth_func)\n",
    "%time func(range(in_array.shape[0]), in_array, out_array, smooth_factor)\n",
    "\n",
    "# numba-multithread test\n",
    "in_array = np.arange(array_size)\n",
    "out_array = np.zeros_like(in_array)\n",
    "\n",
    "func = performance_function(compilation_mode=\"numba-multithread\")(smooth_func)\n",
    "%time func(range(in_array.shape[0]), in_array, out_array, smooth_factor)\n",
    "\n",
    "# cuda test\n",
    "if __GPU_AVAILABLE:\n",
    "    in_array = cupy.arange(array_size)\n",
    "    out_array = cupy.zeros_like(in_array)\n",
    "\n",
    "    func = performance_function(compilation_mode=\"cuda\")(smooth_func)\n",
    "    %time func(range(in_array.shape[0]), in_array, out_array, smooth_factor)\n",
    "    %time tmp = out_array.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830db25d",
   "metadata": {},
   "source": [
    "Finally, we also provide functionality to use multiprocessing instead of multithreading.\n",
    "\n",
    "**NOTE**: There are some inherent limitation with the number of processes that Python can spawn. As such, no process Pool should use more than 50 processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb95b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from multiprocessing import Pool\n",
    "\n",
    "def AlphaPool(process_count: int) -> multiprocessing.Pool:\n",
    "    \"\"\"Create a multiprocessing.Pool object.\n",
    "\n",
    "    Args:\n",
    "        process_count (int): The number of processes.\n",
    "            If larger than available cores, it is trimmed to the available maximum.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        multiprocessing.Pool: A Pool object to parallelize functions with multiple processes.\n",
    "\n",
    "    \"\"\"\n",
    "    max_processes = psutil.cpu_count()\n",
    "    new_max = min(process_count, 50, max_processes)\n",
    "    \n",
    "    if new_max == 0:\n",
    "        new_max = 1\n",
    "    logging.info(f\"AlphaPool was set to {process_count} processes. Setting max to {new_max}.\")\n",
    "\n",
    "    return Pool(new_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bb511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_interface.ipynb.\n",
      "Converted 12_performance.ipynb.\n",
      "Converted 13_export.ipynb.\n",
      "Converted 14_display.ipynb.\n",
      "Converted 15_label.ipynb.\n",
      "Converted additional_code.ipynb.\n",
      "Converted contributing.ipynb.\n",
      "Converted file_formats.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
