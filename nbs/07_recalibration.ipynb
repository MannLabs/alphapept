{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalibration\n",
    "\n",
    "> Functions related to recalibrating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains everything to perform a recalibration.\n",
    "\n",
    "Current ToDo here:\n",
    "\n",
    "- Write introduction / comment more on functions\n",
    "- Describe approach\n",
    "- Cite relevant papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from alphapept.score import score_x_tandem\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def estimate_stepsize(df, min_mz_step = 80, min_rt_step = 50, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to estimate the stepsize for recalibration\n",
    "\n",
    "    \"\"\"\n",
    "    points_rt = np.sort(df['rt'].values)[::min_rt_step]\n",
    "    points_mz = np.sort(df['mz'].values)[::min_mz_step]\n",
    "    \n",
    "    mz_step = np.round(np.mean(np.diff(points_mz))) #1 Th precision\n",
    "    rt_step = np.round(np.mean(np.diff(points_rt)), 1) #0.1 minute precision\n",
    "\n",
    "    # Minimum values are 1 Da and 0.1 minutes\n",
    "    if mz_step < 1:\n",
    "        mz_step = 1\n",
    "    if rt_step < 0.1:\n",
    "        rt_step = 0.1\n",
    "\n",
    "    return mz_step, rt_step\n",
    "\n",
    "\n",
    "def get_calibration(df, features, minimum_score = 20, outlier_std = 3, method='linear', min_mz_step=80, min_rt_step=50, callback = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Calibration\n",
    "\n",
    "    Brief description\n",
    "\n",
    "    (1) From the scored psms isolate the o_mass ppm offset. Filter for x std deviations\n",
    "    (2) Estimate a stepsize for interpolation to ensure minimum sampling\n",
    "    (3) Use points to interpolate on a grid\n",
    "    (4) Use grid to interpolate offset for features\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove outliers for calibration\n",
    "    o_mass_std = np.abs(df['o_mass_ppm'].std())\n",
    "    o_mass_mean = df['o_mass_ppm'].mean()\n",
    "\n",
    "    df_sub = df.query('score > @minimum_score and o_mass_ppm < @o_mass_mean+@outlier_std*@o_mass_std and o_mass_ppm > @o_mass_mean-@outlier_std*@o_mass_std').copy()\n",
    "    \n",
    "    if len(df_sub) > np.max([min_mz_step, min_rt_step]): #need a minimum number of points to estimate stepsize\n",
    "\n",
    "        mz_step, rt_step = estimate_stepsize(df_sub, min_mz_step, min_rt_step, **kwargs)\n",
    "\n",
    "        #Define a grid for valid interpolation\n",
    "\n",
    "        min_x = np.floor(df_sub['mz'].min())\n",
    "        max_x = np.ceil(df_sub['mz'].max())\n",
    "        step_x = mz_step\n",
    "\n",
    "        min_y = np.floor(df_sub['rt'].min())\n",
    "        max_y = np.ceil(df_sub['rt'].max())\n",
    "        step_y = rt_step\n",
    "\n",
    "        tx = np.arange(min_x, max_x, step_x) #mz\n",
    "        ty = np.arange(min_y, max_y, step_y) #rt\n",
    "\n",
    "        xx, yy = np.meshgrid(tx, ty)\n",
    "\n",
    "        f1 = griddata(df_sub[['mz','rt']].values,  df_sub['o_mass_ppm'].values, (xx, yy) , fill_value = 0, method = method, rescale=True)\n",
    "\n",
    "        f2 = griddata(np.vstack([xx.flatten(),yy.flatten()]).T, f1.flatten(), df_sub[['mz','rt']].values, fill_value=0, method = method, rescale=True)\n",
    "\n",
    "        df_sub['o_mass_ppm_offset'] = f2\n",
    "        df_sub['o_mass_ppm_calib'] = (df_sub['o_mass_ppm']-df_sub['o_mass_ppm_offset'])\n",
    "\n",
    "        #Apply to features\n",
    "\n",
    "        offset = griddata(np.vstack([xx.flatten(), yy.flatten()]).T, f1.flatten(), features[['mz_matched','rt_matched']].values, fill_value=0, method = method, rescale=True)/1e6*features['mass_matched']\n",
    "\n",
    "        features_calib = features.copy()\n",
    "        \n",
    "        if not 'mass_matched_raw' in features_calib.columns:\n",
    "            features_calib['mass_matched_raw'] = features_calib['mass_matched'].copy()\n",
    "        features_calib['mass_matched'] -= offset\n",
    "        features_calib['mass_offset'] = offset\n",
    "        \n",
    "    else:\n",
    "        features_calib = features.copy()\n",
    "        if not 'mass_matched_raw' in features_calib.columns:\n",
    "            features_calib['mass_matched_raw'] = features_calib['mass_matched'].copy()\n",
    "        features_calib['mass_matched_raw'] = features_calib['mass_matched'].copy()\n",
    "        \n",
    "        df_sub['o_mass_ppm_offset'] = 0\n",
    "        df_sub['o_mass_ppm_calib'] = (df_sub['o_mass_ppm']-df_sub['o_mass_ppm_offset'])\n",
    "\n",
    "    features_calib = features_calib.sort_values('mass_matched', ascending=True)\n",
    "    \n",
    "    o_mass_ppm_mean = df_sub['o_mass_ppm_calib'].mean()\n",
    "    o_mass_ppm_std = df_sub['o_mass_ppm_calib'].std()\n",
    "    \n",
    "    \n",
    "    if np.isnan(o_mass_ppm_std):\n",
    "        o_mass_ppm_std = 0\n",
    "\n",
    "    return features_calib, o_mass_ppm_std\n",
    "\n",
    "\n",
    "def calibrate_hdf(to_process):\n",
    "\n",
    "    path, settings = to_process\n",
    "    \n",
    "    try:\n",
    "        features = pd.read_hdf(path, 'features')\n",
    "    except KeyError:\n",
    "        features = None\n",
    "    \n",
    "    try:\n",
    "        psms = pd.read_hdf(path, 'first_search')\n",
    "    except KeyError: #no elements in search\n",
    "        psms = pd.DataFrame()\n",
    "        \n",
    "    if len(psms) > 0 :\n",
    "        df = score_x_tandem(psms, fdr_level = settings[\"search\"][\"peptide_fdr\"], plot=False, verbose=False, **settings[\"search\"])\n",
    "        features_calib, o_mass_ppm_std = get_calibration(df, features, **settings[\"calibration\"])\n",
    "        features_calib.to_hdf(path, key= 'features', append=False)\n",
    "    else: \n",
    "        o_mass_ppm_std = 0 \n",
    "        \n",
    "    return (path, o_mass_ppm_std)\n",
    "\n",
    "def calibrate_hdf_parallel(settings, callback=None):\n",
    "    \n",
    "    files_npz = settings['experiment']['files_npz']\n",
    "    \n",
    "    paths = [os.path.splitext(_)[0]+'.hdf' for _ in files_npz]\n",
    "    \n",
    "    to_process = [(_, settings) for _ in paths]\n",
    "    \n",
    "    calibration_dict = {}\n",
    "    \n",
    "    n_processes = settings['general']['n_processes']\n",
    "    \n",
    "    with Pool(n_processes) as p:\n",
    "        max_ = len(to_process)\n",
    "        for i, _ in enumerate(p.imap_unordered(calibrate_hdf, to_process)):\n",
    "            path, offset = _\n",
    "            calibration_dict[path] = float(offset)\n",
    "            if callback:\n",
    "                callback((i+1)/max_)\n",
    "\n",
    "\n",
    "    return [calibration_dict[_] for _ in paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted # Search Modes.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_settings.ipynb.\n",
      "Converted 12_runner.ipynb.\n",
      "Converted 13_parallel.ipynb.\n",
      "Converted FF_parallel.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted Large fasta Search.ipynb.\n",
      "Converted OTF, revised.ipynb.\n",
      "Converted parallel_revision.ipynb.\n",
      "Converted Sample Data Generation.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted Untitled2.ipynb.\n",
      "Converted Untitled3.ipynb.\n",
      "Converted Untitled4.ipynb.\n",
      "Converted Untitled5.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
