{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalibration\n",
    "\n",
    "> Functions related to recalibrating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains everything to perform a recalibration.\n",
    "\n",
    "Current ToDo here:\n",
    "\n",
    "- Write introduction / comment more on functions\n",
    "- Describe approach\n",
    "- Cite relevant papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from alphapept.score import score_x_tandem\n",
    "import alphapept.io\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def estimate_stepsize(df, min_mz_step = 80, min_rt_step = 50, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to estimate the stepsize for recalibration\n",
    "\n",
    "    \"\"\"\n",
    "    points_rt = np.sort(df['rt'].values)[::min_rt_step]\n",
    "    points_mz = np.sort(df['mz'].values)[::min_mz_step]\n",
    "\n",
    "    mz_step = np.round(np.mean(np.diff(points_mz))) #1 Th precision\n",
    "    rt_step = np.round(np.mean(np.diff(points_rt)), 1) #0.1 minute precision\n",
    "\n",
    "    # Minimum values are 1 Da and 0.1 minutes\n",
    "    if mz_step < 1:\n",
    "        mz_step = 1\n",
    "    if rt_step < 0.1:\n",
    "        rt_step = 0.1\n",
    "\n",
    "    return mz_step, rt_step\n",
    "\n",
    "\n",
    "def get_calibration(df, features, minimum_score = 20, outlier_std = 3, method='linear', min_mz_step=80, min_rt_step=50, callback = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Calibration\n",
    "\n",
    "    Brief description\n",
    "\n",
    "    (1) From the scored psms isolate the o_mass ppm offset. Filter for x std deviations\n",
    "    (2) Estimate a stepsize for interpolation to ensure minimum sampling\n",
    "    (3) Use points to interpolate on a grid\n",
    "    (4) Use grid to interpolate offset for features\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove outliers for calibration\n",
    "    o_mass_std = np.abs(df['o_mass_ppm'].std())\n",
    "    o_mass_mean = df['o_mass_ppm'].mean()\n",
    "\n",
    "    df_sub = df.query('score > @minimum_score and o_mass_ppm < @o_mass_mean+@outlier_std*@o_mass_std and o_mass_ppm > @o_mass_mean-@outlier_std*@o_mass_std').copy()\n",
    "\n",
    "    if len(df_sub) > np.max([min_mz_step, min_rt_step]): #need a minimum number of points to estimate stepsize\n",
    "\n",
    "        mz_step, rt_step = estimate_stepsize(df_sub, min_mz_step, min_rt_step, **kwargs)\n",
    "\n",
    "        #Define a grid for valid interpolation\n",
    "\n",
    "        min_x = np.floor(df_sub['mz'].min())\n",
    "        max_x = np.ceil(df_sub['mz'].max())\n",
    "        step_x = mz_step\n",
    "\n",
    "        min_y = np.floor(df_sub['rt'].min())\n",
    "        max_y = np.ceil(df_sub['rt'].max())\n",
    "        step_y = rt_step\n",
    "\n",
    "        tx = np.arange(min_x, max_x, step_x) #mz\n",
    "        ty = np.arange(min_y, max_y, step_y) #rt\n",
    "\n",
    "        xx, yy = np.meshgrid(tx, ty)\n",
    "\n",
    "        f1 = griddata(\n",
    "            df_sub[['mz','rt']].values,\n",
    "            df_sub['o_mass_ppm'].values,\n",
    "            (xx, yy),\n",
    "            fill_value=0,\n",
    "            method=method,\n",
    "            rescale=True\n",
    "        )\n",
    "\n",
    "        f2 = griddata(\n",
    "            np.vstack([xx.flatten(),yy.flatten()]).T,\n",
    "            f1.flatten(),\n",
    "            df_sub[['mz','rt']].values,\n",
    "            fill_value=0,\n",
    "            method=method,\n",
    "            rescale=True\n",
    "        )\n",
    "\n",
    "        df_sub['o_mass_ppm_offset'] = f2\n",
    "        df_sub['o_mass_ppm_calib'] = (df_sub['o_mass_ppm']-df_sub['o_mass_ppm_offset'])\n",
    "\n",
    "        #Apply to features\n",
    "\n",
    "        offset = griddata(\n",
    "            np.vstack([xx.flatten(), yy.flatten()]).T,\n",
    "            f1.flatten(),\n",
    "            features[['mz_matched','rt_matched']].values,\n",
    "            fill_value=0,\n",
    "            method = method,\n",
    "            rescale=True\n",
    "        ) / 1e6*features['mass_matched']\n",
    "\n",
    "    else:\n",
    "        offset = 0\n",
    "\n",
    "        df_sub['o_mass_ppm_offset'] = 0\n",
    "        df_sub['o_mass_ppm_calib'] = (df_sub['o_mass_ppm']-df_sub['o_mass_ppm_offset'])\n",
    "\n",
    "    corrected_mass = features['mass_matched'] - offset\n",
    "\n",
    "    o_mass_ppm_mean = df_sub['o_mass_ppm_calib'].mean()\n",
    "    o_mass_ppm_std = df_sub['o_mass_ppm_calib'].std()\n",
    "\n",
    "    if np.isnan(o_mass_ppm_std):\n",
    "        o_mass_ppm_std = 0\n",
    "\n",
    "    return corrected_mass, o_mass_ppm_std\n",
    "\n",
    "\n",
    "def calibrate_hdf(to_process):\n",
    "\n",
    "    # TODO Only features are calibrated, not raw MS1 signals.\n",
    "    # What if features are not present?\n",
    "    \n",
    "    path, settings = to_process\n",
    "\n",
    "    ms_file = alphapept.io.MS_Data_File(path, is_overwritable=True)\n",
    "    \n",
    "    features = ms_file.read(dataset_name='features')\n",
    "\n",
    "    try:\n",
    "        psms =  ms_file.read(dataset_name='first_search')\n",
    "    except KeyError: #no elements in search\n",
    "        psms = pd.DataFrame()\n",
    "\n",
    "    if len(psms) > 0 :\n",
    "        df = score_x_tandem(\n",
    "            psms,\n",
    "            fdr_level=settings[\"search\"][\"peptide_fdr\"],\n",
    "            plot=False,\n",
    "            verbose=False,\n",
    "            **settings[\"search\"]\n",
    "        )\n",
    "        corrected_mass, o_mass_ppm_std = get_calibration(\n",
    "            df,\n",
    "            features,\n",
    "            **settings[\"calibration\"]\n",
    "        )\n",
    "        ms_file.write(\n",
    "            corrected_mass,\n",
    "            dataset_name=\"corrected_mass\",\n",
    "            group_name=\"features\"\n",
    "        )\n",
    "    else:\n",
    "        o_mass_ppm_std = 0\n",
    "    ms_file.write(\n",
    "        o_mass_ppm_std,\n",
    "        dataset_name=\"corrected_mass\",\n",
    "        group_name=\"features\",\n",
    "        attr_name=\"estimated_max_precursor_ppm\"\n",
    "    )\n",
    "    return (path, o_mass_ppm_std)\n",
    "\n",
    "def calibrate_hdf_parallel(settings, callback=None):\n",
    "\n",
    "    ms_files = []\n",
    "\n",
    "    for _ in settings['experiment']['file_paths']:\n",
    "        base, ext = os.path.splitext(_)\n",
    "        ms_files.append(base + '.ms_data.hdf')\n",
    "\n",
    "    to_process = [(ms_file, settings) for ms_file in ms_files]\n",
    "\n",
    "    calibration_dict = {}\n",
    "\n",
    "    n_processes = settings['general']['n_processes']\n",
    "\n",
    "    with Pool(n_processes) as p:\n",
    "        max_ = len(to_process)\n",
    "        for i, _ in enumerate(p.imap_unordered(calibrate_hdf, to_process)):\n",
    "            path, offset = _\n",
    "            calibration_dict[path] = float(offset)\n",
    "            if callback:\n",
    "                callback((i+1)/max_)\n",
    "\n",
    "\n",
    "    return [calibration_dict[_]*settings['search']['calibration_std'] for _ in ms_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calbration with regards to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "import numba\n",
    "import scipy.signal\n",
    "import scipy.interpolate\n",
    "import alphapept.fasta\n",
    "\n",
    "def get_db_targets(\n",
    "    db_file_name,\n",
    "    max_ppm=100,\n",
    "    min_distance=0.5,\n",
    "    ms_level=2,\n",
    "):\n",
    "    if ms_level == 1:\n",
    "        db_mzs_ = alphapept.fasta.read_database(db_file_name, 'precursors')\n",
    "    elif ms_level == 2:\n",
    "        db_mzs_ = alphapept.fasta.read_database(db_file_name, 'fragmasses')\n",
    "    else:\n",
    "        raise ValueError(f\"{ms_level} is not a valid ms level\")\n",
    "    tmp_result = np.bincount(\n",
    "        (\n",
    "            np.log10(\n",
    "                db_mzs_[\n",
    "                    np.isfinite(db_mzs_) & (db_mzs_ > 0)\n",
    "                ].flatten()\n",
    "            ) * 10**6\n",
    "        ).astype(np.int64)\n",
    "    )\n",
    "    db_mz_distribution = np.zeros_like(tmp_result)\n",
    "    for i in range(1, max_ppm):\n",
    "        db_mz_distribution[i:] += tmp_result[:-i]\n",
    "        db_mz_distribution[:-i] += tmp_result[i:]\n",
    "    peaks = scipy.signal.find_peaks(db_mz_distribution, distance=max_ppm)[0]\n",
    "    db_targets = 10 ** (peaks / 10**6)\n",
    "#     db_vals = db_mz_distribution[peaks]\n",
    "#     plt.vlines(db_targets, 0, db_vals)\n",
    "    db_array = np.zeros(int(db_targets[-1]) + 1, dtype=np.float64)\n",
    "    last_int_mz = -1\n",
    "    last_mz = -1\n",
    "    for mz in db_targets:\n",
    "        mz_int = int(mz)\n",
    "        if (mz_int != last_int_mz) & (mz > (last_mz + min_distance)):\n",
    "            db_array[mz_int] = mz\n",
    "        else:\n",
    "            db_array[mz_int] = 0\n",
    "        last_int_mz = mz_int\n",
    "        last_mz = mz\n",
    "    return db_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def align_run_to_db(\n",
    "    ms_data_file_name,\n",
    "    db_array,\n",
    "    max_ppm_distance=1000000,\n",
    "    rt_step_size=0.1,\n",
    "    plot_ppms=False,\n",
    "    ms_level=2,\n",
    "):\n",
    "    ms_data = alphapept.io.MS_Data_File(ms_data_file_name)\n",
    "    if ms_level == 1:\n",
    "        mzs = ms_data.read(dataset_name=\"mass_matched\", group_name=\"features\")\n",
    "        rts = ms_data.read(dataset_name=\"rt_matched\", group_name=\"features\")\n",
    "    elif ms_level == 2:\n",
    "        mzs = ms_data.read(dataset_name=\"Raw/MS2_scans/mass_list_ms2\")\n",
    "        inds = ms_data.read(dataset_name=\"Raw/MS2_scans/indices_ms2\")\n",
    "        precursor_rts = ms_data.read(dataset_name=\"Raw/MS2_scans/rt_list_ms2\")\n",
    "        rts = np.repeat(precursor_rts, np.diff(inds))\n",
    "    else:\n",
    "        raise ValueError(f\"{ms_level} is not a valid ms level\")\n",
    "    \n",
    "    selected = mzs.astype(np.int64)\n",
    "    ds = np.zeros((3, len(selected)))\n",
    "    if len(db_array) < len(selected) + 1:\n",
    "        tmp = np.zeros(len(selected) + 1)\n",
    "        tmp[:len(db_array)] = db_array\n",
    "        db_array = tmp\n",
    "    ds[0] = mzs - db_array[selected - 1]\n",
    "    ds[1] = mzs - db_array[selected]\n",
    "    ds[2] = mzs - db_array[selected + 1]\n",
    "    min_ds = np.take_along_axis(\n",
    "        ds,\n",
    "        np.expand_dims(np.argmin(np.abs(ds), axis=0), axis=0),\n",
    "        axis=0\n",
    "    ).squeeze(axis=0)\n",
    "    ppm_ds = min_ds / mzs * 10**6\n",
    "\n",
    "    selected = np.abs(ppm_ds) < max_ppm_distance\n",
    "    selected &= np.isfinite(rts)\n",
    "    rt_order = np.argsort(rts)\n",
    "    rt_order = rt_order[selected[rt_order]]\n",
    "\n",
    "    \n",
    "    ordered_rt = rts[rt_order]\n",
    "    ordered_ppm = ppm_ds[rt_order]\n",
    "    \n",
    "    rt_idx_break = np.searchsorted(\n",
    "        ordered_rt,\n",
    "        np.arange(ordered_rt[0], ordered_rt[-1], rt_step_size),\n",
    "        \"left\"\n",
    "    )\n",
    "    median_ppms = np.empty(len(rt_idx_break) - 1)\n",
    "    for i in range(len(median_ppms)):\n",
    "        median_ppms[i] = np.median(\n",
    "            ordered_ppm[rt_idx_break[i]: rt_idx_break[i + 1]]\n",
    "        )\n",
    "\n",
    "    if plot_ppms:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(\n",
    "            rt_step_size + np.arange(\n",
    "                ordered_rt[0],\n",
    "                ordered_rt[-1],\n",
    "                rt_step_size\n",
    "            )[:-1],\n",
    "            median_ppms\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "    estimated_errors = scipy.interpolate.griddata(\n",
    "        rt_step_size / 2 + np.arange(\n",
    "            ordered_rt[0],\n",
    "            ordered_rt[-1] - 2 * rt_step_size,\n",
    "            rt_step_size\n",
    "        ),\n",
    "        median_ppms,\n",
    "        rts,\n",
    "        fill_value=0,\n",
    "        method=\"linear\",\n",
    "        rescale=True\n",
    "    )\n",
    "    \n",
    "    estimated_errors[~np.isfinite(estimated_errors)] = 0\n",
    "        \n",
    "    return estimated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def calibrate_fragments(\n",
    "    db_file_name,\n",
    "    ms_data_file_name,\n",
    "    ms_level=2\n",
    "):\n",
    "    db_array = get_db_targets(\n",
    "        db_file_name,\n",
    "        max_ppm=100,\n",
    "        min_distance=0.5,\n",
    "        ms_level=ms_level,\n",
    "    )\n",
    "    estimated_errors = align_run_to_db(\n",
    "        ms_data_file_name,\n",
    "        db_array=db_array,\n",
    "        ms_level=ms_level,\n",
    "        plot_ppms=False,\n",
    "    )\n",
    "    \n",
    "    ms_file = alphapept.io.MS_Data_File(ms_data_file_name, is_overwritable=True)\n",
    "    ms_file.write(\n",
    "        estimated_errors,\n",
    "        dataset_name=\"corrected_fragment_mzs\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphapept] *",
   "language": "python",
   "name": "conda-env-alphapept-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
