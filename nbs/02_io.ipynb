{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input / Output\n",
    "\n",
    "> Functions related to input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to importing and exporting files. The current way to store raw data is to use the numpy native *.npz container. It allows dictionary-type access and provides reasonable access speeds.\n",
    "\n",
    "To access proprietary data formats, we have import functions to access `Bruker` and `Thermo` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion functions\n",
    "\n",
    "`get_most_abundant`: In order to save spectra in a more memory efficient form, we only keep the n most abundant peaks. This allows us to save data in a fast accessible matrix format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept.chem import calculate_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numba.typed import List\n",
    "from numba import njit\n",
    "from pyteomics import mzml, mzxml\n",
    "import gzip\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "def get_most_abundant(mass, intensity, n_max):\n",
    "    \"\"\"\n",
    "    Returns the n_max most abundant peaks of a spectrum\n",
    "    \"\"\"\n",
    "    if len(mass) < n_max:\n",
    "        return mass, intensity\n",
    "    else:\n",
    "        sortindex = np.argsort(intensity)[::-1][:n_max]\n",
    "        sortindex.sort()\n",
    "\n",
    "    return mass[sortindex], intensity[sortindex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Thermo Files\n",
    "\n",
    "> This implementation is based on `pymsfilereader`. It requires that MSFileReader from Thermo is installed.\n",
    "\n",
    "> The current implementation uses a lot of lists and fills them with list comprehensions. This creates a lot of variables but seems to work reasonably fast. This code could be refactored as all variables end up in a dictionary-type container anyhow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_thermo_raw(raw_file, most_abundant, callback=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Load thermo raw file and extract spectra\n",
    "    \"\"\"\n",
    "\n",
    "    from pymsfilereader import MSFileReader\n",
    "    rawfile = MSFileReader(raw_file)\n",
    "\n",
    "    spec_indices = np.array(\n",
    "        range(rawfile.FirstSpectrumNumber, rawfile.LastSpectrumNumber + 1)\n",
    "    )\n",
    "\n",
    "    scan_list = []\n",
    "    rt_list = []\n",
    "    mass_list = []\n",
    "    int_list = []\n",
    "    ms_list = []\n",
    "    prec_mzs_list = []\n",
    "    mono_mzs_list = []\n",
    "    charge_list = []\n",
    "\n",
    "    for idx, i in enumerate(spec_indices):\n",
    "        ms_order = rawfile.GetMSOrderForScanNum(i)\n",
    "        rt = rawfile.RTFromScanNum(i)\n",
    "\n",
    "        prec_mz = rawfile.GetPrecursorMassForScanNum(i, 2)\n",
    "\n",
    "        trailer_extra = rawfile.GetTrailerExtraForScanNum(i)\n",
    "        mono_mz = trailer_extra[\"Monoisotopic M/Z\"]\n",
    "        charge = trailer_extra[\"Charge State\"]\n",
    "\n",
    "        label_data = rawfile.GetLabelData(i)\n",
    "\n",
    "        # if labeled data is not available extract else\n",
    "        # Todo: check for centroided or not \n",
    "        \n",
    "        if label_data[0][0] == ():\n",
    "            mlist = rawfile.GetMassListFromScanNum(i)\n",
    "            masses = np.array(mlist[0][0])\n",
    "            intensity = np.array(mlist[0][1])\n",
    "        else:\n",
    "            intensity = np.array(label_data[0][1])\n",
    "            masses = np.array(label_data[0][0])\n",
    "\n",
    "        if ms_order == 2:\n",
    "            masses, intensity = get_most_abundant(masses, intensity, most_abundant)\n",
    "\n",
    "        scan_list.append(i)\n",
    "        rt_list.append(rt)\n",
    "        mass_list.append(np.array(masses))\n",
    "        int_list.append(np.array(intensity, dtype=np.int64))\n",
    "        ms_list.append(ms_order)\n",
    "        prec_mzs_list.append(prec_mz)\n",
    "        mono_mzs_list.append(mono_mz)\n",
    "        charge_list.append(charge)\n",
    "        \n",
    "        if callback:\n",
    "            callback((idx+1)/len(spec_indices))\n",
    "\n",
    "    scan_list_ms1 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    rt_list_ms1 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    mass_list_ms1 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    int_list_ms1 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    ms_list_ms1 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "\n",
    "    scan_list_ms2 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    rt_list_ms2 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    mass_list_ms2 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    int_list_ms2 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    ms_list_ms2 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    mono_mzs2 = [mono_mzs_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    charge2 = [charge_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "\n",
    "    prec_mass_list2 = [\n",
    "        calculate_mass(mono_mzs_list[i], charge_list[i])\n",
    "        for i, _ in enumerate(ms_list)\n",
    "        if _ == 2\n",
    "    ]\n",
    "\n",
    "    check_sanity(mass_list)\n",
    "    \n",
    "    query_data = {}\n",
    "\n",
    "    query_data[\"scan_list_ms1\"] = np.array(scan_list_ms1)\n",
    "    query_data[\"rt_list_ms1\"] = np.array(rt_list_ms1)\n",
    "    query_data[\"mass_list_ms1\"] = np.array(mass_list_ms1)\n",
    "    query_data[\"int_list_ms1\"] = np.array(int_list_ms1)\n",
    "    query_data[\"ms_list_ms1\"] = np.array(ms_list_ms1)\n",
    "\n",
    "    query_data[\"scan_list_ms2\"] = np.array(scan_list_ms2)\n",
    "    query_data[\"rt_list_ms2\"] = np.array(rt_list_ms2)\n",
    "    query_data[\"mass_list_ms2\"] = mass_list_ms2\n",
    "    query_data[\"int_list_ms2\"] = int_list_ms2\n",
    "    query_data[\"ms_list_ms2\"] = np.array(ms_list_ms2)\n",
    "    query_data[\"prec_mass_list2\"] = np.array(prec_mass_list2)\n",
    "    query_data[\"mono_mzs2\"] = np.array(mono_mzs2)\n",
    "    query_data[\"charge2\"] = np.array(charge2)\n",
    "    \n",
    "    return query_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper\n",
    "\n",
    "We use `multiprocessing - pool` to be able to convert multiple files to raw in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def raw_to_npz(to_process, callback = None):\n",
    "    \"\"\"\n",
    "    Wrapper function to convert raw to npz\n",
    "    \"\"\"\n",
    "\n",
    "    path, settings = to_process\n",
    "\n",
    "    base, ext = os.path.splitext(path)\n",
    "    \n",
    "    if ext.lower() == '.raw':\n",
    "        logging.info('File {} has extension {} - converting from Thermo.'.format(base, ext))\n",
    "        query_data = load_thermo_raw(path, callback=callback, **settings['raw'])\n",
    "    elif ext.lower() == '.d':\n",
    "        logging.info('File {} has extension {} - converting from Bruker.'.format(base, ext))\n",
    "        query_data = load_bruker_raw(path, callback=callback, **settings['raw'])\n",
    "    else:\n",
    "        raise NotImplementedError('File extension {} not understood.'.format(ext))\n",
    "        \n",
    "    logging.info('File conversion complete. Extracted {:,} precursors.'.format(len(query_data['prec_mass_list2'])))\n",
    "        \n",
    "    save_path = base + \".npz\"\n",
    "    save_query_as_npz(save_path, query_data)\n",
    "    logging.info('Converted file saved to {}'.format(save_path))\n",
    "    \n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def raw_to_npz_parallel(path_list, settings, callback=None):\n",
    "    \n",
    "    n_processes = settings['general']['n_processes']\n",
    "    \n",
    "    to_process = [(_, settings) for _ in path_list]\n",
    "    \n",
    "    if len(to_process) == 1:\n",
    "        raw_to_npz(to_process[0], callback=callback)\n",
    "    \n",
    "    else:\n",
    "        with Pool(n_processes) as p:\n",
    "            max_ = len(to_process)\n",
    "            for i, _ in enumerate(p.imap_unordered(raw_to_npz, to_process)):\n",
    "                if callback:\n",
    "                    callback((i+1)/max_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruker\n",
    "\n",
    "For accessing Bruker files, we rely on the external `timsdata` library. \n",
    "For `ccs` values, we need some functions from this library. As the live feature-finder might not be able to determine some charge values, it is intended to perform this calculation at a later stage once we have charge values from the post-processing feature finder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_bruker_raw(raw_file, most_abundant, callback=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Load bruker raw file and extract spectra\n",
    "    \"\"\"\n",
    "    import sqlalchemy as db\n",
    "    import pandas as pd\n",
    "    from ext.bruker import timsdata\n",
    "\n",
    "    tdf = os.path.join(raw_file, 'analysis.tdf')\n",
    "    engine = db.create_engine('sqlite:///{}'.format(tdf))\n",
    "    prec_data = pd.read_sql_table('Precursors', engine)\n",
    "    frame_data = pd.read_sql_table('Frames', engine)\n",
    "    frame_data = frame_data.set_index('Id')\n",
    "    \n",
    "    from alphapept.constants import mass_dict\n",
    "\n",
    "    tdf = timsdata.TimsData(raw_file)\n",
    "\n",
    "    M_PROTON = mass_dict['Proton']\n",
    "\n",
    "    prec_data['Mass'] = prec_data['MonoisotopicMz'].values * prec_data['Charge'].values - prec_data['Charge'].values*M_PROTON\n",
    "\n",
    "    from alphapept.io import list_to_numpy_f32, get_most_abundant\n",
    "\n",
    "    mass_list_ms2 = []\n",
    "    int_list_ms2 = []\n",
    "    scan_list_ms2 = []\n",
    "    \n",
    "    prec_data = prec_data.sort_values(by='Mass', ascending=True)\n",
    "    \n",
    "    precursor_ids = prec_data['Id'].tolist()\n",
    "\n",
    "    for idx, key in enumerate(precursor_ids):\n",
    "\n",
    "        ms2_data = tdf.readPasefMsMs([key])\n",
    "        masses, intensity = ms2_data[key]\n",
    "\n",
    "        masses, intensity = get_most_abundant(np.array(masses), np.array(intensity), most_abundant)\n",
    "\n",
    "        mass_list_ms2.append(masses)\n",
    "        int_list_ms2.append(intensity)\n",
    "        scan_list_ms2.append(key)\n",
    "        \n",
    "        if callback:\n",
    "            callback((idx+1)/len(precursor_ids))\n",
    "            \n",
    "\n",
    "    check_sanity(mass_list_ms2)\n",
    "                               \n",
    "    query_data = {}\n",
    "\n",
    "    query_data['prec_mass_list2'] = prec_data['Mass'].values\n",
    "    query_data['prec_id'] = prec_data['Id'].values\n",
    "    query_data['mono_mzs2'] = prec_data['MonoisotopicMz'].values\n",
    "    query_data['rt_list_ms2'] = frame_data.loc[prec_data['Parent'].values]['Time'].values / 60 #convert to minutes\n",
    "    query_data['scan_list_ms2'] = prec_data['Parent'].values\n",
    "    query_data['charge2'] = prec_data['Charge'].values\n",
    "    query_data['mobility'] = tdf.scanNumToOneOverK0(1, prec_data['ScanNumber'].to_list()) #check if its okay to always use first frame\n",
    "    query_data[\"mass_list_ms2\"] = mass_list_ms2\n",
    "    query_data[\"int_list_ms2\"] = int_list_ms2\n",
    "    \n",
    "    \n",
    "    return query_data\n",
    "\n",
    "def one_over_k0_to_CCS(one_over_k0s, charges, mzs):\n",
    "    \"\"\"\n",
    "    convert one_over_k0 to CCS\n",
    "    \"\"\"\n",
    "    from ext.bruker import timsdata\n",
    "    ccs = np.empty(len(one_over_k0s))\n",
    "    ccs[:] = np.nan\n",
    "    \n",
    "    for idx, (one_over, charge, mz) in enumerate(zip(one_over_k0s, charges, mzs)):\n",
    "        try:\n",
    "            ccs[idx] =timsdata.oneOverK0ToCCSforMz(one_over, int(charge), mz)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return ccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MZML \n",
    "\n",
    "To access mzml files, we rely on the pyteomics package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def check_sanity(mass_list):\n",
    "    \"\"\"\n",
    "    Sanity check for mass list to make sure the masses are sorted\n",
    "    \"\"\"\n",
    "    \n",
    "    if not all(\n",
    "        mass_list[0][i] <= mass_list[0][i + 1] for i in range(len(mass_list[0]) - 1)\n",
    "    ):\n",
    "        raise ValueError(\"Masses are not sorted.\")\n",
    "        \n",
    "        \n",
    "def extract_mzml_info(input_dict):\n",
    "    rt = float(input_dict.get('scanList').get('scan')[0].get('scan start time'))  # rt_list_ms1/2\n",
    "    masses = input_dict.get('m/z array')\n",
    "    intensities = input_dict.get('intensity array')\n",
    "    ms_order = input_dict.get('ms level')  # ms_list_ms1/2\n",
    "    prec_mass = 0\n",
    "    if ms_order == 2:\n",
    "        charge = int(\n",
    "            input_dict.get('precursorList').get('precursor')[0].get('selectedIonList').get('selectedIon')[0].get(\n",
    "                'charge state'))\n",
    "        mono_mz = round(\n",
    "            input_dict.get('precursorList').get('precursor')[0].get('selectedIonList').get('selectedIon')[0].get(\n",
    "                'selected ion m/z'), 4)\n",
    "        prec_mass = calculate_mass(mono_mz, charge)\n",
    "    return rt, masses, intensities, ms_order, prec_mass\n",
    "\n",
    "\n",
    "def extract_mzxml_info(input_dict):\n",
    "    rt = float(input_dict.get('retentionTime'))\n",
    "    masses = input_dict.get('m/z array')\n",
    "    intensities = input_dict.get('intensity array')\n",
    "    ms_order = input_dict.get('msLevel')  # ms_list_ms1/2\n",
    "    prec_mass = 0\n",
    "    if ms_order == 2:\n",
    "        charge = int(input_dict.get('precursorMz')[0].get('precursorCharge'))\n",
    "        mono_mz = round(input_dict.get('precursorMz')[0].get('precursorMz'), 4)\n",
    "        prec_mass = calculate_mass(mono_mz, charge)\n",
    "    return rt, masses, intensities, ms_order, prec_mass\n",
    "\n",
    "\n",
    "def read_mzML(filename, most_abundant):\n",
    "    \"\"\"\n",
    "    Read spectral data from an mzML file and return various lists separately for ms1 and ms2 data.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if os.path.splitext(filename)[1] == '.gz':\n",
    "            reader = mzml.read(gzip.open(filename), use_index=True)\n",
    "        else:\n",
    "            reader = mzml.read(filename, use_index=True)\n",
    "        spec_indices = np.array(range(1, len(reader) + 1))\n",
    "\n",
    "    except OSError:\n",
    "        logging('Could not open the file. Please, specify the correct path to the file.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    scan_list = []\n",
    "    rt_list = []\n",
    "    mass_list = []\n",
    "    int_list = []\n",
    "    ms_list = []\n",
    "    prec_mzs_list = []\n",
    "\n",
    "    logging('Start reading mzML file...')\n",
    "    if reader:\n",
    "        for i in tqdm(spec_indices):\n",
    "            spec = next(reader)\n",
    "            scan_list.append(i)\n",
    "            rt, masses, intensities, ms_order, prec_mass = extract_mzml_info(spec, min_charge, max_charge)\n",
    "            if ms_order == 2:\n",
    "                masses, intensities = get_most_abundant(masses, intensities, most_abundant)\n",
    "            rt_list.append(rt)\n",
    "            mass_list.append(masses)\n",
    "            int_list.append(intensities)\n",
    "            ms_list.append(ms_order)\n",
    "            prec_mzs_list.append(prec_mass)\n",
    "\n",
    "    check_sanity(mass_list)\n",
    "\n",
    "    scan_list_ms1 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    rt_list_ms1 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    mass_list_ms1 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    int_list_ms1 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    ms_list_ms1 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "\n",
    "    scan_list_ms2 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    rt_list_ms2 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    mass_list_ms2 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    int_list_ms2 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    ms_list_ms2 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    prec_mass_list2 = [prec_mzs_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    \n",
    "    query_data = {}\n",
    "\n",
    "    query_data[\"scan_list_ms1\"] = np.array(scan_list_ms1)\n",
    "    query_data[\"rt_list_ms1\"] = np.array(rt_list_ms1)\n",
    "    query_data[\"mass_list_ms1\"] = np.array(mass_list_ms1)\n",
    "    query_data[\"int_list_ms1\"] = np.array(int_list_ms1)\n",
    "    query_data[\"ms_list_ms1\"] = np.array(ms_list_ms1)\n",
    "\n",
    "    query_data[\"scan_list_ms2\"] = np.array(scan_list_ms2)\n",
    "    query_data[\"rt_list_ms2\"] = np.array(rt_list_ms2)\n",
    "    query_data[\"mass_list_ms2\"] = mass_list_ms2\n",
    "    query_data[\"int_list_ms2\"] = int_list_ms2\n",
    "    query_data[\"ms_list_ms2\"] = np.array(ms_list_ms2)\n",
    "    query_data[\"prec_mass_list2\"] = np.array(prec_mass_list2)\n",
    "    query_data[\"mono_mzs2\"] = np.array(mono_mzs2)\n",
    "    query_data[\"charge2\"] = np.array(charge2)\n",
    "    \n",
    "    return query_data\n",
    "\n",
    "\n",
    "def read_mzXML(filename, most_abundant):\n",
    "    \"\"\"\n",
    "    Read spectral data from an mzXML file and return various lists separately for ms1 and ms2 data.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if os.path.splitext(filename)[1] == '.gz':\n",
    "            reader = mzxml.read(gzip.open(filename), use_index=True)\n",
    "        else:\n",
    "            reader = mzxml.read(filename, use_index=True)\n",
    "        spec_indices = np.array(range(1, len(reader) + 1))\n",
    "\n",
    "    except OSError:\n",
    "        print('Could not open the file. Please, specify the correct path to the file.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    scan_list = []\n",
    "    rt_list = []\n",
    "    mass_list = []\n",
    "    int_list = []\n",
    "    ms_list = []\n",
    "    prec_mzs_list = []\n",
    "\n",
    "    print('Start reading mzXML file...')\n",
    "    if reader:\n",
    "        for i in tqdm(spec_indices):\n",
    "            spec = next(reader)\n",
    "            scan_list.append(i)\n",
    "            rt, masses, intensities, ms_order, prec_mass = extract_mzxml_info(spec, min_charge, max_charge)\n",
    "            if ms_order == 2:\n",
    "                masses, intensities = get_most_abundant(masses, intensities, most_abundant)\n",
    "            rt_list.append(rt)\n",
    "            mass_list.append(masses)\n",
    "            int_list.append(intensities)\n",
    "            ms_list.append(ms_order)\n",
    "            prec_mzs_list.append(prec_mass)\n",
    "\n",
    "    check_sanity(mass_list)\n",
    "\n",
    "    scan_list_ms1 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    rt_list_ms1 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    mass_list_ms1 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    int_list_ms1 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "    ms_list_ms1 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 1]\n",
    "\n",
    "    scan_list_ms2 = [scan_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    rt_list_ms2 = [rt_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    mass_list_ms2 = [mass_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    int_list_ms2 = [int_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    ms_list_ms2 = [ms_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "    prec_mass_list2 = [prec_mzs_list[i] for i, _ in enumerate(ms_list) if _ == 2]\n",
    "\n",
    "    check_sanity(mass_list)\n",
    "    \n",
    "    query_data = {}\n",
    "\n",
    "    query_data[\"scan_list_ms1\"] = np.array(scan_list_ms1)\n",
    "    query_data[\"rt_list_ms1\"] = np.array(rt_list_ms1)\n",
    "    query_data[\"mass_list_ms1\"] = np.array(mass_list_ms1)\n",
    "    query_data[\"int_list_ms1\"] = np.array(int_list_ms1)\n",
    "    query_data[\"ms_list_ms1\"] = np.array(ms_list_ms1)\n",
    "\n",
    "    query_data[\"scan_list_ms2\"] = np.array(scan_list_ms2)\n",
    "    query_data[\"rt_list_ms2\"] = np.array(rt_list_ms2)\n",
    "    query_data[\"mass_list_ms2\"] = mass_list_ms2\n",
    "    query_data[\"int_list_ms2\"] = int_list_ms2\n",
    "    query_data[\"ms_list_ms2\"] = np.array(ms_list_ms2)\n",
    "    query_data[\"prec_mass_list2\"] = np.array(prec_mass_list2)\n",
    "    query_data[\"mono_mzs2\"] = np.array(mono_mzs2)\n",
    "    query_data[\"charge2\"] = np.array(charge2)\n",
    "    \n",
    "    return query_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "For saving, we are currently relying on the NumPy-native npz-container. It offers reasonable speed, dictionary-type access, and does not need individual type definitions.\n",
    "\n",
    "While we could, in principle, store the mz and int arrays as a list of variable length, this will come at a performance decrease. We, therefore, create an array of the dimensions of the n most abundant peaks and the number of spectra with the function `list_to_numpy_f32` and fill the unoccupied cells with `-1`. This allows an increase in accessing times at the cost of additional disk space.\n",
    "\n",
    "Implementation Note: For large files (e.g., choosing a large number of peaks that should be kept, the npz array can fail and trigger an ZIP64 error. This is supposed to be fixed in a later NumPy version.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def list_to_numpy_f32(long_list):\n",
    "    \"\"\"\n",
    "    Function to convert a list to float32 array\n",
    "    \"\"\"\n",
    "    np_array = (\n",
    "        np.zeros(\n",
    "            [len(max(long_list, key=lambda x: len(x))), len(long_list)],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        - 1\n",
    "    )\n",
    "    for i, j in enumerate(long_list):\n",
    "        np_array[0 : len(j), i] = j\n",
    "\n",
    "    return np_array\n",
    "\n",
    "        \n",
    "def save_query_as_npz(raw_file_npz, query_data):\n",
    "    \"\"\"\n",
    "    Saves query_data as npz\n",
    "    \"\"\"\n",
    "    \n",
    "    to_save = {}\n",
    "    \n",
    "    for key in query_data.keys():\n",
    "        if key in ['mass_list_ms2','int_list_ms2']:\n",
    "            to_save[key] = list_to_numpy_f32(query_data[key])\n",
    "        else:\n",
    "            to_save[key] = query_data[key]\n",
    "            \n",
    "    to_save[\"bounds\"] = np.sum(to_save['mass_list_ms2']>=0,axis=0).astype(np.int64)\n",
    "            \n",
    "    np.savez(raw_file_npz, **to_save)\n",
    "    \n",
    "    return raw_file_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing other Files\n",
    "\n",
    "Benchmarking proteomics software against each other is not straightforward as various naming conventions exist, and different algorithms are implemented. In this section, we define some helper functions that allow us to facilitate the comparison of different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading MaxQuant xml settings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_nested(child):\n",
    "    \"\"\"\n",
    "    Helper function to extract nested entries\n",
    "    \"\"\"\n",
    "    if len(child) > 0:\n",
    "        temp_dict = {}\n",
    "        for xx in child:\n",
    "            temp_dict[xx.tag] = extract_nested(xx)\n",
    "        return temp_dict\n",
    "    else:\n",
    "        if child.text == 'True':\n",
    "            info = True\n",
    "        elif child.text == 'False':\n",
    "            info = False\n",
    "        else:\n",
    "            info = child.text\n",
    "        return info\n",
    "\n",
    "def extract_mq_settings(path):\n",
    "    \"\"\"\n",
    "    Function to return MaxQuant values as a dictionary for a given xml file\n",
    "    \"\"\"\n",
    "    if not path.endswith('.xml'):\n",
    "        raise ValueError(\"Path {} is not a valid xml file.\".format(path))\n",
    "    \n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    mq_dict = {}\n",
    "\n",
    "    for child in root:  \n",
    "\n",
    "        mq_dict[child.tag] = extract_nested(child)\n",
    "        \n",
    "    return mq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FastaFileInfo': {'fastaFilePath': 'testfile.fasta',\n",
       "  'identifierParseRule': '>([^\\\\s]*)',\n",
       "  'descriptionParseRule': '>(.*)',\n",
       "  'taxonomyParseRule': None,\n",
       "  'variationParseRule': None,\n",
       "  'modificationParseRule': None,\n",
       "  'taxonomyId': None}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mq_dict = extract_mq_settings('../testfiles/test_mqpar.xml')\n",
    "mq_dict['fastaFiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_mq_seq(peptide):\n",
    "    \"\"\"\n",
    "    Replaces maxquant convention to alphapept convention\n",
    "    ToDo: include more sequences\n",
    "    \"\"\"\n",
    "    peptide = peptide[1:-1] #Remove _\n",
    "\n",
    "    peptide = peptide.replace('(Acetyl (Protein N-term))','a')\n",
    "    peptide = peptide.replace('M(Oxidation (M))','oxM')\n",
    "    peptide = peptide.replace('C','cC') #This is fixed and not indicated in MaxQuant\n",
    "    \n",
    "    return peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AFQPFFVELToxMPYSVIR'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_mq_seq('_AFQPFFVELTM(Oxidation (M))PYSVIR_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
