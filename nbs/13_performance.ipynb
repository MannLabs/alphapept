{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-fields",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5223bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefe0cd",
   "metadata": {},
   "source": [
    "AlphaPept deals with high-throughput data. As this can be computationally intensive, we try to make all functions as performant as possible. To do so, we rely on two principles:\n",
    "* **Compilation**\n",
    "* **Parallelization**\n",
    "\n",
    "A first step of **compilation** can be achieved by using NumPy arrays which are already heavily c-optimized. Net we consider three kinds of compilation:\n",
    "* **Python** This allows to use no compilation\n",
    "* **Numba** This allows to use just-in-time (JIT) compilation.\n",
    "* **Cuda** This allows compilation on the GPU.\n",
    "\n",
    "All of these compilation approaches can be combined with **parallelization** approaches. We consider the following possibilities:\n",
    "* **No parallelization** Not all functionality can be parallelized.\n",
    "* **Multithreading** This is only performant when Python's blobal interpreter lock (GIL) is released or when mostly using input-/output (IO) functions.\n",
    "* **GPU** This is only available if an NVIDIA GPU is available and properly configured.\n",
    "\n",
    "Note that not all compilation approaches can sensibly be combined with all parallelization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e256be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "COMPILATION_MODE_OPTIONS = [\n",
    "    \"python\",\n",
    "    \"python-multithread\",\n",
    "    \"numba\",\n",
    "    \"numba-multithread\",\n",
    "    \"cuda\", # Cuda is always multithreaded\n",
    "]\n",
    "COMPILATION_MODE = \"numba-multithread\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b0c6e",
   "metadata": {},
   "source": [
    "Next we import all libraries, taking into account that not every machine has a GPU (with NVidia cores) available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb507f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import psutil\n",
    "import ast\n",
    "\n",
    "# Parallelization\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "# Compilation\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "try:\n",
    "    import cupy\n",
    "    cuda.get_current_device()\n",
    "    __GPU_AVAILABLE = True\n",
    "except ModuleNotFoundError:\n",
    "    __GPU_AVAILABLE = False\n",
    "    cupy = None\n",
    "    logging.info(\"Cupy is not available\")\n",
    "except cuda.CudaSupportError:\n",
    "    __GPU_AVAILABLE = False\n",
    "    logging.info(\"Cuda device is not available\")\n",
    "    \n",
    "def is_valid_compilation_mode(compilation_mode: str):\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    if compilation_mode.startswith(\"cuda\"):\n",
    "        if not __GPU_AVAILABLE:\n",
    "            raise ModuleNotFoundError('Cuda functions are not available.')\n",
    "    if compilation_mode not in COMPILATION_MODE_OPTIONS:\n",
    "        raise NotImplementedError(\n",
    "            f\"Compilation mode '{compilation_mode}' is not available, \"\n",
    "            \"see COMPILATION_MODE_OPTIONS for available options.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eae564",
   "metadata": {},
   "source": [
    "To consistently use multiple threads or processes, we can set a global MAX_WORKER_COUNT parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d131329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "MAX_WORKER_COUNT = 1\n",
    "\n",
    "def set_worker_count(worker_count: int = 1, set_global: bool = True) -> int:\n",
    "    \"\"\"Parse and set the (global) number of threads.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    worker_count : int\n",
    "        The number of workers.\n",
    "        If larger than available cores, it is trimmed to the available maximum.\n",
    "        If 0, it is set to the maximum cores available.\n",
    "        If negative, it indicates how many cores NOT to use.\n",
    "        Default is 1\n",
    "    set_global : bool\n",
    "        If False, the number of workers is only parsed to a valid value.\n",
    "        If True, the number of workers is saved as a global variable.\n",
    "        Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    : int\n",
    "        The parsed worker_count.\n",
    "    \"\"\"\n",
    "    max_cpu_count = psutil.cpu_count()\n",
    "    if worker_count > max_cpu_count:\n",
    "        worker_count = max_cpu_count\n",
    "    else:\n",
    "        while worker_count <= 0:\n",
    "            worker_count += max_cpu_count\n",
    "    if set_global:\n",
    "        global MAX_WORKER_COUNT\n",
    "        MAX_WORKER_COUNT = worker_count\n",
    "    return worker_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3d21f",
   "metadata": {},
   "source": [
    "Compiled functions are intended to be very fast. However, they do not have the same flexibility as pure Python functions. In general, we recommend to use staticly defined compilation functions for optimal performance. We provide the option to define a default compilation mode for decorated functions, while also allowing to define the compilation mode for each individual function.\n",
    "\n",
    "**NOTE**: Compiled functions are by default expected to be performed on a single thread. Thus, 'cuda' funtions are always assumed to be device functions which makes them callable from within the GPU, unless explicitly stated otherwise. Similarly, 'numba' functions are always assumed to bo 'nopython' and 'nogil'.\n",
    "\n",
    "In addition, we allow to enable dynamic compilation, meaning the compilation mode of functions can be changed at runtime. Do note that this comes at the cost of some performance, as compilation needs to be done at runtime as well. Moreover, functions that are defined with dynamic compilation can not be called from within other compiled functions (with the exception of 'python' compilation, which means no compilation is actually performed).\n",
    "\n",
    "**NOTE**: Dynamic compilation must be enabled before functions are decorated to take effect at runtime, otherwise they are statically compiled with the current settings at the time they are defined! Alternatively, statically compiled functions of a an 'imported_module' can reloaded (and thus statically be recompiled) with the commands:\n",
    "```\n",
    "import importlib\n",
    "importlib.reload(imported_module)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d849370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "DYNAMIC_COMPILATION_ENABLED = False\n",
    "    \n",
    "def set_compilation_mode(\n",
    "    compilation_mode: str = None,\n",
    "    enable_dynamic_compilation: bool = None,\n",
    ") -> None:\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    if enable_dynamic_compilation is not None:\n",
    "        global DYNAMIC_COMPILATION_ENABLED\n",
    "        DYNAMIC_COMPILATION_ENABLED = enable_dynamic_compilation\n",
    "    if compilation_mode is not None:\n",
    "        is_valid_compilation_mode(compilation_mode)\n",
    "        global COMPILATION_MODE\n",
    "        COMPILATION_MODE = compilation_mode\n",
    "    \n",
    "\n",
    "def compile_function(\n",
    "    _func: callable = None,\n",
    "    *,\n",
    "    compilation_mode: str = None,\n",
    "    **decorator_kwargs,\n",
    "):\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    if compilation_mode is None:\n",
    "        if DYNAMIC_COMPILATION_ENABLED:\n",
    "            compilation_mode = \"dynamic\"\n",
    "        else:\n",
    "            compilation_mode = COMPILATION_MODE\n",
    "    def parse_compilation(current_compilation_mode, func):\n",
    "        if current_compilation_mode.startswith(\"python\"):\n",
    "            compiled_function = func\n",
    "        elif current_compilation_mode.startswith(\"numba\"):\n",
    "            if \"nogil\" in decorator_kwargs:\n",
    "                if \"nopython\" in decorator_kwargs:\n",
    "                    compiled_function = numba.jit(func, **decorator_kwargs)\n",
    "                else:\n",
    "                    compiled_function = numba.jit(func, **decorator_kwargs, nopython=True)\n",
    "            elif \"nopython\" in decorator_kwargs:\n",
    "                compiled_function = numba.jit(func, **decorator_kwargs, nogil=True)\n",
    "            else:\n",
    "                compiled_function = numba.jit(func, **decorator_kwargs, nogil=True, nopython=True)\n",
    "        elif current_compilation_mode.startswith(\"cuda\"):\n",
    "            if \"device\" in decorator_kwargs:\n",
    "                compiled_function = cuda.jit(func, **decorator_kwargs)\n",
    "            else:\n",
    "                compiled_function = cuda.jit(func, **decorator_kwargs, device=True)\n",
    "        return compiled_function\n",
    "    def decorated_function(func):\n",
    "        if compilation_mode != \"dynamic\":\n",
    "            is_valid_compilation_mode(compilation_mode)\n",
    "            static_compiled_function = parse_compilation(compilation_mode, func)\n",
    "            return functools.wraps(func)(static_compiled_function)\n",
    "        else:\n",
    "            def dynamic_compiled_function(*func_args, **func_kwargs):\n",
    "                compiled_function = parse_compilation(COMPILATION_MODE, func)\n",
    "                return compiled_function(*func_args, **func_kwargs)\n",
    "            return functools.wraps(func)(dynamic_compiled_function)\n",
    "    if _func is None:\n",
    "        return decorated_function\n",
    "    else:\n",
    "        return decorated_function(_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dd7c2",
   "metadata": {},
   "source": [
    "Testing yields the expected results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367a650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"numba-multithread\")\n",
    "\n",
    "@compile_function(compilation_mode=\"python\")\n",
    "def test_func_python(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "    \n",
    "@compile_function(compilation_mode=\"numba\")\n",
    "def test_func_numba(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "    \n",
    "@compile_function(compilation_mode=\"cuda\")\n",
    "def test_func_cuda(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "set_compilation_mode(enable_dynamic_compilation=True)\n",
    "\n",
    "@compile_function\n",
    "def test_func_dynamic_runtime(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "set_compilation_mode(enable_dynamic_compilation=False, compilation_mode=\"numba-multithread\")\n",
    "\n",
    "@compile_function\n",
    "def test_func_static_runtime_numba(x):\n",
    "    \"\"\"Docstring test\"\"\"\n",
    "    x[0] += 1\n",
    "\n",
    "a = np.zeros(1, dtype=np.int64)\n",
    "assert(isinstance(test_func_python, types.FunctionType))\n",
    "test_func_python(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_numba, numba.core.registry.CPUDispatcher))\n",
    "test_func_numba(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "# # Cuda function cannot be tested from outside the GPU\n",
    "# a = np.zeros(1)\n",
    "# assert(isinstance(test_func_cuda, numba.cuda.compiler.Dispatcher))\n",
    "# test_func_cuda.forall(1,1)(a)\n",
    "# assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"python\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_static_runtime_numba, numba.core.registry.CPUDispatcher))\n",
    "test_func_static_runtime_numba(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"python\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "test_func_dynamic_runtime(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "set_compilation_mode(compilation_mode=\"numba\")\n",
    "a = np.zeros(1)\n",
    "assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "test_func_dynamic_runtime(a)\n",
    "assert(np.all(a == np.ones(1)))\n",
    "\n",
    "# # Cuda function cannot be tested from outside the GPU\n",
    "# set_compilation_mode(compilation_mode=\"cuda\")\n",
    "# a = np.zeros(1)\n",
    "# assert(isinstance(test_func_dynamic_runtime, types.FunctionType))\n",
    "# test_func_dynamic_runtime.forall(1,1)(a)\n",
    "# assert(np.all(a == np.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22037748",
   "metadata": {},
   "source": [
    "Next, we define the 'performance_function' decorator to take full advantage of both compilation and parallelization for maximal performance. Note that a 'performance_function' can note reutnr values. Instead, it should store results in provided buffer arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8ae63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def performance_function(\n",
    "    _func: callable = None,\n",
    "    *,\n",
    "    worker_count: int = None,\n",
    "    compilation_mode: str = None,\n",
    "    **decorator_kwargs,\n",
    "):\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    if worker_count is not None:\n",
    "        worker_count = set_worker_count(worker_count, set_global=False)\n",
    "    if compilation_mode is None:\n",
    "        if DYNAMIC_COMPILATION_ENABLED:\n",
    "            compilation_mode = \"dynamic\"\n",
    "        else:\n",
    "            compilation_mode = COMPILATION_MODE\n",
    "    else:\n",
    "        is_valid_compilation_mode(compilation_mode)\n",
    "    def _decorated_function(func):\n",
    "        if compilation_mode != \"dynamic\":\n",
    "            compiled_function = compile_function(\n",
    "                func,\n",
    "                compilation_mode=compilation_mode,\n",
    "                **decorator_kwargs\n",
    "            )\n",
    "        def _parallel_python(\n",
    "            compiled_function,\n",
    "            iterable,\n",
    "            thread_id,\n",
    "            start,\n",
    "            stop,\n",
    "            step,\n",
    "            *func_args\n",
    "        ):\n",
    "            if len(iterable) == 0:\n",
    "                for index in range(start, stop, step):\n",
    "                    compiled_function(index, *func_args)\n",
    "            else:\n",
    "                for index in iterable:\n",
    "                    compiled_function(index, *func_args)\n",
    "        _parallel_numba = numba.njit(nogil=True)(_parallel_python)\n",
    "        def _parallel_cuda(compiled_function, iterable, *func_args):\n",
    "            cuda_func_dict = {\"cuda\": cuda, \"compiled_function\": compiled_function}\n",
    "            func_string = \", \".join(f\"arg{i}\" for i in range(len(func_args)))\n",
    "            cuda_string = (\n",
    "                f\"@cuda.jit\\n\"\n",
    "                f\"def cuda_func({func_string}):\\n\"\n",
    "                f\"    index = cuda.grid(1)\\n\"\n",
    "                f\"    compiled_function(index, {func_string})\\n\"\n",
    "            )\n",
    "            exec(cuda_string, cuda_func_dict)\n",
    "            cuda_func_dict[\"cuda_func\"].forall(len(iterable), 1)(*func_args)\n",
    "#                 @cuda.jit\n",
    "#                 def cuda_func(a1, a2, a3):\n",
    "#                     index = cuda.grid(1)\n",
    "#                     compiled_function(index, a1, a2, a3)\n",
    "#                 cuda_func.forall(len(iterable), 1)(*func_args)\n",
    "        def _performance_function(iterable, *func_args):\n",
    "            if compilation_mode == \"dynamic\":\n",
    "                selected_compilation_mode = COMPILATION_MODE\n",
    "                _compiled_function = compile_function(\n",
    "                    func,\n",
    "                    compilation_mode=selected_compilation_mode,\n",
    "                    **decorator_kwargs\n",
    "                )\n",
    "            else:\n",
    "                _compiled_function = compiled_function\n",
    "                selected_compilation_mode = compilation_mode\n",
    "            try:\n",
    "                iter(iterable)\n",
    "            except TypeError:\n",
    "                iterable = [iterable]\n",
    "            if worker_count is None:\n",
    "                selected_worker_count = MAX_WORKER_COUNT\n",
    "            else:\n",
    "                selected_worker_count = worker_count\n",
    "            if selected_compilation_mode == \"cuda\":\n",
    "                _parallel_cuda(_compiled_function, iterable, *func_args)\n",
    "            else:\n",
    "                if \"python\" in selected_compilation_mode:\n",
    "                    parallel_function = _parallel_python\n",
    "                elif \"numba\" in selected_compilation_mode:\n",
    "                    parallel_function = _parallel_numba\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        f\"Compilation mode {selected_compilation_mode} is not valid. \"\n",
    "                        \"This error should not be possible, something is seriously wrong!!!\"\n",
    "                    )\n",
    "                if selected_compilation_mode in [\"python\", \"numba\"]:\n",
    "                    iterable_is_range = isinstance(iterable, range)\n",
    "                    parallel_function(\n",
    "                        _compiled_function,\n",
    "                        np.empty(0, dtype=np.int64) if iterable_is_range else iterable,\n",
    "                        0,\n",
    "                        iterable.start if iterable_is_range else -1,\n",
    "                        iterable.stop if iterable_is_range else -1,\n",
    "                        iterable.step if iterable_is_range else -1,\n",
    "                        *func_args\n",
    "                    )\n",
    "                else:\n",
    "                    workers = []\n",
    "                    for worker_id in range(selected_worker_count):\n",
    "                        local_iterable = iterable[worker_id::selected_worker_count]\n",
    "                        iterable_is_range = isinstance(local_iterable, range)\n",
    "                        worker = threading.Thread(\n",
    "                            target=parallel_function,\n",
    "                            args=(\n",
    "                                _compiled_function,\n",
    "                                np.empty(0, dtype=np.int64) if iterable_is_range else local_iterable,\n",
    "                                worker_id,\n",
    "                                local_iterable.start if iterable_is_range else -1,\n",
    "                                local_iterable.stop if iterable_is_range else -1,\n",
    "                                local_iterable.step if iterable_is_range else -1,\n",
    "                                *func_args\n",
    "                            )\n",
    "                        )\n",
    "                        worker.start()\n",
    "                        workers.append(worker)\n",
    "                    for worker in workers:\n",
    "                        worker.join()\n",
    "                        del worker\n",
    "        return functools.wraps(func)(_performance_function)\n",
    "    if _func is None:\n",
    "        return _decorated_function\n",
    "    else:\n",
    "        return _decorated_function(_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "624250cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "def smooth_func(index, in_array, out_array, window_size):\n",
    "    min_index = max(index - window_size, 0)\n",
    "    max_index = min(index + window_size + 1, len(in_array))\n",
    "    smooth_value = 0\n",
    "    for i in range(min_index, max_index):\n",
    "        smooth_value += 2 * in_array[i]\n",
    "    out_array[index] += smooth_value / (max_index - min_index)\n",
    "\n",
    "    \n",
    "set_worker_count(0)\n",
    "s = 10**6\n",
    "in_array = cupy.arange(s)\n",
    "out_array = cupy.zeros_like(in_array)\n",
    "\n",
    "func = performance_function(compilation_mode=\"cuda\")(smooth_func)\n",
    "%time func(range(in_array.shape[0]), in_array, out_array, 100000)\n",
    "# %time print(out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b7ce0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 300000,  300003,  300006, ..., 5699988, 5699991, 5699994])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 10**6\n",
    "out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2023996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%time func(range(s), in_array, out_array, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "f = (\n",
    "    \"def z(a):\\n\"\n",
    "    \"  np.sum(a)\\n\"\n",
    "    \"  return a\"\n",
    ")\n",
    "exec(f, d)\n",
    "# d[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5970a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.arange(3)\n",
    "\n",
    "d[\"z\"](r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da07f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(r, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8982cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81881f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05771540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3898e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = \"a1,a2\"\n",
    "exec(\n",
    "    \"@cuda.jit\\n\"\n",
    "    f\"def cuda_func2({fs}):\\n\"\n",
    "    \"    index = cuda.grid(1)\\n\"\n",
    "    f\"    compiled_function(index, {fs})\\n\"\n",
    ")\n",
    "cuda_func2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c176f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dfdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa4d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9259e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9168a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed548e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0a9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import multiprocessing\n",
    "import threading\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import psutil\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import numpy as numpy_\n",
    "cupy = numpy_\n",
    "from numba import cuda as cuda_\n",
    "cuda = cuda_\n",
    "import numba as numba_\n",
    "numba = numba_\n",
    "\n",
    "# We use jit_fun and jit_fun_gpu.\n",
    "# This is to be able too distinguish GPU device functions and numba optimized functions in a GPU setting\n",
    "\n",
    "jit_fun = None\n",
    "jit_fun_gpu = None\n",
    "speed_mode = None\n",
    "\n",
    "\n",
    "try:\n",
    "    import cupy as cupy_\n",
    "except ModuleNotFoundError:\n",
    "    cupy_ = None\n",
    "\n",
    "def dummy_decorator(func):\n",
    "    \"\"\"\n",
    "    Dummy decorator that does nothing\n",
    "    \"\"\"\n",
    "    return func\n",
    "\n",
    "def set_speed_mode(mode):\n",
    "    \"\"\"\n",
    "    Function to change \n",
    "    \n",
    "    \"\"\"\n",
    "    global jit_fun\n",
    "    global jit_fun_gpu\n",
    "    global speed_mode\n",
    "    global cupy\n",
    "    \n",
    "    speed_mode = mode\n",
    "    \n",
    "    if mode == 'python':\n",
    "        jit_fun = dummy_decorator\n",
    "        jit_fun_gpu = dummy_decorator\n",
    "        cupy = numpy_\n",
    "    elif mode == 'numba':\n",
    "        jit_fun = njit\n",
    "        jit_fun_gpu = njit\n",
    "        cupy = numpy_\n",
    "    elif mode == 'numba_gpu':\n",
    "        jit_fun = njit\n",
    "        jit_fun_gpu = cuda.jit(device=True)\n",
    "        if cupy_ is not None:\n",
    "            cupy = cupy_\n",
    "        else:\n",
    "            raise ModuleNotFoundError('Cupy not installed.')\n",
    "    else:\n",
    "        raise NotImplementedError(mode)\n",
    "        \n",
    "        \n",
    "if cupy_ is not None:\n",
    "    set_speed_mode('numba_gpu')\n",
    "else:\n",
    "    set_speed_mode('numba')\n",
    "    \n",
    "@numba.njit\n",
    "def grid_1d(x): return -1\n",
    "@numba.njit\n",
    "def grid_2d(x): return -1, -1\n",
    "\n",
    "def set_cuda_grid(dimensions=0):\n",
    "    global cuda\n",
    "    if dimensions == 0:\n",
    "        cuda = cuda_\n",
    "        cuda.grid = cuda_.grid\n",
    "    if dimensions == 1:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_1d\n",
    "    if dimensions == 2:\n",
    "        cuda = numba_\n",
    "        cuda.grid = grid_2d\n",
    "        \n",
    "        \n",
    "def numba_threaded(_func=None, *, cpu_threads=0):\n",
    "    if cpu_threads <= 0:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "        \n",
    "    def parallel_compiled_func_inner(func):\n",
    "        if speed_mode == 'python':\n",
    "            numba_func = func\n",
    "        else:\n",
    "            numba_func = numba.njit(nogil=True)(func)\n",
    "\n",
    "        def numba_func_parallel(thread, iterable, *args):\n",
    "            for i in range(thread, len(iterable), cpu_threads):\n",
    "                numba_func(i, iterable, *args)\n",
    "\n",
    "        if speed_mode == 'python':\n",
    "            numba_func_parallel = numba_func_parallel\n",
    "        else:\n",
    "            numba_func_parallel = numba.njit(nogil=True)(numba_func_parallel)\n",
    "\n",
    "        def wrapper(iterable, *args):\n",
    "            threads = []\n",
    "            for thread_id in range(cpu_threads):\n",
    "                t = threading.Thread(\n",
    "                    target=numba_func_parallel,\n",
    "                    args=(thread_id, iterable, *args)\n",
    "                )\n",
    "                t.start()\n",
    "                threads.append(t)\n",
    "            for t in threads:\n",
    "                t.join()\n",
    "                del t\n",
    "        return functools.wraps(func)(wrapper)\n",
    "    \n",
    "    if _func is None:\n",
    "        return parallel_compiled_func_inner\n",
    "    else:\n",
    "        return parallel_compiled_func_inner(_func)\n",
    "    \n",
    "     \n",
    "def parallel_compiled_func(\n",
    "    _func=None,\n",
    "    *,\n",
    "    cpu_threads=None,\n",
    "    dimensions=1,\n",
    "):\n",
    "    #set_cuda_grid()\n",
    "    if dimensions not in (1, 2):\n",
    "        raise ValueError(\"Only 1D and 2D are supported\")\n",
    "\n",
    "    if cpu_threads is not None:\n",
    "        use_gpu = False\n",
    "    else:\n",
    "        try:\n",
    "            cuda_.get_current_device()\n",
    "        except cuda_.CudaSupportError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "        else:\n",
    "            use_gpu = True\n",
    "        try:\n",
    "            import cupy\n",
    "        except ModuleNotFoundError:\n",
    "            use_gpu = False\n",
    "            cpu_threads = 0\n",
    "            \n",
    "    if cpu_threads is None:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "        \n",
    "    if cpu_threads <= 0:\n",
    "        cpu_threads = multiprocessing.cpu_count()\n",
    "\n",
    "    if speed_mode == 'numba_gpu':\n",
    "        use_gpu = True\n",
    "    elif speed_mode == 'numba':\n",
    "        use_gpu = False\n",
    "    elif speed_mode == 'python':\n",
    "        use_gpu = False\n",
    "                \n",
    "    if use_gpu:\n",
    "        set_cuda_grid()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            cuda_func = cuda.jit(func)\n",
    "            if dimensions == 1:\n",
    "                def wrapper(iterable_1d, *args):\n",
    "                    cuda_func.forall(iterable_1d.shape[0], 1)(\n",
    "                        -1,\n",
    "                        iterable_1d,\n",
    "                        *args\n",
    "                    )\n",
    "            elif dimensions == 2:\n",
    "                def wrapper(iterable_2d, *args):\n",
    "                    threadsperblock = (\n",
    "                        min(iterable_2d.shape[0], 16),\n",
    "                        min(iterable_2d.shape[0], 16)\n",
    "                    )\n",
    "                    blockspergrid_x = math.ceil(\n",
    "                        iterable_2d.shape[0] / threadsperblock[0]\n",
    "                    )\n",
    "                    blockspergrid_y = math.ceil(\n",
    "                        iterable_2d.shape[1] / threadsperblock[1]\n",
    "                    )\n",
    "                    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "                    cuda_func[blockspergrid, threadsperblock](\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        iterable_2d,\n",
    "                        *args\n",
    "                    )\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    else:\n",
    "        set_cuda_grid(dimensions)\n",
    "        if cpu_threads <= 0:\n",
    "            cpu_threads = multiprocessing.cpu_count()\n",
    "        def parallel_compiled_func_inner(func):\n",
    "            \n",
    "            if speed_mode == 'python':\n",
    "                numba_func = func\n",
    "            else:\n",
    "                numba_func = numba.njit(nogil=True)(func)\n",
    "\n",
    "            if dimensions == 1:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_1d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        len(iterable_1d),\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        numba_func(i, iterable_1d, *args)\n",
    "            elif dimensions == 2:\n",
    "                def numba_func_parallel(\n",
    "                    thread,\n",
    "                    iterable_2d,\n",
    "                    *args\n",
    "                ):\n",
    "                    for i in range(\n",
    "                        thread,\n",
    "                        iterable_2d.shape[0],\n",
    "                        cpu_threads\n",
    "                    ):\n",
    "                        for j in range(iterable_2d.shape[1]):\n",
    "                            numba_func(i, j, iterable_2d, *args)\n",
    "                            \n",
    "            if speed_mode == 'python':\n",
    "                numba_func_parallel = numba_func_parallel\n",
    "            else:\n",
    "                numba_func_parallel = numba.njit(nogil=True)(numba_func_parallel)\n",
    "\n",
    "            def wrapper(iterable, *args):\n",
    "                threads = []\n",
    "                for thread_id in range(cpu_threads):\n",
    "                    t = threading.Thread(\n",
    "                        target=numba_func_parallel,\n",
    "                        args=(thread_id, iterable, *args)\n",
    "                    )\n",
    "                    t.start()\n",
    "                    threads.append(t)\n",
    "                for t in threads:\n",
    "                    t.join()\n",
    "                    del t\n",
    "            return functools.wraps(func)(wrapper)\n",
    "    if _func is None:\n",
    "        return parallel_compiled_func_inner\n",
    "    else:\n",
    "        return parallel_compiled_func_inner(_func)\n",
    "    \n",
    "def set_max_process(a):\n",
    "    max_processes = psutil.cpu_count()\n",
    "    new_max = min(a, max_processes)\n",
    "    \n",
    "    return new_max\n",
    "\n",
    "def AlphaPool(a, *args, **kwargs):  \n",
    "    max_processes = psutil.cpu_count()\n",
    "    if a == -1:\n",
    "        a = max_processes\n",
    "    new_max = min(a, 50, max_processes)\n",
    "    print(f\"AlphaPool was set to {a} processes. Setting max to {new_max}.\")\n",
    "\n",
    "    return Pool(new_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
