{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "\n",
    "> Functions related to the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to the scoring of peptide-spectrum-matches (PSMS).\n",
    "\n",
    "In brief, this notebook includes the following:\n",
    "\n",
    "- Functions for target-decoy based FDR estimation\n",
    "- X!tandem based scoring of PSMs\n",
    "- Machine learning based scoring of PSMs\n",
    "- Protein grouping by the razor approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "The filtering functions are essential base functions for scoring in AlphaPept. They make sure that only the 'best precursor per spectum' and the 'best spectrum per precursor' is used.\n",
    "\n",
    "Recall from the search that when having feautres, `raw_idx` refers to the actual index from the raw data. Otherwise it is`query_data`.\n",
    "\n",
    "For filtering, we have several functions. When applying for a score, we first use `filter_score` and then `filter_precursor`.\n",
    "`filter_score` is keeping the best score per experimental spectrum. First we rank by score for each `query_idx`. As we have multiple hits for each experimental spectrum from the search we only want to keep the best one.\n",
    "\n",
    "When performing feature finding, we assign multiple possible features to each experimental spectrum. The idea here is that a spectrum could originate from various precursors. To disentangle these psms we can use the following modes:\n",
    "\n",
    "* `single`: This mode will only keep one feature per experimental spectrum (the one with the highest score and the closest distance). Each feature can only occur once.\n",
    "* `multiple`: Allow multiple features per experimental spectrum. Each feature can only occur once.\n",
    "\n",
    "`filter_precusor` is intended for the case that a precursor (charge + sequence) occurs more than once. Only the one with the highest score will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'alphapept'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-929d282bf7e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0malphapept\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfilter_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multiple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'alphapept'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import alphapept.io\n",
    "\n",
    "def filter_score(df, mode='multiple'):\n",
    "    \"\"\"\n",
    "    Filter df by score\n",
    "    TODO: PSMS could still have the same score when having modifications at multiple positions that are not distinguishable.\n",
    "    Only keep one.\n",
    "\n",
    "    \"\"\"\n",
    "    df[\"rank\"] = df.groupby(\"query_idx\")[\"score\"].rank(\"dense\", ascending=False).astype(\"int\")\n",
    "    df = df[df[\"rank\"] == 1]\n",
    "\n",
    "    # in case two hits have the same score and therfore rank only accept the first one\n",
    "    df = df.drop_duplicates(\"query_idx\")\n",
    "\n",
    "    if 'dist' in df.columns:\n",
    "        df[\"feature_rank\"] = df.groupby(\"feature_idx\")[\"dist\"].rank(\"dense\", ascending=True).astype(\"int\")\n",
    "        df[\"raw_rank\"] = df.groupby(\"raw_idx\")[\"score\"].rank(\"dense\", ascending=False).astype(\"int\")\n",
    "\n",
    "        if mode == 'single':\n",
    "            df_filtered = df[(df[\"feature_rank\"] == 1) & (df[\"raw_rank\"] == 1) ]\n",
    "            df_filtered = df_filtered.drop_duplicates(\"raw_idx\")\n",
    "\n",
    "        elif mode == 'multiple':\n",
    "            df_filtered = df[(df[\"feature_rank\"] == 1)]\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Mode {} not implemented yet'.format(mode))\n",
    "\n",
    "    else:\n",
    "        df_filtered = df\n",
    "\n",
    "    # TOD: this needs to be sorted out, for modifications -> What if we have MoxM -> oxMM, this will screw up with the filter sequence part\n",
    "    return df_filtered\n",
    "\n",
    "def filter_precursor(df):\n",
    "    \"\"\"\n",
    "    Filter df by precursor\n",
    "    Allow each precursor only once.\n",
    "\n",
    "    \"\"\"\n",
    "    df[\"rank_precursor\"] = (\n",
    "        df.groupby(\"precursor\")[\"score\"].rank(\"dense\", ascending=False).astype(\"int\")\n",
    "    )\n",
    "    df_filtered = df[df[\"rank_precursor\"] == 1]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_q_values` is used to calculate q-values from FDR values. The direct relationship is illustrated further down in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "@njit\n",
    "def get_q_values(fdr_values):\n",
    "    \"\"\"\n",
    "    Calculate q values from fdr_values\n",
    "    \"\"\"\n",
    "    q_values = np.zeros_like(fdr_values)\n",
    "    min_q_value = np.max(fdr_values)\n",
    "    for i in range(len(fdr_values) - 1, -1, -1):\n",
    "        fdr = fdr_values[i]\n",
    "        if fdr < min_q_value:\n",
    "            min_q_value = fdr\n",
    "        q_values[i] = min_q_value\n",
    "\n",
    "    return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR\n",
    "\n",
    "The employed FDR strategy is based on a classical target-decoy competition approach. The procedure works as follows:\n",
    "1. Consider only the best scoring target or decoy PSM per spectrum. \n",
    "2. Sort all PSMs by decreasing scores.\n",
    "3. Estimate the FDR as #decoys / #targets, where #targets (#decoys) is the number of positive target (decoy) PSMs at a given score threshold t (i.e. PSMs with scores higher than t).\n",
    "4. Convert the estimated FDR to q-values by selecting the minimum FDR at which the identification could be made, i.e. the lowest score threshold t that could be set to include an identification without increasing the number of false positives.\n",
    "5. Report the set of target PSMs with q-values smaller or equal to the selected `fdr_level`.\n",
    "\n",
    "Informative literature describing and discussing different FDR estimation approaches for shotgun proteomics can be found here (the implemented strategy in alphapept is referred to as T-TDC in this article):\n",
    "> Keich, Uri et al. \"Improved False Discovery Rate Estimation Procedure for Shotgun Proteomics.\" Journal of proteome research vol. 14,8 (2015): 3148-61. <https://pubs.acs.org/doi/10.1021/acs.jproteome.5b00081>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def cut_fdr(df, fdr_level=0.01, plot=True):\n",
    "    \"\"\"\n",
    "    Cuts a dataframe with a given fdr level\n",
    "\n",
    "    Args:\n",
    "        fdr_level: fdr level that should be used\n",
    "        plot: flag to enable plot\n",
    "\n",
    "    Returns:\n",
    "        cutoff: df with psms within fdr\n",
    "        cutoff_value: numerical value of score cutoff\n",
    "\n",
    "    Raises:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"target\"] = ~df[\"decoy\"]\n",
    "\n",
    "    df = df.sort_values(by=[\"score\",\"decoy\"], ascending=False)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df[\"target_cum\"] = np.cumsum(df[\"target\"])\n",
    "    df[\"decoys_cum\"] = np.cumsum(df[\"decoy\"])\n",
    "\n",
    "    df[\"fdr\"] = df[\"decoys_cum\"] / df[\"target_cum\"]\n",
    "    df[\"q_value\"] = get_q_values(df[\"fdr\"].values)\n",
    "\n",
    "    last_q_value = df[\"q_value\"].iloc[-1]\n",
    "    first_q_value = df[\"q_value\"].iloc[0]\n",
    "\n",
    "    if last_q_value <= fdr_level:\n",
    "        logging.info('Last q_value {:.3f} of dataset is smaller than fdr_level {:.3f}'.format(last_q_value, fdr_level))\n",
    "        cutoff_index = len(df)-1\n",
    "\n",
    "    elif first_q_value >= fdr_level:\n",
    "        logging.info('First q_value {:.3f} of dataset is larger than fdr_level {:.3f}'.format(last_q_value, fdr_level))\n",
    "        cutoff_index = 0\n",
    "\n",
    "    else:\n",
    "        cutoff_index = df[df[\"q_value\"].gt(fdr_level)].index[0] - 1\n",
    "\n",
    "    cutoff_value = df.loc[cutoff_index][\"score\"]\n",
    "    cutoff = df[df[\"score\"] >= cutoff_value]\n",
    "\n",
    "    targets = df.loc[cutoff_index, \"target_cum\"]\n",
    "    decoy = df.loc[cutoff_index, \"decoys_cum\"]\n",
    "\n",
    "    fdr = df.loc[cutoff_index, \"fdr\"]\n",
    "\n",
    "    \n",
    "    logging.info(f\"{targets:,} target ({decoy:,} decoy) of {len(df)} PSMs. fdr {fdr:.6f} for a cutoff of {cutoff_value:.2f} (set fdr was {fdr_level})\")\n",
    "\n",
    "    if plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df[\"score\"], df[\"fdr\"])\n",
    "        plt.axhline(0.01, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "        plt.axvline(cutoff_value, color=\"r\", linestyle=\"--\")\n",
    "        plt.title(\"fdr vs Cutoff value\")\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"fdr\")\n",
    "        # plt.savefig('fdr.png')\n",
    "        plt.show()\n",
    "\n",
    "        bins = np.linspace(np.min(df[\"score\"]), np.max(df[\"score\"]), 100)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.distplot(df[df[\"decoy\"]][\"score\"].values, label=\"decoy\", bins=bins)\n",
    "        sns.distplot(df[~df[\"decoy\"]][\"score\"].values, label=\"target\", bins=bins)\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Score vs Class\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    cutoff = cutoff.reset_index(drop=True)\n",
    "    return cutoff_value, cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulateTargetDecoyScores(n, target_mu=4.0, stdev=1.0, pi0=0.5):\n",
    "    decoys = np.random.normal(loc=0.0, scale=stdev, size=n)\n",
    "    false_targets = np.random.normal(loc=0.0, scale=stdev, size=int(np.round(n*pi0)))\n",
    "    true_targets = np.random.normal(loc=target_mu, scale=stdev, size=int(np.round(n*(1-pi0))))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'TD':np.append(np.append(np.repeat('TT',len(true_targets)),np.repeat('FT',len(false_targets))),np.repeat('D',len(decoys))),\n",
    "        'decoy':np.append(np.repeat(False,len(true_targets)+len(false_targets)), np.repeat(True,len(decoys))),\n",
    "        'score':np.append(np.append(true_targets,false_targets),decoys),\n",
    "        'sequence':np.append(np.arange(0,n),np.arange(0,n)),\n",
    "        'protein':np.append(np.arange(0,n),np.arange(0,n))})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def simulateProteinLevelTargetDecoyScores(n, target_mu=4.0, stdev=1.0, pi0=0.5, plot=True):\n",
    "    idx = np.arange(0,n)\n",
    "\n",
    "    protein_size = np.random.poisson(lam=3.0, size=n) + 1\n",
    "    \n",
    "    if plot:\n",
    "        plt.hist(protein_size)\n",
    "        plt.title(\"Number of peptides per protein\")\n",
    "        plt.xlabel(\"Number of peptides per protein\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "    TT_protein_size = protein_size[idx[0:int(np.round(1-(n*pi0)))]]\n",
    "    FT_protein_size = protein_size[idx[int(np.round(1-(n*pi0))):n]]\n",
    "    D_protein_size = protein_size\n",
    "\n",
    "    true_targets = np.random.normal(loc=target_mu, scale=stdev, size=sum(TT_protein_size))\n",
    "    false_targets = np.random.normal(loc=0.0, scale=stdev, size=sum(FT_protein_size))\n",
    "    decoys = np.random.normal(loc=0.0, scale=stdev, size=sum(D_protein_size))\n",
    "\n",
    "    D_proteins = np.repeat(idx,D_protein_size)\n",
    "    TT_proteins = np.repeat(idx[0:int(np.round(1-(n*pi0)))],TT_protein_size)\n",
    "    FT_proteins = np.repeat(idx[int(np.round(1-(n*pi0))):n],FT_protein_size)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'TD':np.append(np.append(np.repeat('TT',len(TT_proteins)),np.repeat('FT',len(FT_proteins))),np.repeat('D',len(D_proteins))),\n",
    "        'decoy':np.append(np.repeat(False,len(TT_proteins)+len(FT_proteins)), np.repeat(True,len(D_proteins))),\n",
    "        'score':np.append(np.append(true_targets,false_targets),decoys),\n",
    "        'sequence':np.append(np.arange(0,sum(protein_size)),np.arange(0,sum(protein_size))),\n",
    "        'protein':np.append(np.append(TT_proteins,FT_proteins),D_proteins)})\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_score_hist(df, analyte_level='sequence'):\n",
    "    \n",
    "    if analyte_level=='protein':\n",
    "        df = df.sort_values(by=['protein','score'], ascending=False)\n",
    "        df = df.drop_duplicates(subset='protein', keep=\"first\")\n",
    "    \n",
    "    decoys=df[df.decoy].score.values\n",
    "    false_targets= df[df.TD == 'FT'].score.values\n",
    "    true_targets= df[df.TD == 'TT'].score.values\n",
    "    \n",
    "    minS = int(np.round(np.min(np.append(decoys, np.append(false_targets, true_targets)))))\n",
    "    maxS = int(np.round(np.max(np.append(decoys, np.append(false_targets, true_targets)))))\n",
    "    \n",
    "    plt.hist(false_targets, rwidth=.4, bins=range(minS,maxS), range=[minS,maxS], align='mid', label='false targets')\n",
    "    plt.hist(true_targets, rwidth=.4, bins=range(minS,maxS), range=[minS,maxS], align='mid', label='true targets')\n",
    "    plt.hist(decoys, rwidth=.4, bins=range(minS,maxS), range=[minS,maxS], align='left', label='decoys')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"score histogram\")\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.xlim(-5,10)\n",
    "    plt.show()\n",
    "\n",
    "def score_TDcompetition(df):\n",
    "    td_dataframe = pd.DataFrame({'T':df[~df.decoy].score.values, 'D':df[df.decoy].score.values, 'label':df[~df.decoy].TD.values})\n",
    "    td_dataframe['win'] = td_dataframe.apply(lambda x: 'T' if x['T'] > x['D'] else 'D', axis = 1)\n",
    "\n",
    "    target_in = np.where(td_dataframe.win=='T')\n",
    "    decoy_in = np.where(td_dataframe.win=='D')\n",
    "\n",
    "    T_df = df[(~df.decoy) & (np.isin(df.sequence, target_in))]\n",
    "    D_df = df[(df.decoy) & (np.isin(df.sequence, decoy_in))]\n",
    "    \n",
    "    df = T_df.append(D_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_simulated_stat_rates(df, TDcompetition = False, analyte_level='sequence', df_ini = None):\n",
    "    alpha = np.arange(0.002,1,0.002)\n",
    "    stat_rates = pd.DataFrame(columns=['alpha','TP','FP','TN','FN','TPR','FPR','FDR','FNR','ACC'])\n",
    "\n",
    "    if analyte_level=='protein':\n",
    "        df = df.drop_duplicates(subset='protein', keep=\"first\")\n",
    "        \n",
    "    for idx in range(len(alpha)):\n",
    "        sig = df[df.q_value <= alpha[idx]]\n",
    "        not_sig = df[df.q_value > alpha[idx]]\n",
    "\n",
    "        TP = len(sig[sig.TD == 'TT'][analyte_level].unique())\n",
    "        FP = len(sig[sig.TD == 'FT'][analyte_level].unique())\n",
    "        TN = len(not_sig[not_sig.TD == 'FT'][analyte_level].unique())\n",
    "        FN = len(not_sig[not_sig.TD == 'TT'][analyte_level].unique())\n",
    "        \n",
    "        if TDcompetition:\n",
    "            TN = TN + (len(df_ini[df_ini.TD == 'FT'][analyte_level].unique()) - len(df[df.TD == 'FT'][analyte_level].unique()))\n",
    "            FN = FN + (len(df_ini[df_ini.TD == 'TT'][analyte_level].unique()) - len(df[df.TD == 'TT'][analyte_level].unique()))\n",
    "\n",
    "\n",
    "        TPR = TP/(TP+FN) \n",
    "        FPR = FP/(FP+TN) \n",
    "        if (FP+TP)==0:\n",
    "            FDR = 0\n",
    "        else:\n",
    "            FDR = FP/(FP+TP)\n",
    "        FNR = FN/(FN+TP)\n",
    "\n",
    "        ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "        stat_rates.loc[idx] = [alpha[idx], TP, FP, TN, FN, TPR, FPR, FDR, FNR, ACC] \n",
    "    \n",
    "    border = 0.1\n",
    "    \n",
    "    plt.plot([-1,2], [-1,2], linestyle=\"--\", color='red')\n",
    "    plt.scatter(stat_rates.alpha, stat_rates.FDR)\n",
    "    plt.ylim(0-border,1+border)\n",
    "    plt.xlim(0-border,1+border)\n",
    "    plt.title(\"decoy vs. true FDR\")\n",
    "    plt.xlabel(\"decoy FDR\")\n",
    "    plt.ylabel(\"true FDR\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot([-1,1], [-1,1], linestyle=\"--\", color='red')\n",
    "    plt.scatter(stat_rates.alpha, stat_rates.FDR)\n",
    "    plt.ylim(0-(0.01),0.1+(0.01))\n",
    "    plt.xlim(0-(0.01),0.1+(0.01))\n",
    "    plt.title(\"decoy vs. true FDR (zoom)\")\n",
    "    plt.xlabel(\"decoy FDR\")\n",
    "    plt.ylabel(\"true FDR\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot([-1,2], [1,1], linestyle=\"--\", color='red')\n",
    "    plt.scatter(stat_rates.FPR, stat_rates.TPR)\n",
    "    plt.ylim(0-border,1+border)\n",
    "    plt.xlim(0-border,1+border)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot([-1,2], [1,1], linestyle=\"--\", color='red')\n",
    "    plt.scatter(stat_rates.FPR, stat_rates.TPR)\n",
    "    plt.ylim(0-border,1+border)\n",
    "    plt.xlim(0-0.01,0.1+0.01)\n",
    "    plt.title(\"ROC curve (zoom)\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.show()\n",
    "    \n",
    "    return stat_rates\n",
    "\n",
    "def plot_qvalue_vs_fdr(df):\n",
    "    plt.plot(df.fdr, df.target_cum, label='FDR')\n",
    "    plt.plot(df.q_value, df.target_cum, label='q-value')\n",
    "    plt.xlim(0-0.0001,0.005)\n",
    "    plt.ylim(0-100,7000)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Difference between q-value and FDR\")\n",
    "    plt.xlabel(\"q-value / FDR\")\n",
    "    plt.ylabel(\"Cummulative number of accepted targets\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "TD = simulateTargetDecoyScores(n=50000, pi0=0.8, target_mu=3.5)\n",
    "TDC = score_TDcompetition(TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation of random scores for 50'000 measurements (corresponding to spectra). Simulated are decoys, true targets and false targets. We assume a false traget raio (pi0) of 0.8 and a mean score difference of 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated score distribution for a separate target and decoy database search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "plot_score_hist(TD, analyte_level='sequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated score distribution for a corresponding concatinated target-decoy database search with target-decoy-competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "plot_score_hist(TDC, analyte_level='sequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of the `cut_fdr` function to the simulated target-decoy competition dataset saved in `TDC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cval, cut_TDC = cut_fdr(TDC, fdr_level=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the FDR estimated by the target-decoy approach versus the true FDR confirms accurate FDR estimation by our approach. The true FDR is capped by the selected fraction of false targets (pi0 = 0.8) and by the effect of target decoy competition. Similarly, the true positive rate (TPR) is limited by the effect of target decoy competition and can only reach 1 in cases where not a single decoy scores higher than a true target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "cval_, cut_TDC_ = cut_fdr(TDC, fdr_level=100, plot=False)\n",
    "stat = get_simulated_stat_rates(cut_TDC_, TDcompetition = True, analyte_level='sequence', df_ini = TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure illustrates the difference between `fdr` and `q_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "plot_qvalue_vs_fdr(cut_TDC_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware that the shown simulations are not an accurate model for PSMS scoring and they were designed only for illustrative purposes and to test the implemeted functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global FDR\n",
    "\n",
    "The `cut_global_fdr` function has two specific applications:\n",
    "1. **Estimate q-values on the peptide and protein level** <br/>\n",
    "The concept here is based on selecting the best scoring precursor per peptide (or protein) to then estimate the FDR by target-decoy competition using the `cut_fdr` function.\n",
    "2. **Estimate q-values across an entire dataset on either precursor, peptide or protein level** <br/>\n",
    "The concept here is based on selecting the best scoring precursor, peptide or protein signal across an entire dataset to then estimate the FDR by target-decoy competition using the `cut_fdr` function.\n",
    "\n",
    "This strategy was extensively tested and discussed in the following publications:\n",
    "> Nesvizhskii, Alexey I. \"A survey of computational methods and error rate estimation procedures for peptide and protein identification in shotgun proteomics.\" Journal of proteomics vol. 73,11 (2010): 2092-123. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2956504/> \n",
    "\n",
    "> Savitski, Mikhail M et al. \"A Scalable Approach for Protein False Discovery Rate Estimation in Large Proteomic Data Sets.\" Molecular & cellular proteomics : MCP vol. 14,9 (2015): 2394-404. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4563723/>\n",
    "\n",
    "> The, Matthew et al. \"Fast and Accurate Protein False Discovery Rates on Large-Scale Proteomics Data Sets with Percolator 3.0.\" Journal of the American Society for Mass Spectrometry vol. 27,11 (2016): 1719-1727. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5059416/>\n",
    "\n",
    "> Gupta, Nitin, and Pavel A Pevzner. \"False discovery rates of protein identifications: a strike against the two-peptide rule.\" Journal of proteome research vol. 8,9 (2009): 4173-81. \n",
    "<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3398614/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def cut_global_fdr(data, analyte_level='sequence', fdr_level=0.01, plot=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to estimate and filter by global peptide or protein fdr\n",
    "\n",
    "    \"\"\"\n",
    "    logging.info('Global FDR on {}'.format(analyte_level))\n",
    "    data_sub = data[[analyte_level,'score','decoy']]\n",
    "    data_sub_unique = data_sub.groupby([analyte_level,'decoy'], as_index=False).agg({\"score\": \"max\"})\n",
    "\n",
    "    analyte_levels = ['precursor', 'sequence', 'protein']\n",
    "\n",
    "    if analyte_level in analyte_levels:\n",
    "        agg_score = data_sub_unique.groupby([analyte_level,'decoy'])['score'].max().reset_index()\n",
    "    else:\n",
    "        raise Exception('analyte_level should be either sequence or protein. The selected analyte_level was: {}'.format(analyte_level))\n",
    "\n",
    "    agg_cval, agg_cutoff = cut_fdr(agg_score, fdr_level=fdr_level, plot=plot)\n",
    "\n",
    "    agg_report = pd.merge(data,\n",
    "                          agg_cutoff,\n",
    "                          how = 'inner',\n",
    "                          on = [analyte_level,'decoy'],\n",
    "                          suffixes=('', '_'+analyte_level),\n",
    "                          validate=\"many_to_one\")\n",
    "    return agg_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the sequence level simulations we can simulatae score distributions for peptides beloning to proteins. In our simulation we assumed a poisson distribution for the number of peptides for each protein centered at 4 peptides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "TD_prot = simulateProteinLevelTargetDecoyScores(n=8000, pi0=0.8, target_mu=3.5)\n",
    "\n",
    "TDC_prot = score_TDcompetition(TD_prot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of the `cut_global_fdr` function to the simulated protein-level target-decoy competition dataset saved in `TDC_prot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_TDC_prot = cut_global_fdr(TDC_prot, fdr_level=0.01, analyte_level='protein')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the protein-level FDR estimated by the target-decoy approach versus the true FDR confirms accurate FDR estimation by our approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "cut_TDC_prot_ = cut_global_fdr(TDC_prot, fdr_level=100, analyte_level='protein', plot=False)\n",
    "stat_prot = get_simulated_stat_rates(cut_TDC_prot_, TDcompetition = True, analyte_level='protein', df_ini = TD_prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the peptide-level statistics after protein-level FDR filtering shows a conservative pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "stat_prot = get_simulated_stat_rates(cut_TDC_prot_, TDcompetition = True, analyte_level='sequence', df_ini = TD_prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware that the shown simulations are not an accurate model for PSMS scoring and they were designed only for illustrative purposes and to test the implemeted functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X!tandem scoring\n",
    "\n",
    "* `get_x_tandem_score` performs scoring of PSMs according to the X!tandem strategy:\n",
    "\n",
    "* `score_x_tandem` first calls `get_x_tandem_score` and and subsequently applies the `cut_fdr` function to filter PSMs at the specified `fdr_level`.\n",
    "\n",
    "> X!Tandem, Craig,R. and Beavis,R.C. (2003) Rapid Commun. Mass Spectrom., 17, 2310-2316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def get_x_tandem_score(df):\n",
    "\n",
    "    b = df['b_hits'].astype('int').apply(lambda x: np.math.factorial(x)).values\n",
    "    y = df['y_hits'].astype('int').apply(lambda x: np.math.factorial(x)).values\n",
    "    x_tandem = np.log(b.astype('float')*y.astype('float')*df['matched_int'].values)\n",
    "\n",
    "    x_tandem[x_tandem==-np.inf] = 0\n",
    "\n",
    "    return x_tandem\n",
    "\n",
    "def score_x_tandem(df, fdr_level = 0.01, plot = True, **kwargs):\n",
    "    logging.info('Scoring using X-Tandem')\n",
    "    df['score'] = get_x_tandem_score(df)\n",
    "    df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "\n",
    "    df = filter_score(df)\n",
    "    df = filter_precursor(df)\n",
    "    cval, cutoff = cut_fdr(df, fdr_level, plot)\n",
    "\n",
    "    return cutoff\n",
    "\n",
    "def filter_with_x_tandem(df, fdr_level = 0.01):\n",
    "    \"\"\"\n",
    "    Filters a dataframe using an x_tandem score\n",
    "    \"\"\"\n",
    "    logging.info('Filter df with x_tandem score')\n",
    "\n",
    "    df['score'] = get_x_tandem_score(df)\n",
    "    df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "\n",
    "    df = filter_score(df)\n",
    "    df = filter_precursor(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_get_x_tandem_score():\n",
    "    y_hits = np.array([1,2,3,0])\n",
    "    b_hits = np.array([0,1,2,1])\n",
    "    matched_int = np.array([1000,1000,1000,1000])\n",
    "    df = pd.DataFrame({'y_hits':y_hits,'b_hits':b_hits,'matched_int':matched_int})\n",
    "    np.testing.assert_almost_equal(get_x_tandem_score(df), np.array([6.90775528, 7.60090246, 9.39266193, 6.90775528]))\n",
    "\n",
    "test_get_x_tandem_score()\n",
    "\n",
    "def test_score_x_tandem():\n",
    "    y_hits = np.array([1,2,3,0])\n",
    "    b_hits = np.array([0,1,2,1])\n",
    "    matched_int = np.array([1000,1000,1000,1000])\n",
    "    sequence = np.array(['A','A','B','C_decoy'])\n",
    "    precursor = np.array(['A1','A1','B','C_decoy'])\n",
    "    query_idx = np.array([1,2,3,4])\n",
    "    df = pd.DataFrame({'y_hits':y_hits,'b_hits':b_hits,'matched_int':matched_int,\n",
    "                      'sequence':sequence,'precursor':precursor,'query_idx':query_idx})\n",
    "    res = score_x_tandem(df, fdr_level=1, plot=False)\n",
    "    assert all(res.precursor == ['B','A1','C_decoy'])\n",
    "    assert all(res.q_value == [0,0,0.5])\n",
    "\n",
    "test_score_x_tandem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score and filter PSMs by any specified score\n",
    "\n",
    "`score_psms` uses the specified `score` and applies the `cut_fdr` function to filter PSMs at the specified `fdr_level`. `filter_score` and `filter_precursor` are applied to only report the best PSM per acquired spectrum and the best signal per precursor (i.e. sequence + charge combination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def score_psms(df, score = 'y_hits', fdr_level = 0.01, plot = True, **kwargs):\n",
    "    if score in df.columns:\n",
    "        df['score'] = df[score]\n",
    "    else:\n",
    "        raise ValueError(\"The specified 'score' {} is not available in 'df'.\".format(score))\n",
    "    df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "\n",
    "    df = filter_score(df)\n",
    "    df = filter_precursor(df)\n",
    "    cval, cutoff = cut_fdr(df, fdr_level, plot)\n",
    "\n",
    "    return cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_score_psms():\n",
    "    y_hits = np.array([1,2,3,0])\n",
    "    b_hits = np.array([0,1,2,1])\n",
    "    matched_int = np.array([1000,1000,1000,1000])\n",
    "    sequence = np.array(['A','A','B','C_decoy'])\n",
    "    precursor = np.array(['A1','A1','B','C_decoy'])\n",
    "    query_idx = np.array([1,2,3,4])\n",
    "    df = pd.DataFrame({'y_hits':y_hits,'b_hits':b_hits,'matched_int':matched_int,\n",
    "                      'sequence':sequence,'precursor':precursor,'query_idx':query_idx})\n",
    "    \n",
    "    res = score_psms(df, fdr_level=1, plot=False)\n",
    "    assert all(res.precursor == ['B','A1','C_decoy'])\n",
    "    assert all(res.q_value == [0,0,0.5])\n",
    "    \n",
    "    res = score_psms(df, score='b_hits', fdr_level=1, plot=False)\n",
    "    assert all(res.precursor == ['B','C_decoy','A1'])\n",
    "    assert all(res.q_value == [0,0.5,0.5])\n",
    "\n",
    "test_score_x_tandem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning based scoring of PSMs\n",
    "\n",
    "* `get_ML_features` extracts additional scoring metrics for the machine learning, including the number of amino acids per precursor, the number of missed cleavages and the logarithmic number of times the same peptide occurs in the set of PSMs\n",
    "\n",
    "* `train_RF` trains a random forest classifier for scoring all PSMs. For this, we use the scikit-learn library.\n",
    "    * First, a machine learning pipeline is created including the sklearn `StandardScaler` and `RandomForestClassifier`. The `StandardScaler` is used to standardize all features by removing the mean and scaling to unit variance. For details on the `RandomForestClassifier` see: <https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>.\n",
    "    * Next, a grid search is initialized for testing the hyperparameter space (`max_depth` and `max_leaf_nodes`) of the random forest classifier by a 5-fold cross-validation using `GridSearchCV`.\n",
    "    * To train the classifier, we first select a suitable set of PSMSs. This is achieved by an initial scoring and FDR estimation of the input PSMs based on the `ini_score`. Only targets below the `train_fdr_level` cutoff are considered for training the classifier. To ensure a balanced dataset for training (i.e. same number of targets and decoys), the number of PSMs per category is selected to be the minimum of either the number of high scoring targets below the `train_fdr_level` cutoff or the overall number of decoys among the PSMs. `min_train` specifies the minimum number of targets and decoys that should be available. \n",
    "    * Once a balanced set of PSMs is established, the PSMs are split into a training and test set accoring to the `test_size` argument using `train_test_split` from sklearn while ensuring the PSMs are split in a stratified fashion (i.e. equal number of targets and decoys in both the training and test sets).\n",
    "    * The grid search and training of the random forest classifier is performed on the training set of PSMs. The `GridSearchCV` returns the classifier which performed best across all cross-validation hold-out sets according to the `scoring` function (classification *'accuracy'* is set as default score). The grid search is parallelize dinto `n_jobs`.\n",
    "    * Next, the trained classifier is applied to the testing set of PSMs and the test score is reported. \n",
    "    * If `plot` is enabled, a figure illustrating the weights of each feature is produced.\n",
    "    * Finally the function returns the trained random forest classifier for subsequent application to the entire set of PSMs or for transfering to a different dataset. \n",
    "\n",
    "* `score_ML` applies a classifier trained by `train_RF` to a complete set of PSMs. It calls the `cut_fdr` function and filters for the specified `fdr_level`. `filter_score` and `filter_precursor` are applied to only report the best PSM per acquired spectrum and the best signal per precursor (i.e. sequence + charge combination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from alphapept.fasta import count_missed_cleavages, count_internal_cleavages\n",
    "\n",
    "\n",
    "def get_ML_features(df, protease='trypsin', **kwargs):\n",
    "    df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "\n",
    "    df['abs_delta_m_ppm'] = np.abs(df['delta_m_ppm'])\n",
    "    df['naked_sequence'] = df['sequence'].str.replace('[a-z]|_', '')\n",
    "    df['n_AA']= df['naked_sequence'].str.len()\n",
    "    df['matched_ion_fraction'] = df['hits']/(2*df['n_AA'])\n",
    "\n",
    "    df['n_missed'] = df['naked_sequence'].apply(lambda x: count_missed_cleavages(x, protease))\n",
    "    df['n_internal'] = df['naked_sequence'].apply(lambda x: count_internal_cleavages(x, protease))\n",
    "    \n",
    "    df['x_tandem'] = get_x_tandem_score(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_RF(df,\n",
    "             exclude_features = ['precursor_idx','ion_idx','fasta_index','feature_rank','raw_rank','rank','db_idx', 'feature_idx', 'precursor', 'query_idx', 'raw_idx','sequence','decoy','naked_sequence'],\n",
    "             train_fdr_level = 0.1,\n",
    "             ini_score = 'x_tandem',\n",
    "             min_train = 5000,\n",
    "             test_size = 0.8,\n",
    "             max_depth = [5,25,50],\n",
    "             max_leaf_nodes = [150,200,250],\n",
    "             n_jobs=1,\n",
    "             scoring='accuracy',\n",
    "             plot = False,\n",
    "             random_state = 42,\n",
    "             **kwargs):\n",
    "    \n",
    "    features = [_ for _ in df.columns if _ not in exclude_features]\n",
    "\n",
    "    # Setup ML pipeline\n",
    "    scaler = StandardScaler()\n",
    "    rfc = RandomForestClassifier(random_state=random_state) # class_weight={False:1,True:5},\n",
    "    ## Initiate scaling + classification pipeline\n",
    "    pipeline = Pipeline([('scaler', scaler), ('clf', rfc)])\n",
    "    parameters = {'clf__max_depth':(max_depth), 'clf__max_leaf_nodes': (max_leaf_nodes)}\n",
    "    ## Setup grid search framework for parameter selection and internal cross validation\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters, cv=5, scoring=scoring,\n",
    "                     verbose=0,return_train_score=True,n_jobs=n_jobs)\n",
    "\n",
    "    # Prepare target and decoy df\n",
    "    df['decoy'] = df['sequence'].str[-1].str.islower()\n",
    "    df['target'] = ~df['decoy']\n",
    "    df['score'] = df[ini_score]\n",
    "    dfT = df[~df.decoy]\n",
    "    dfD = df[df.decoy]\n",
    "\n",
    "    # Select high scoring targets (<= train_fdr_level)\n",
    "    df_prescore = filter_score(df)\n",
    "    df_prescore = filter_precursor(df_prescore)\n",
    "    scored = cut_fdr(df_prescore, fdr_level = train_fdr_level, plot=False)[1]\n",
    "    highT = scored[scored.decoy==False]\n",
    "    dfT_high = dfT[dfT['query_idx'].isin(highT.query_idx)]\n",
    "    dfT_high = dfT_high[dfT_high['db_idx'].isin(highT.db_idx)]\n",
    "\n",
    "    # Determine the number of psms for semi-supervised learning\n",
    "    n_train = int(dfT_high.shape[0])\n",
    "    if dfD.shape[0] < n_train:\n",
    "        n_train = int(dfD.shape[0])\n",
    "        logging.info(\"The total number of available decoys is lower than the initial set of high scoring targets.\")\n",
    "    if n_train < min_train:\n",
    "        raise ValueError(\"There are fewer high scoring targets or decoys than required by 'min_train'.\")\n",
    "\n",
    "    # Subset the targets and decoys datasets to result in a balanced dataset\n",
    "    df_training = dfT_high.sample(n=n_train, random_state=random_state).append(dfD.sample(n=n_train, random_state=random_state))\n",
    "\n",
    "    # Select training and test sets\n",
    "    X = df_training[features]\n",
    "    y = df_training['target'].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=test_size, random_state=random_state, stratify=y.values)\n",
    "\n",
    "    # Train the classifier on the training set via 5-fold cross-validation and subsequently test on the test set\n",
    "    logging.info('Training & cross-validation on {} targets and {} decoys'.format(np.sum(y_train),X_train.shape[0]-np.sum(y_train)))\n",
    "    cv.fit(X_train,y_train)\n",
    "\n",
    "    logging.info('The best parameters selected by 5-fold cross-validation were {}'.format(cv.best_params_))\n",
    "    logging.info('The train {} was {}'.format(scoring, cv.score(X_train, y_train)))\n",
    "    logging.info('Testing on {} targets and {} decoys'.format(np.sum(y_test),X_test.shape[0]-np.sum(y_test)))\n",
    "    logging.info('The test {} was {}'.format(scoring, cv.score(X_test, y_test)))\n",
    "    \n",
    "    feature_importances=cv.best_estimator_.named_steps['clf'].feature_importances_\n",
    "    indices = np.argsort(feature_importances)[::-1][:40]\n",
    "    \n",
    "    top_features = X.columns[indices][:40]\n",
    "    top_score = feature_importances[indices][:40]\n",
    "    \n",
    "    feature_dict = dict(zip(top_features, top_score))\n",
    "    logging.info(f\"Top features {feature_dict}\")\n",
    "    \n",
    "    # Inspect feature importances\n",
    "    if plot:\n",
    "        g = sns.barplot(y=X.columns[indices][:40],\n",
    "                        x = feature_importances[indices][:40],\n",
    "                        orient='h', palette='RdBu')\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(\"Feature importance\")\n",
    "        plt.show()\n",
    "\n",
    "    return cv, features\n",
    "\n",
    "def score_ML(df,\n",
    "             trained_classifier,\n",
    "             features = None,\n",
    "            fdr_level = 0.01,\n",
    "            plot=True,\n",
    "             **kwargs):\n",
    "    \n",
    "    logging.info('Scoring using Machine Learning')\n",
    "    # Apply the classifier to the entire dataset\n",
    "    df_new = df.copy()\n",
    "    df_new['score'] = trained_classifier.predict_proba(df_new[features])[:,1]\n",
    "    df_new = filter_score(df_new)\n",
    "    df_new = filter_precursor(df_new)\n",
    "    cval, cutoff = cut_fdr(df_new, fdr_level, plot)\n",
    "\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def filter_with_ML(df,\n",
    "             trained_classifier,\n",
    "             features = None,\n",
    "            fdr_level = 0.01,\n",
    "            plot=True,\n",
    "             **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Filters a dataframe using ML\n",
    "    \"\"\"\n",
    "    logging.info('Filter df with x_tandem score')\n",
    "    # Apply the classifier to the entire dataset\n",
    "    df_new = df.copy()\n",
    "    df_new['score'] = trained_classifier.predict_proba(df_new[features])[:,1]\n",
    "    df_new = filter_score(df_new)\n",
    "    df_new = filter_precursor(df_new)\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein grouping\n",
    "\n",
    "For protein grouping, we implement a razor approach. Here, we check whether a protein has unique PSMs, meaning that the peptide can only belong to one protein. For all ambiguous proteins, were PSMs could be shared between multiple proteins, we employ the razor-approach, which is implemented with the networkx-package.\n",
    "\n",
    "We create a network and add all connections between the peptides and proteins. Then, we extract all connected components, referring to all peptides and proteins that are connected. For a cluster of connected components, we then iterate over all proteins and count the number of peptides that are connected to the particular protein. The protein with the most peptides will then be the razor protein. We remove this protein and the respective peptides and continue with the extraction from the cluster until no more peptides are present.\n",
    "\n",
    "For efficient implementation, the proteins and peptides are encoded as indexes. To distinguish proteins from peptides, proteins are have a leading 'p'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import networkx as nx\n",
    "def get_protein_groups(data, pept_dict, fasta_dict, callback = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to perform protein grouping by razor approach\n",
    "    ToDo: implement callback for solving\n",
    "    Each protein is indicated with a p -> protein index\n",
    "    \"\"\"\n",
    "    G=nx.Graph()\n",
    "\n",
    "    found_proteins = {}\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line = data.iloc[i]\n",
    "        seq = line['sequence']\n",
    "        score = line['score']\n",
    "        if seq in pept_dict:\n",
    "            proteins = pept_dict[seq]\n",
    "            if len(proteins) > 1:\n",
    "                for protein in proteins:\n",
    "                    G.add_edge(str(i), 'p'+str(protein), score=score)\n",
    "            else: #if there is only one PSM just add to this protein\n",
    "                if 'p'+str(proteins[0]) in found_proteins.keys():\n",
    "                    found_proteins['p'+str(proteins[0])] = found_proteins['p'+str(proteins[0])] + [str(i)]\n",
    "                else:\n",
    "                    found_proteins['p'+str(proteins[0])] = [str(i)]\n",
    "\n",
    "        if callback:\n",
    "            callback((i+1)/len(data))\n",
    "\n",
    "    logging.info('A total of {:,} proteins with unique PSMs found'.format(len(found_proteins)))\n",
    "\n",
    "    connected_groups = np.array([list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)], dtype=object)\n",
    "    n_groups = len(connected_groups)\n",
    "\n",
    "\n",
    "    logging.info('A total of {} ambigious proteins'.format(len(connected_groups)))\n",
    "\n",
    "    #Solving with razor:\n",
    "    found_proteins_razor = {}\n",
    "    for a in connected_groups:\n",
    "        H = G.subgraph(a)\n",
    "\n",
    "        shared_proteins = list(np.array(a)[np.array(list(i[0] == 'p' for i in a))])\n",
    "\n",
    "        removed = []\n",
    "\n",
    "        while len(shared_proteins) > 0:\n",
    "\n",
    "            neighbors_list = []\n",
    "\n",
    "            for node in shared_proteins:\n",
    "                neighbors = list(H.neighbors(node))\n",
    "                n_neigbhors = len(neighbors)\n",
    "\n",
    "                if node in G:\n",
    "                    if node in found_proteins.keys():\n",
    "                        n_neigbhors+= len(found_proteins[node])\n",
    "\n",
    "                neighbors_list.append((n_neigbhors, node, neighbors))\n",
    "\n",
    "            neighbors_list.sort()\n",
    "\n",
    "            #Remove the last entry:\n",
    "\n",
    "            count, node, psms = neighbors_list[-1]\n",
    "\n",
    "            shared_proteins.remove(node)\n",
    "\n",
    "            psms = [_ for _ in psms if _ not in removed]\n",
    "\n",
    "            removed += psms\n",
    "\n",
    "            found_proteins_razor[node] = psms\n",
    "\n",
    "    #Put back in Df\n",
    "    report = data.copy()\n",
    "    report['protein'] = ''\n",
    "    report['protein_group'] = ''\n",
    "\n",
    "    for protein_str in found_proteins.keys():\n",
    "        protein = int(protein_str[1:])\n",
    "        indexes = [int(_) for _ in found_proteins[protein_str]]\n",
    "        report.loc[indexes, 'protein'] = fasta_dict[protein]['name']\n",
    "        report.loc[indexes, 'protein_group'] = fasta_dict[protein]['name']\n",
    "\n",
    "    report['razor'] = False\n",
    "    for protein_str in found_proteins_razor.keys():\n",
    "        protein = int(protein_str[1:])\n",
    "        indexes = [int(_) for _ in found_proteins_razor[protein_str]]\n",
    "\n",
    "        report.loc[indexes, 'protein'] = fasta_dict[protein]['name']\n",
    "        report.loc[indexes, 'razor'] = True\n",
    "\n",
    "    for a in connected_groups:\n",
    "        protein_group = list(np.array(a)[np.array(list(i[0] == 'p' for i in a))])\n",
    "        psms = [int(i) for i in a if i not in protein_group]\n",
    "        report.loc[psms, 'protein_group'] = ','.join([fasta_dict[int(_[1:])]['name'] for _ in protein_group])\n",
    "\n",
    "    return report\n",
    "\n",
    "def perform_protein_grouping(data, pept_dict, fasta_dict, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper function to perform protein grouping by razor approach\n",
    "\n",
    "    \"\"\"\n",
    "    data_sub = data[['sequence','score','decoy']]\n",
    "    data_sub_unique = data_sub.groupby(['sequence','decoy'], as_index=False).agg({\"score\": \"max\"})\n",
    "\n",
    "    targets = data_sub_unique[data_sub_unique.decoy == False]\n",
    "    targets = targets.reset_index(drop=True)\n",
    "    protein_targets = get_protein_groups(targets, pept_dict, fasta_dict, **kwargs)\n",
    "\n",
    "    decoys = data_sub_unique[data_sub_unique.decoy == True]\n",
    "    decoys = decoys.reset_index(drop=True)\n",
    "    protein_decoys = get_protein_groups(decoys, pept_dict, fasta_dict, **kwargs)\n",
    "\n",
    "    protein_groups = protein_targets.append(protein_decoys)\n",
    "    protein_groups_app = protein_groups[['sequence','decoy','protein','protein_group','razor']]\n",
    "    protein_report = pd.merge(data,\n",
    "                                protein_groups_app,\n",
    "                                how = 'inner',\n",
    "                                on = ['sequence','decoy'],\n",
    "                                validate=\"many_to_one\")\n",
    "    return protein_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_protein_groups():\n",
    "    pept_dict = {}\n",
    "\n",
    "    pept_dict['seq0'] = [0] #unique\n",
    "    pept_dict['seq1'] = [1] #unique\n",
    "    pept_dict['seq2'] = [2] #unique\n",
    "    pept_dict['seq3'] = [3] #unique\n",
    "    pept_dict['seq4'] = [4] #unique\n",
    "    pept_dict['seq5'] = [5] #unique\n",
    "    pept_dict['seq345'] = [3,4,5] #multiple\n",
    "    pept_dict['seq34'] = [3,4] #multiple\n",
    "    pept_dict['seq45'] = [4,5] #multiple\n",
    "    pept_dict['seq35'] = [3,5] #multiple\n",
    "\n",
    "    fasta_dict = {}\n",
    "    fasta_dict[0] = {'name':'P0'}\n",
    "    fasta_dict[1] = {'name':'P1'}\n",
    "    fasta_dict[2] = {'name':'P2'}\n",
    "    fasta_dict[3] = {'name':'P3'}\n",
    "    fasta_dict[4] = {'name':'P4'}\n",
    "    fasta_dict[5] = {'name':'P5'}\n",
    "\n",
    "\n",
    "    test_case = ['seq0','seq1','seq2','seq3','seq4','seq5']\n",
    "    data = pd.DataFrame({'sequence':test_case, 'score':[1 for _ in test_case]})\n",
    "    res = get_protein_groups(data, pept_dict, fasta_dict)\n",
    "    assert res['razor'].sum() == 0\n",
    "\n",
    "    #sequence 3,4 & 3,5 are present -> P3 will be razor\n",
    "    test_case = ['seq0','seq1','seq2','seq3','seq4','seq5','seq34','seq35']\n",
    "    data = pd.DataFrame({'sequence':test_case, 'score':[1 for _ in test_case]})\n",
    "    res = get_protein_groups(data, pept_dict, fasta_dict)\n",
    "    assert res[res['sequence'] == 'seq34'][['protein', 'razor']].values.tolist()[0] == ['P3', True]\n",
    "    assert res[res['sequence'] == 'seq35'][['protein', 'razor']].values.tolist()[0] == ['P3', True]\n",
    "\n",
    "    #sequence 3,4,5 & 3,4, & 4,5 are present -> P4 will be razor\n",
    "    test_case = ['seq0','seq1','seq2','seq3','seq4','seq5','seq345','seq34','seq45']\n",
    "    data = pd.DataFrame({'sequence':test_case, 'score':[1 for _ in test_case]})\n",
    "    res = get_protein_groups(data, pept_dict, fasta_dict)\n",
    "    assert res[res['sequence'] == 'seq345'][['protein', 'razor']].values.tolist()[0] == ['P4', True]\n",
    "    assert res[res['sequence'] == 'seq34'][['protein', 'razor']].values.tolist()[0] == ['P4', True]\n",
    "    assert res[res['sequence'] == 'seq45'][['protein', 'razor']].values.tolist()[0] == ['P4', True]\n",
    "    \n",
    "test_get_protein_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_cut_fdr():\n",
    "    import random\n",
    "    import string\n",
    "    from collections import Counter\n",
    "    # Generate dummy data\n",
    "    n_samples = 10000\n",
    "    test_data = np.random.rand(n_samples)\n",
    "    df = pd.DataFrame(test_data, columns=['score'])\n",
    "    df['decoy'] = (np.random.rand(n_samples) + df['score']) < 0.5\n",
    "\n",
    "    df['filename'] = np.repeat(['file1','file2','file3','file4'], 2500)\n",
    "\n",
    "    sequences = []\n",
    "    i = 0\n",
    "    while i < 5000:\n",
    "        i += 1\n",
    "        sequences.append(''.join(random.choices(string.ascii_uppercase, k=50)))\n",
    "    df['sequence'] = np.random.choice(sequences, 10000, replace=True)\n",
    "\n",
    "    proteins = []\n",
    "    i = 0\n",
    "    while i < 500:\n",
    "        i += 1\n",
    "        proteins.append(''.join(random.choices(string.ascii_uppercase, k=50)))\n",
    "    df['protein'] = np.random.choice(proteins, 10000, replace=True)\n",
    "\n",
    "    for fdr_level in [0.01, 0.02, 0.05, 0.1, 0.2, 0.4]:\n",
    "        cutoff_value, cutoff = cut_fdr(df,fdr_level = fdr_level, plot=False)\n",
    "        assert cutoff.iloc[-1]['fdr'] <= fdr_level\n",
    "        count_fdr = len(cutoff[cutoff.decoy])/len(cutoff[cutoff.target])\n",
    "        assert  count_fdr <= fdr_level\n",
    "        sequence_res = cut_global_fdr(df, plot=False)\n",
    "        sequence_count_fdr = len(np.unique(sequence_res[sequence_res.decoy].sequence))/len(np.unique(sequence_res[~ sequence_res.decoy].sequence))\n",
    "        assert len(np.unique(sequence_res.filename)) == 4\n",
    "        assert Counter(sequence_res.sequence).most_common(1)[0][1] > 1\n",
    "        assert sequence_count_fdr <= fdr_level\n",
    "        protein_res = cut_global_fdr(df, analyte_level=\"protein\", plot=False)\n",
    "        protein_count_fdr = len(np.unique(protein_res[protein_res.decoy].protein))/len(np.unique(protein_res[~ protein_res.decoy].protein))\n",
    "        assert len(np.unique(protein_res.filename)) == 4\n",
    "        assert protein_count_fdr <= fdr_level\n",
    "        assert Counter(protein_res.sequence).most_common(1)[0][1] > 1\n",
    "        \n",
    "test_cut_fdr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def score_hdf(to_process, callback = None, parallel=False):\n",
    "    try:\n",
    "        index, settings = to_process\n",
    "        file_name = settings['experiment']['file_paths'][index]\n",
    "        base_file_name, ext = os.path.splitext(file_name)\n",
    "        ms_file = base_file_name+\".ms_data.hdf\"\n",
    "\n",
    "        skip = False\n",
    "\n",
    "        ms_file_ = alphapept.io.MS_Data_File(ms_file, is_overwritable=True)\n",
    "\n",
    "        try:\n",
    "            df = ms_file_.read(dataset_name='second_search')\n",
    "            logging.info('Found second search psms for scoring.')\n",
    "        except KeyError:\n",
    "            df = ms_file_.read(dataset_name='first_search')\n",
    "            logging.info('No second search psms for scoring found. Using first search.')\n",
    "\n",
    "        if len(df) == 0:\n",
    "            skip = True\n",
    "            logging.info('Dataframe does not contain data. Skipping scoring step.')\n",
    "\n",
    "        if not skip:\n",
    "            df = get_ML_features(df, **settings['fasta'])\n",
    "\n",
    "            if settings[\"general\"][\"score\"] == 'random_forest':\n",
    "                try:\n",
    "                    cv, features = train_RF(df)\n",
    "                    df = filter_with_ML(df, cv, features = features, fdr_level = settings[\"search\"][\"peptide_fdr\"])\n",
    "                except ValueError as e:\n",
    "                    logging.info('ML failed. Defaulting to x_tandem score')\n",
    "                    logging.info(f\"{e}\")\n",
    "                    df = filter_with_x_tandem(df, fdr_level = settings[\"search\"][\"peptide_fdr\"])\n",
    "            elif settings[\"general\"][\"score\"] == 'x_tandem':\n",
    "                df = filter_with_x_tandem(df, fdr_level = settings[\"search\"][\"peptide_fdr\"])\n",
    "            else:\n",
    "                raise NotImplementedError('Scoring method {} not implemented.'.format(settings[\"general\"][\"score\"]))\n",
    "\n",
    "            df = cut_global_fdr(df, analyte_level='precursor',  plot=False, fdr_level = settings[\"search\"][\"peptide_fdr\"], **settings['search'])\n",
    "\n",
    "            ms_file_.write(df, dataset_name=\"peptide_fdr\")\n",
    "\n",
    "            logging.info('FDR on peptides complete. For {} FDR found {:,} targets and {:,} decoys.'.format(settings[\"search\"][\"peptide_fdr\"], df['target'].sum(), df['decoy'].sum()) )\n",
    "        \n",
    "        logging.info(f'Scoring of file {ms_file} complete.')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f'Scoring of file {ms_file} failed. Exception {e}')\n",
    "        return f\"{e}\" #Can't return exception object, cast as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "ion_dict = {}\n",
    "ion_dict[0] = ''\n",
    "ion_dict[1] = '-H20'\n",
    "ion_dict[2] = '-NH3'\n",
    "\n",
    "def get_ion(i, df, ions):\n",
    "    start = df['ion_idx'].iloc[i]\n",
    "    end = df['n_ions'].iloc[i]+start\n",
    "\n",
    "    ion = [('b'+str(int(_))).replace('b-','y') for _ in ions.iloc[start:end]['ion_index']]\n",
    "    losses = [ion_dict[int(_)] for _ in ions.iloc[start:end]['ion_type']]\n",
    "    ion = [a+b for a,b in zip(ion, losses)]\n",
    "    ints = ions.iloc[start:end]['ion_int'].astype('int').values\n",
    "    \n",
    "    return ion, ints\n",
    "\n",
    "def protein_groups_hdf(to_process):\n",
    "\n",
    "    skip = False\n",
    "    path, pept_dict, fasta_dict, settings = to_process\n",
    "    ms_file = alphapept.io.MS_Data_File(path, is_overwritable=True)\n",
    "    try:\n",
    "        df = ms_file.read(dataset_name='peptide_fdr')\n",
    "    except KeyError:\n",
    "        skip = True\n",
    "\n",
    "    if not skip:\n",
    "        df_pg = perform_protein_grouping(df, pept_dict, fasta_dict, callback = None)\n",
    "\n",
    "        df_pg = cut_global_fdr(df_pg, analyte_level='protein',  plot=False, fdr_level = settings[\"search\"][\"protein_fdr\"], **settings['search'])\n",
    "        logging.info('FDR on proteins complete. For {} FDR found {:,} targets and {:,} decoys. A total of {:,} proteins found.'.format(settings[\"search\"][\"protein_fdr\"], df_pg['target'].sum(), df_pg['decoy'].sum(), len(set(df_pg['protein']))))\n",
    "        \n",
    "        try:\n",
    "            logging.info('Extracting ions')\n",
    "            ions = ms_file.read(dataset_name='ions')\n",
    "            \n",
    "        \n",
    "            ion_list = []\n",
    "            ion_ints = []\n",
    "\n",
    "            for i in range(len(df_pg)):\n",
    "                ion, ints = get_ion(i, df_pg, ions)\n",
    "                ion_list.append(ion)\n",
    "                ion_ints.append(ints)\n",
    "\n",
    "            df_pg['ion_int'] = ion_ints\n",
    "            df_pg['ion_types'] = ion_list\n",
    "        \n",
    "            logging.info('Extracting ions complete.')\n",
    "            \n",
    "        except KeyError:\n",
    "            logging.info('No ions present.')\n",
    "\n",
    "        \n",
    "        ms_file.write(df_pg, dataset_name=\"protein_fdr\")\n",
    "        base, ext = os.path.splitext(path)\n",
    "        df_pg.to_csv(base+'_protein_fdr.csv')\n",
    "\n",
    "        logging.info('Saving complete.')\n",
    "\n",
    "\n",
    "def protein_groups_hdf_parallel(settings, pept_dict, fasta_dict, callback=None):\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    for _ in settings['experiment']['file_paths']:\n",
    "        base, ext = os.path.splitext(_)\n",
    "        hdf_path = base+'.ms_data.hdf'\n",
    "        paths.append(hdf_path)\n",
    "\n",
    "    to_process = [(path, pept_dict.copy(), fasta_dict.copy(), settings) for path in paths]\n",
    "\n",
    "    n_processes = settings['general']['n_processes']\n",
    "\n",
    "    if len(to_process) == 1:\n",
    "        protein_groups_hdf(to_process[0])\n",
    "    else:\n",
    "\n",
    "        with Pool(n_processes) as p:\n",
    "            max_ = len(to_process)\n",
    "            for i, _ in enumerate(p.imap_unordered(protein_groups_hdf, to_process)):\n",
    "                if callback:\n",
    "                    callback((i+1)/max_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
