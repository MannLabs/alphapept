{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface\n",
    "\n",
    "This notebook describes/implements the interface to use alphapept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "The implemented functions are as follows:\n",
    "\n",
    "* Create database\n",
    "* Import raw data\n",
    "* Perform feature finding\n",
    "* Search data with fasta\n",
    "* Recalibrate\n",
    "* Score data with fasta\n",
    "* Perform LFQ\n",
    "* Export results\n",
    "* Run whole workflow\n",
    "\n",
    "The last command allows to run the whole pipeline at once.\n",
    "\n",
    "Helper functions include:\n",
    "\n",
    "* Callback function to track progress\n",
    "* Logging function\n",
    "* Version/hardware/settings checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def tqdm_wrapper(pbar, update):\n",
    "    current_value = pbar.n\n",
    "    delta = update - current_value\n",
    "    pbar.update(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "def set_logger():\n",
    "    root = logging.getLogger()\n",
    "    while root.hasHandlers():\n",
    "        root.removeHandler(root.handlers[0])\n",
    "    root.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s %(levelname)-s - %(message)s', \"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.utils\n",
    "\n",
    "\n",
    "def check_version_and_hardware(settings):\n",
    "    alphapept.utils.check_hardware()\n",
    "    alphapept.utils.check_python_env()\n",
    "    settings = alphapept.utils.check_settings(settings)\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.fasta\n",
    "import os\n",
    "import functools\n",
    "\n",
    "\n",
    "def create_database(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    if 'database_path' not in settings['fasta']:\n",
    "        database_path = ''\n",
    "    else:\n",
    "        database_path = settings['fasta']['database_path']\n",
    "    if settings['fasta']['save_db']:\n",
    "        if os.path.isfile(database_path):\n",
    "            logging.info(\n",
    "                'Database path set and exists. Using {} as database.'.format(\n",
    "                    database_path\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            logging.info(\n",
    "                'Database path {} is not a file.'.format(database_path)\n",
    "            )\n",
    "            for fasta_file in settings['fasta']['fasta_paths']:\n",
    "                if os.path.isfile(fasta_file):\n",
    "                    logging.info(\n",
    "                        'Found FASTA file {} with size {:.2f} Mb.'.format(\n",
    "                            fasta_file,\n",
    "                            os.stat(fasta_file).st_size/(1024**2)\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    raise FileNotFoundError(\n",
    "                        'File {} not found'.format(fasta_file)\n",
    "                    )\n",
    "\n",
    "            logging.info('Creating a new database from FASTA.')\n",
    "\n",
    "            if not callback:\n",
    "                cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "            else:\n",
    "                cb = callback\n",
    "\n",
    "            (\n",
    "                spectra,\n",
    "                pept_dict,\n",
    "                fasta_dict\n",
    "            ) = alphapept.fasta.generate_database_parallel(\n",
    "                settings,\n",
    "                callback=cb\n",
    "            )\n",
    "            logging.info(\n",
    "                'Digested {:,} proteins and generated {:,} spectra'.format(\n",
    "                    len(fasta_dict),\n",
    "                    len(spectra)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            alphapept.fasta.save_database(\n",
    "                spectra,\n",
    "                pept_dict,\n",
    "                fasta_dict,\n",
    "                **settings['fasta']\n",
    "            )\n",
    "            logging.info(\n",
    "                'Database saved to {}. Filesize of database is {:.2f} GB'.format(\n",
    "                    database_path,\n",
    "                    os.stat(database_path).st_size/(1024**3)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            settings['fasta']['database_path'] = database_path\n",
    "\n",
    "    else:\n",
    "        logging.info(\n",
    "            'Not using a stored database. Create database on the fly.'\n",
    "        )\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.io\n",
    "\n",
    "\n",
    "def import_raw_data(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    files_ms_data_hdf = []\n",
    "    to_convert = []\n",
    "\n",
    "    for file_name in settings['experiment']['file_paths']:\n",
    "        base, ext = os.path.splitext(file_name)\n",
    "        ms_data_file_path = f'{base}.ms_data.hdf'\n",
    "        files_ms_data_hdf.append(ms_data_file_path)\n",
    "        if os.path.isfile(ms_data_file_path):\n",
    "            logging.info(f'Found *.ms_data.hdf file for {file_name}')\n",
    "        else:\n",
    "            to_convert.append(file_name)\n",
    "            logging.info(f'No *.ms_data.hdf file found for {file_name}. Adding to conversion list.')\n",
    "    files_ms_data_hdf.sort()\n",
    "\n",
    "    if len(to_convert) > 0:\n",
    "        logging.info('Starting file conversion.')\n",
    "        if not callback:\n",
    "            cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "        else:\n",
    "            cb = callback\n",
    "        for file_name in to_convert:\n",
    "            to_process = (file_name, settings)\n",
    "            alphapept.io.raw_to_ms_data_file(to_process, callback=None)\n",
    "            logging.info('File conversion complete.')\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.feature_finding\n",
    "\n",
    "\n",
    "def feature_finding(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    to_convert = []\n",
    "    for file_name in settings['experiment']['file_paths']:\n",
    "        base, ext = os.path.splitext(file_name)\n",
    "        hdf_path = base+'.ms_data.hdf'\n",
    "\n",
    "        if os.path.isfile(hdf_path):\n",
    "            try:\n",
    "                alphapept.io.MS_Data_File(\n",
    "                    hdf_path\n",
    "                ).read(dataset_name=\"features\")\n",
    "                logging.info(\n",
    "                    'Found *.hdf with features for {}'.format(file_name)\n",
    "                )\n",
    "            except KeyError:\n",
    "                to_convert.append(file_name)\n",
    "                logging.info(\n",
    "                    'No *.hdf file with features found for {}. Adding to feature finding list.'.format(file_name)\n",
    "                )\n",
    "        else:\n",
    "            to_convert.append(file_name)\n",
    "            logging.info(\n",
    "                'No *.hdf file with features found for {}. Adding to feature finding list.'.format(file_name)\n",
    "            )\n",
    "\n",
    "    if len(to_convert) > 0:\n",
    "        logging.info(\n",
    "            'Feature extraction for {} file(s).'.format(len(to_convert))\n",
    "        )\n",
    "        if not callback:\n",
    "            cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "        else:\n",
    "            cb = callback\n",
    "\n",
    "        alphapept.feature_finding.find_and_save_features_parallel(\n",
    "            to_convert,\n",
    "            settings,\n",
    "            callback=cb\n",
    "        )\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.search\n",
    "import alphapept.io\n",
    "\n",
    "\n",
    "def search_data(\n",
    "    settings,\n",
    "    recalibrated=False,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    if not recalibrated:\n",
    "        if settings['fasta']['save_db']:\n",
    "            logging.info('Starting first search with DB.')\n",
    "\n",
    "            if not callback:\n",
    "                cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "            else:\n",
    "                cb = callback\n",
    "\n",
    "            fasta_dict, pept_dict = alphapept.search.search_parallel_db(\n",
    "                settings,\n",
    "                callback=cb\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            logging.info('Starting first search.')\n",
    "\n",
    "            if not callback:\n",
    "                cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "            else:\n",
    "                cb = callback\n",
    "\n",
    "            fasta_dict = alphapept.search.search_parallel(settings, callback=cb)\n",
    "            pept_dict = None\n",
    "\n",
    "        logging.info('First search complete.')\n",
    "    else:\n",
    "        ms_files = []\n",
    "        for _ in settings['experiment']['file_paths']:\n",
    "            base, ext = os.path.splitext(_)\n",
    "            ms_files.append(base + '.ms_data.hdf')\n",
    "        offsets = [\n",
    "            alphapept.io.MS_Data_File(\n",
    "                ms_file_name\n",
    "            ).read(\n",
    "                dataset_name=\"corrected_mass\",\n",
    "                group_name=\"features\",\n",
    "                attr_name=\"estimated_max_precursor_ppm\"\n",
    "            ) * settings['search']['calibration_std'] for ms_file_name in ms_files\n",
    "        ]\n",
    "        if settings['fasta']['save_db']:\n",
    "            logging.info('Starting second search with DB.')\n",
    "\n",
    "            if not callback:\n",
    "                cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "            else:\n",
    "                cb = callback\n",
    "\n",
    "            fasta_dict, pept_dict = alphapept.search.search_parallel_db(\n",
    "                settings,\n",
    "                calibration=offsets,\n",
    "                callback=cb\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            logging.info('Starting second search.')\n",
    "\n",
    "            if not callback:\n",
    "                cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "            else:\n",
    "                cb = callback\n",
    "\n",
    "            fasta_dict = alphapept.search.search_parallel(\n",
    "                settings,\n",
    "                calibration=offsets,\n",
    "                callback=cb\n",
    "            )\n",
    "            pept_dict = None\n",
    "\n",
    "        logging.info('Second search complete.')\n",
    "    return settings, pept_dict, fasta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.recalibration\n",
    "\n",
    "\n",
    "def recalibrate_data(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    if settings['search']['calibrate']:\n",
    "        logging.info('Performing recalibration.')\n",
    "\n",
    "        if not callback:\n",
    "            cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "        else:\n",
    "            cb = callback\n",
    "\n",
    "        offsets = alphapept.recalibration.calibrate_hdf_parallel(\n",
    "            settings,\n",
    "            callback=cb\n",
    "        )\n",
    "\n",
    "        logging.info('Recalibration complete.')\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.score\n",
    "\n",
    "\n",
    "def score(\n",
    "    settings,\n",
    "    pept_dict=None,\n",
    "    fasta_dict=None,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    if not callback:\n",
    "        cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "    else:\n",
    "        cb = callback\n",
    "\n",
    "    if (fasta_dict is None) or (pept_dict is None):\n",
    "        db_data = alphapept.fasta.read_database(\n",
    "            settings['fasta']['database_path']\n",
    "        )\n",
    "        fasta_dict = db_data['fasta_dict'].item()\n",
    "        pept_dict = db_data['pept_dict'].item()\n",
    "    alphapept.score.score_hdf_parallel(settings, callback=cb)\n",
    "    logging.info('Scoring complete.')\n",
    "\n",
    "    if not settings['fasta']['save_db']:\n",
    "        pept_dict = alphapept.fasta.pept_dict_from_search(settings)\n",
    "\n",
    "    # Protein groups\n",
    "    logging.info('Extracting protein groups.')\n",
    "\n",
    "    if not callback:\n",
    "        cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "    else:\n",
    "        cb = callback\n",
    "\n",
    "    # This is on each file individually -> when having repeats maybe\n",
    "    # use differently (if this matter at all )\n",
    "    alphapept.score.protein_groups_hdf_parallel(\n",
    "        settings,\n",
    "        pept_dict,\n",
    "        fasta_dict,\n",
    "        callback=cb\n",
    "    )\n",
    "    logging.info('Protein groups complete.')\n",
    "\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import alphapept.quantification\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def lfq_quantification(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    field = settings['quantification']['mode']\n",
    "\n",
    "    logging.info('Assembling dataframe.')\n",
    "    df = alphapept.utils.assemble_df(settings)\n",
    "    logging.info('Assembly complete.')\n",
    "    \n",
    "    if field in df.keys():  # Check if the quantification information exists.\n",
    "        # We could include another protein fdr in here..\n",
    "        if 'fraction' in df.keys():\n",
    "            logging.info('Delayed Normalization.')\n",
    "            df, normalization = alphapept.quantification.delayed_normalization(\n",
    "                df,\n",
    "                field\n",
    "            )\n",
    "            pd.DataFrame(normalization).to_hdf(\n",
    "                settings['experiment']['results_path'],\n",
    "                'fraction_normalization'\n",
    "            )\n",
    "            df_grouped = df.groupby(\n",
    "                ['shortname', 'precursor', 'protein', 'filename']\n",
    "            )[['{}_dn'.format(field)]].sum().reset_index()\n",
    "        else:\n",
    "            df_grouped = df.groupby(\n",
    "                ['shortname', 'precursor', 'protein', 'filename']\n",
    "            )[field].sum().reset_index()\n",
    "\n",
    "        df.to_hdf(\n",
    "            settings['experiment']['results_path'],\n",
    "            'combined_protein_fdr_dn'\n",
    "        )\n",
    "\n",
    "        logging.info('Complete. ')\n",
    "        logging.info('Starting profile extraction.')\n",
    "\n",
    "        if not callback:\n",
    "            cb = functools.partial(tqdm_wrapper, tqdm.tqdm(total=1))\n",
    "        else:\n",
    "            cb = callback\n",
    "\n",
    "        protein_table = alphapept.quantification.protein_profile_parallel(\n",
    "            settings,\n",
    "            df_grouped,\n",
    "            callback=cb\n",
    "        )\n",
    "        protein_table.to_hdf(\n",
    "            settings['experiment']['results_path'],\n",
    "            'protein_table'\n",
    "        )\n",
    "        results_path = settings['experiment']['results_path']\n",
    "        base, ext = os.path.splitext(results_path)\n",
    "        protein_table.to_csv(base+'.csv')\n",
    "\n",
    "        logging.info('LFQ complete.')\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def export(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    base, ext = os.path.splitext(settings['experiment']['results_path'])\n",
    "    out_path_settings = base+'.yaml'\n",
    "\n",
    "    with open(out_path_settings, 'w') as file:\n",
    "        yaml.dump(settings, file)\n",
    "\n",
    "    logging.info('Settings saved to {}'.format(out_path_settings))\n",
    "    logging.info('Analysis complete.')\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def run_complete_workflow(\n",
    "    settings,\n",
    "    logger_set=False,\n",
    "    settings_parsed=False,\n",
    "    callback=None\n",
    "):\n",
    "    if not logger_set:\n",
    "        set_logger()\n",
    "    if not settings_parsed:\n",
    "        settings = check_version_and_hardware(settings)\n",
    "    settings = create_database(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = import_raw_data(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = feature_finding(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings, pept_dict, fasta_dict = search_data(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = recalibrate_data(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings, pept_dict, fasta_dict = search_data(\n",
    "        settings,\n",
    "        recalibrated=True,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = score(\n",
    "        settings,\n",
    "        pept_dict=pept_dict,\n",
    "        fasta_dict=fasta_dict,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = lfq_quantification(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )\n",
    "    settings = export(\n",
    "        settings,\n",
    "        logger_set=True,\n",
    "        settings_parsed=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI\n",
    "\n",
    "All workflow functions can be called with the command line interface (CLI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import click\n",
    "import os\n",
    "import alphapept.settings\n",
    "from alphapept.__version__ import VERSION_NO\n",
    "from alphapept.__version__ import COPYRIGHT\n",
    "from alphapept.__version__ import URL\n",
    "\n",
    "CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])\n",
    "CLICK_SETTINGS_OPTION = click.argument(\n",
    "    \"settings_file\",\n",
    "#     help=\"A .yaml file with settings.\",\n",
    "    type=click.Path(exists=True, dir_okay=False),\n",
    "#     default=f\"{os.path.dirname(__file__)}/settings_template.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_cli():\n",
    "    print(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                \"\\n\",\n",
    "                r\"     ___    __      __          ____             __ \",\n",
    "                r\"    /   |  / /___  / /_  ____  / __ \\___  ____  / /_\",\n",
    "                r\"   / /| | / / __ \\/ __ \\/ __ \\/ /_/ / _ \\/ __ \\/ __/\",\n",
    "                r\"  / ___ |/ / /_/ / / / / /_/ / ____/ ___/ /_/ / /_  \",\n",
    "                r\" /_/  |_/_/ .___/_/ /_/\\__,_/_/    \\___/ .___/\\__/  \",\n",
    "                r\"         /_/                          /_/           \",\n",
    "                '.'*52,\n",
    "                '.{}.'.format(URL.center(50)),\n",
    "                '.{}.'.format(COPYRIGHT.center(50)),\n",
    "                '.{}.'.format(VERSION_NO.center(50)),\n",
    "                '.'*52,\n",
    "                \"\\n\"\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    cli_overview.add_command(cli_database)\n",
    "    cli_overview.add_command(cli_import)\n",
    "    cli_overview.add_command(cli_feature_finding)\n",
    "    cli_overview.add_command(cli_search)\n",
    "    cli_overview.add_command(cli_recalibrate)\n",
    "    cli_overview.add_command(cli_score)\n",
    "    cli_overview.add_command(cli_quantify)\n",
    "    cli_overview.add_command(cli_export)\n",
    "    cli_overview.add_command(cli_workflow)\n",
    "    cli_overview.add_command(cli_gui)\n",
    "    cli_overview()\n",
    "\n",
    "\n",
    "@click.group(\n",
    "    context_settings=CONTEXT_SETTINGS,\n",
    "#     help=\"AlphaPept\"\n",
    ")\n",
    "def cli_overview():\n",
    "    pass\n",
    "\n",
    "\n",
    "@click.command(\n",
    "    \"database\",\n",
    "    help=\"Create a database from a fasta file.\",\n",
    "    short_help=\"Create a database from a fasta file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_database(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    create_database(settings)\n",
    "    \n",
    "    \n",
    "@click.command(\n",
    "    \"import\",\n",
    "    help=\"Import and convert raw data from vendor to `.ms_data.hdf` file.\",\n",
    "    short_help=\"Import and convert raw data from vendor to `.ms_data.hdf` file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_import(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    import_raw_data(settings)\n",
    "    \n",
    "    \n",
    "@click.command(\n",
    "    \"features\",\n",
    "    help=\"Find features in a `.ms_data.hdf` file.\",\n",
    "    short_help=\"Find features in a `.ms_data.hdf` file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_feature_finding(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    feature_finding(settings)\n",
    "    \n",
    "    \n",
    "@click.command(\n",
    "    \"search\",\n",
    "    help=\"Search and identify feature in a `.ms_data.hdf` file.\",\n",
    "    short_help=\"Search and identify feature in a `.ms_data.hdf` file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "@click.option(\n",
    "    '--recalibrated_features',\n",
    "    '-r',\n",
    "    'recalibrated',\n",
    "    help=\"Use recalibrated features if present\",\n",
    "    is_flag=True,\n",
    "    default=False,\n",
    "    show_default=True,\n",
    ")\n",
    "def cli_search(settings_file, recalibrated):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    search_data(settings, recalibrated)\n",
    "    \n",
    "    \n",
    "@click.command(\n",
    "    \"recalibrate\",\n",
    "    help=\"Recalibrate a `.ms_data.hdf` file.\",\n",
    "    short_help=\"Recalibrate a `.ms_data.hdf` file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_recalibrate(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    recalibrate_data(settings)\n",
    "    \n",
    "\n",
    "@click.command(\n",
    "    \"score\",\n",
    "    help=\"Score PSM from a `.ms_data.hdf` file.\",\n",
    "    short_help=\"Score PSM from a `.ms_data.hdf` file.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_score(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    score(settings)\n",
    "    \n",
    "    \n",
    "@click.command(\n",
    "    \"quantify\",\n",
    "    help=\"Quantify and compare multiple `.ms_data.hdf` files.\",\n",
    "    short_help=\"Quantify and compare multiple `.ms_data.hdf` files.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_quantify(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    lfq_quantification(settings)\n",
    "    \n",
    "\n",
    "@click.command(\n",
    "    \"export\",\n",
    "    help=\"Export protein table from `.ms_data.hdf` files as `.csv`\",\n",
    "    short_help=\"Export protein table from `.ms_data.hdf` files as `.csv`.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_export(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    export(settings)\n",
    "    \n",
    "\n",
    "@click.command(\n",
    "    \"workflow\",\n",
    "    help=\"Run the complete AlphaPept workflow.\",\n",
    "    short_help=\"Run the complete AlphaPept workflow.\"\n",
    ")\n",
    "@CLICK_SETTINGS_OPTION\n",
    "def cli_workflow(settings_file):\n",
    "    settings = alphapept.settings.load_settings(settings_file)\n",
    "    run_complete_workflow(settings)\n",
    "\n",
    "    \n",
    "@click.command(\n",
    "    \"gui\",\n",
    "    help=\"Start graphical user interface for AlphaPept.\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--test\",\n",
    "    \"test\",\n",
    "    help=\"Test\",\n",
    "    is_flag=True,\n",
    "    default=False,\n",
    "    show_default=True,\n",
    ")\n",
    "def cli_gui(test):\n",
    "    print('Launching GUI')\n",
    "    import alphapept.ui\n",
    "    if test:\n",
    "        alphapept.ui.main(close=True)\n",
    "    else:\n",
    "        alphapept.ui.main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_settings.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_interface.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alphapept]",
   "language": "python",
   "name": "conda-env-alphapept-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
