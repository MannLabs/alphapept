{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA\n",
    "\n",
    "> Functions related to generating spectra from FASTA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all functions related to creating spectra from FASTA files. In brief, what we are doing is the following:\n",
    "\n",
    "1. Read a FASTA file and digest the sequences\n",
    "2. For each peptide, calculate a synthetic spectrum and precursor mass\n",
    "3. Save spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "from numba import NumbaPendingDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaving\n",
    "\n",
    "For cleaving, we rely on the `parser` from the `pyteomics` package and write the wrapper `cleave_sequence` to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pyteomics import parser\n",
    "from alphapept import constants\n",
    "\n",
    "def cleave_sequence(\n",
    "    sequence=\"\",\n",
    "    num_missed_cleavages=0,\n",
    "    protease=\"trypsin\",\n",
    "    min_length=6,\n",
    "    max_length=65,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Cleave a peptide with a a given rule\n",
    "    \"\"\"\n",
    "    proteases = constants.protease_dict\n",
    "    protease = proteases[protease]\n",
    "    pep_peptides = list(\n",
    "        parser.cleave(\n",
    "            sequence, protease, num_missed_cleavages, min_length=min_length, semi=False\n",
    "        )\n",
    "    )\n",
    "    pep_peptides = [_ for _ in pep_peptides if len(_) <= max_length]\n",
    "\n",
    "    return pep_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABCDEFGHIJK', 'LMNOPQR']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protease = \"trypsin\"\n",
    "num_missed_cleavages = 0\n",
    "min_length, max_length = 6, 65\n",
    "\n",
    "cleave_sequence('ABCDEFGHIJKLMNOPQRST', num_missed_cleavages, protease, min_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_cleave_sequence():\n",
    "    \n",
    "    protease = \"trypsin\"\n",
    "    num_missed_cleavages = 0\n",
    "    min_length, max_length = 6, 65\n",
    "\n",
    "    assert set(cleave_sequence('ABCDEFGHIJKLMNOPQRST', num_missed_cleavages, protease, min_length, max_length)) == set(['ABCDEFGHIJK', 'LMNOPQR'])\n",
    "    \n",
    "test_cleave_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Peptides are composed out of amino acids that are written in capital letters - `PEPTIDE`. to distinguish modifications, they are written in lowercase such as `PEPTIoxDE` and can be of arbitrary length. For a modified amino acid, the modification preceds the letter of the amino acid. Decoys are indicated with a underscore, hence the `parse` function splits after `_`. When parsing, the peptide string is converted into a numba-compatible list so that each element can be determined with the `mass_dict` from `alphapept.constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "@njit\n",
    "def parse(peptide):\n",
    "    \"\"\"\n",
    "    Parser to parse peptide strings\n",
    "    \"\"\"\n",
    "    if \"_\" in peptide:\n",
    "        peptide = peptide.split(\"_\")[0]\n",
    "    parsed = List()\n",
    "    string = \"\"\n",
    "\n",
    "    for i in peptide:\n",
    "        string += i\n",
    "        if i.isupper():\n",
    "            parsed.append(string)\n",
    "            string = \"\"\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def list_to_numba(a_list):\n",
    "    numba_list = List()\n",
    "\n",
    "    for element in a_list:\n",
    "        numba_list.append(element)\n",
    "\n",
    "    return numba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P, E, P, T, I, D, E]\n",
      "[P, E, P, oxT, I, D, E]\n"
     ]
    }
   ],
   "source": [
    "print(parse('PEPTIDE'))\n",
    "print(parse('PEPoxTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_parse():\n",
    "    peptide = \"PEPTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPoxTIDE\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"oxT\", \"I\", \"D\", \"E\"])\n",
    "    peptide = \"PEPTIDE_decoy\"\n",
    "    assert parse(peptide) == list_to_numba([\"P\", \"E\", \"P\", \"T\", \"I\", \"D\", \"E\"])\n",
    "    \n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoy\n",
    "\n",
    "The decoy strategy that is employed is a reversal of the sequence. Additionally, we can call the functions `swap_KR` and and `swap_AL` that will swap the respective AAs. The function `swap_KR` will only swap terminal AAs. The swapping functions only work if the AA is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_decoy_sequence(peptide, AL_swap=True, KR_swap = True):\n",
    "    \"\"\"\n",
    "    Reverses a sequence and adds the '_decoy' tag.\n",
    "\n",
    "    \"\"\"\n",
    "    pep = parse(peptide)\n",
    "    rev_pep = pep[::-1]\n",
    "\n",
    "    if AL_swap:\n",
    "        rev_pep = swap_AL(rev_pep)\n",
    "\n",
    "    if KR_swap:\n",
    "        rev_pep = swap_KR(rev_pep)\n",
    "\n",
    "    rev_pep = \"\".join(rev_pep)\n",
    "\n",
    "    return rev_pep\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_KR(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a terminal K or R. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    if peptide[-1] == 'K':\n",
    "        peptide[-1] = 'R'\n",
    "    elif peptide[-1] == 'R':\n",
    "        peptide[-1] = 'K'\n",
    "\n",
    "    return peptide\n",
    "\n",
    "\n",
    "@njit\n",
    "def swap_AL(peptide):\n",
    "    \"\"\"\n",
    "    Swaps a A with L. Note: Only if AA is not modified.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(range(len(peptide) - 1)):\n",
    "        if peptide[i] == \"A\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"A\"\n",
    "            i += 1\n",
    "        elif peptide[i] == \"L\":\n",
    "            peptide[i] = peptide[i + 1]\n",
    "            peptide[i + 1] = \"L\"\n",
    "            i += 1\n",
    "        i += 1\n",
    "\n",
    "    return peptide\n",
    "\n",
    "def get_decoys(peptide_list):\n",
    "    \"\"\"\n",
    "    Wrapper to get decoys for lists of peptides\n",
    "    \"\"\"\n",
    "    decoys = []\n",
    "    decoys.extend([get_decoy_sequence(peptide) for peptide in peptide_list])\n",
    "    return decoys\n",
    "\n",
    "def add_decoy_tag(peptides):\n",
    "    \"\"\"\n",
    "    Adds a _decoy tag to a list of peptides\n",
    "    \"\"\"\n",
    "    return [peptide + \"_decoy\" for peptide in peptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[K, K, K, L, A, K, K, K]\n",
      "[A, A, A, K, R, A, A, A]\n"
     ]
    }
   ],
   "source": [
    "print(swap_AL(parse('KKKALKKK')))\n",
    "print(swap_KR(parse('AAAKRAAA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDITPEP\n"
     ]
    }
   ],
   "source": [
    "print(get_decoy_sequence('PEPTIDE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CBA', 'FED', 'IHG']\n"
     ]
    }
   ],
   "source": [
    "print(get_decoys(['ABC','DEF','GHI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_swap_AL():\n",
    "    assert swap_AL(parse(\"ABCDEF\")) == parse(\"BACDEF\")\n",
    "    assert swap_AL(parse(\"GHIKLM\")) == parse(\"GHIKML\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "    assert swap_AL(parse(\"GHIKL\")) == parse(\"GHIKL\")\n",
    "    assert swap_AL(parse(\"ABCDEFGHIKLM\")) == parse(\"BACDEFGHIKML\")\n",
    "    assert swap_AL(parse(\"BBAcCD\")) == parse(\"BBcCAD\")\n",
    "    assert swap_AL(parse(\"FEDCBA\")) == parse(\"FEDCBA\")\n",
    "\n",
    "test_swap_AL()\n",
    "\n",
    "def test_swapKR():\n",
    "    assert swap_KR(parse(\"ABCDEK\")) == parse(\"ABCDER\")\n",
    "    assert swap_KR(parse(\"ABCDER\")) == parse(\"ABCDEK\")\n",
    "    assert swap_KR(parse(\"ABCDEF\")) == parse(\"ABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCDEF\")) == parse(\"KABCDEF\")\n",
    "    assert swap_KR(parse(\"KABCRDEF\")) == parse(\"KABCRDEF\")\n",
    "    assert swap_KR(parse(\"KABCKDEF\")) == parse(\"KABCKDEF\")\n",
    "\n",
    "test_swapKR()\n",
    "    \n",
    "def test_get_decoy_sequence():\n",
    "    peptide = \"PEPTIDE\"\n",
    "    assert get_decoy_sequence(peptide) == \"EDITPEP\"\n",
    "    \n",
    "test_get_decoy_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "\n",
    "To add modifications to the peptides we distinguish fixed and variable modifications. Additionally, we make a distinciton between whether the modification is only terminal or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Modifications\n",
    "Fixed modifications are implemented by passing a list with modified AAs that should be replaced. As we only have one letter AAs the remainder is the modification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mods(seqs, mods_fixed, **kwargs):\n",
    "    \"\"\"\n",
    "    Adds fixed modifications to sequences.\n",
    "    \"\"\"\n",
    "    if not mods_fixed:\n",
    "        return seqs\n",
    "    else:\n",
    "        for mod_aa in mods_fixed:\n",
    "            seqs = [seq.replace(mod_aa[-1], mod_aa) for seq in seqs]\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbBcCDEF']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_fixed = ['cC','bB']\n",
    "peptide_list = ['ABCDEF']\n",
    "\n",
    "add_fixed_mods(peptide_list, mods_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_fixed_mods():\n",
    "    mods_fixed = ['cC']\n",
    "    peptide_list = ['ABCDEF']\n",
    "\n",
    "    peptides_new = add_fixed_mods(peptide_list, [])\n",
    "    assert peptides_new == peptide_list\n",
    "    \n",
    "    peptides_new = add_fixed_mods(peptide_list, mods_fixed)\n",
    "    assert peptides_new == ['ABcCDEF']\n",
    "    \n",
    "test_add_fixed_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Modifications\n",
    "\n",
    "To employ variable modifications, we use the function `get_mod_pos` that returns a list of tuples with all possible modifications when giving a dicitionary with variable modifications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_mod_pos(variable_mods_r, sequence):\n",
    "    \"\"\"\n",
    "    Returns a list with of tuples with all possibilities for modified an unmodified AAs.\n",
    "    \"\"\"\n",
    "    modvar = []\n",
    "    for c in sequence:\n",
    "        if c in variable_mods_r.keys():\n",
    "            modvar.append((c, variable_mods_r[c]))\n",
    "        else:\n",
    "            modvar.append((c,))\n",
    "\n",
    "    return modvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "get_mod_pos(mods_variable_dict, peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_get_mod_pos():\n",
    "    \n",
    "    mods_variable_dict = {'M':'oxM'}\n",
    "    peptide = 'AMAMA'\n",
    "    assert set(get_mod_pos(mods_variable_dict, peptide)) == set([('A',), ('M', 'oxM'), ('A',), ('M', 'oxM'), ('A',)])\n",
    "    \n",
    "test_get_mod_pos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To now generate all isoforms, we employ the function `get_isoforms` that generates all isoforms for a given peptide. As the number of isoforms can become large, we restrict it with the parameter `max_isoforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from itertools import product\n",
    "def get_isoforms(variable_mods_r, sequence, max_isoforms):\n",
    "    \"\"\"\n",
    "    Function to generate isoforms for a given peptide - returns a list of isoforms.\n",
    "    The original sequence is included in the list\n",
    "    \"\"\"\n",
    "    modvar = get_mod_pos(variable_mods_r, sequence)\n",
    "    isoforms = []\n",
    "    i = 0\n",
    "    for o in product(*modvar):\n",
    "        if i < max_isoforms:\n",
    "            i += 1\n",
    "            isoforms.append(\"\".join(o))\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_variable_dict = {'M':'oxM'}\n",
    "peptide = 'AMAMA'\n",
    "max_isoforms = 1024\n",
    "get_isoforms(mods_variable_dict, peptide, max_isoforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the wrapper `add_variable_mods` so that the functions can be called for lists of peptides and a list of variable modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from itertools import chain\n",
    "\n",
    "def add_variable_mods(peptide_list, mods_variable, max_isoforms, **kwargs):\n",
    "    if not mods_variable:\n",
    "        return peptide_list\n",
    "    else:\n",
    "        mods_variable_r = {}\n",
    "        for _ in mods_variable:\n",
    "            mods_variable_r[_[-1]] = _\n",
    "\n",
    "        peptide_list = [get_isoforms(mods_variable_r, peptide, max_isoforms) for peptide in peptide_list]\n",
    "        return list(chain.from_iterable(peptide_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMA', 'AoxMA', 'AAC', 'AAamC']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMA', 'AAC']\n",
    "mods_variable = ['oxM','amC']\n",
    "max_isoforms = 1024\n",
    "\n",
    "add_variable_mods(peptide_list, mods_variable, max_isoforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_variable_mods():\n",
    "    mods_variable = ['oxM']\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, [], 1024)\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 1024)\n",
    "\n",
    "    assert set(['AMAMA', 'AMAoxMA', 'AoxMAMA', 'AoxMAoxMA']) == set(peptides_new)\n",
    "\n",
    "    # Check if number of isoforms is correct\n",
    "    peptides_new = add_variable_mods(peptide, mods_variable, 2)\n",
    "\n",
    "    assert len(peptides_new) == 2\n",
    "    \n",
    "test_add_variable_mods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Fixed\n",
    "\n",
    "To handle terminal modifications, we use the following convention:\n",
    "\n",
    "* `<` for the left side (N-terminal)\n",
    "* `>` for the right side (C-Terminal)\n",
    "\n",
    "Additionally, if we want to have a terminal modification on any AA we indicate this `^`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_fixed_mod_terminal(peptides, mod):\n",
    "    \"\"\"\n",
    "    Adds fixed terminal modifications\n",
    "    \"\"\"\n",
    "    # < for left side (N-Term), > for right side (C-Term)\n",
    "    if \"<^\" in mod: #Any n-term, e.g. a<^\n",
    "        peptides = [mod[:-2] + peptide for peptide in peptides]\n",
    "    elif \">^\" in mod: #Any c-term, e.g. a>^\n",
    "        peptides = [peptide[:-1] + mod[:-2] + peptide[-1] for peptide in peptides]\n",
    "    elif \"<\" in mod: #only if specific AA, e.g. ox<C\n",
    "        peptides = [peptide[0].replace(mod[-1], mod[:-2]+mod[-1]) + peptide[1:] for peptide in peptides]\n",
    "    elif \">\" in mod:\n",
    "        peptides = [peptide[:-1] + peptide[-1].replace(mod[-1], mod[:-2]+mod[-1]) for peptide in peptides]\n",
    "    else:\n",
    "        # This should not happen\n",
    "        raise (\"Invalid fixed terminal modification {}.\".format(key))\n",
    "    return peptides\n",
    "\n",
    "def add_fixed_mods_terminal(peptides, mods_fixed_terminal, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to add fixed mods on sequences and lists of mods\n",
    "    \"\"\"\n",
    "    if mods_fixed_terminal == []:\n",
    "        return peptides\n",
    "    else:\n",
    "        # < for left side (N-Term), > for right side (C-Term)\n",
    "        for key in mods_fixed_terminal:\n",
    "            peptides = add_fixed_mod_terminal(peptides, key)\n",
    "        return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any n-term modified with x (x<^): ['xAMAMA']\n",
      "Any c-term modified with x (x>^): ['AMAMxA']\n",
      "Only A on n-term modified with x (x<A): ['xAMAMA']\n",
      "Only A on c-term modified with x (x<A): ['AMAMxA']\n"
     ]
    }
   ],
   "source": [
    "peptide = ['AMAMA']\n",
    "\n",
    "print('Any n-term modified with x (x<^):', add_fixed_mods_terminal(peptide, ['x<^']))\n",
    "print('Any c-term modified with x (x>^):', add_fixed_mods_terminal(peptide, ['x>^']))\n",
    "print('Only A on n-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x<A']))\n",
    "print('Only A on c-term modified with x (x<A):', add_fixed_mods_terminal(peptide, ['x>A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_fixed_mods_terminal():\n",
    "    peptide = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<^'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    #Any C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>^'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    #Selected N-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<A'])\n",
    "    assert peptides_new == ['xAMAMA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x<C'])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Selected C-term\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>A'])\n",
    "    assert peptides_new == ['AMAMxA']\n",
    "\n",
    "    peptides_new = add_fixed_mods_terminal(peptide, ['x>C'])\n",
    "    assert peptides_new == peptide\n",
    "    \n",
    "test_add_fixed_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Modifications - Variable\n",
    "\n",
    "Lastly, to handle terminal variable modifications we use the function `add_variable_mods_terminal`. As the modifcation can only be at the terminal end this function only adds a peptide where the terminal end is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_variable_mods_terminal(peptides, mods_variable_terminal, **kwargs):\n",
    "    \"Function to add variable terminal modifications\"\n",
    "    if not mods_variable_terminal:\n",
    "        return peptides\n",
    "    else:\n",
    "        new_peptides_n = peptides.copy()\n",
    "\n",
    "        for key in mods_variable_terminal:\n",
    "            if \"<\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_n.extend(\n",
    "                    add_fixed_mod_terminal(peptides, key)\n",
    "                )\n",
    "        new_peptides_n = get_unique_peptides(new_peptides_n)\n",
    "        # N complete, let's go for c-terminal\n",
    "        new_peptides_c = new_peptides_n\n",
    "        for key in mods_variable_terminal:\n",
    "            if \">\" in key:\n",
    "                # Only allow one variable mod on one end\n",
    "                new_peptides_c.extend(\n",
    "                    add_fixed_mod_terminal(new_peptides_n, key)\n",
    "                )\n",
    "\n",
    "        return get_unique_peptides(new_peptides_c)\n",
    "\n",
    "def get_unique_peptides(peptides):\n",
    "    return list(set(peptides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xAMAMA', 'AMAMA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_list = ['AMAMA']\n",
    "add_variable_mods_terminal(peptide_list, ['x<^'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_add_variable_mods_terminal():\n",
    "    peptide_list = ['AMAMA']\n",
    "\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, [])\n",
    "    assert peptides_new == peptide\n",
    "\n",
    "    #Any N-term\n",
    "    peptides_new = add_variable_mods_terminal(peptide_list, ['x<^'])\n",
    "    assert set(peptides_new) == set(['xAMAMA', 'AMAMA'])\n",
    "    \n",
    "test_add_variable_mods_terminal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Peptides\n",
    "\n",
    "Lastly we put all the functions into a wrapper `generate_peptides`. It will accept a peptide and a dictionary with settings so that we can get all modified peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_peptides(peptide, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to get modified peptides from a peptide\n",
    "    \"\"\"\n",
    "    mod_peptide = add_fixed_mods_terminal([peptide], kwargs['mods_fixed_terminal_prot'])\n",
    "\n",
    "    mod_peptide = add_variable_mods_terminal(mod_peptide, kwargs['mods_variable_terminal_prot'])\n",
    "\n",
    "    peptides = []\n",
    "    [peptides.extend(cleave_sequence(_, **kwargs)) for _ in mod_peptide]\n",
    "\n",
    "    #Regular peptides\n",
    "    mod_peptides = add_fixed_mods(peptides, **kwargs)\n",
    "    mod_peptides = add_fixed_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods_terminal(mod_peptides, **kwargs)\n",
    "    mod_peptides = add_variable_mods(mod_peptides, **kwargs)\n",
    "\n",
    "    #Decoys:\n",
    "    decoy_peptides = get_decoys(peptides)\n",
    "\n",
    "    mod_peptides_decoy = add_fixed_mods(decoy_peptides, **kwargs)\n",
    "    mod_peptides_decoy = add_fixed_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods_terminal(mod_peptides_decoy, **kwargs)\n",
    "    mod_peptides_decoy = add_variable_mods(mod_peptides_decoy, **kwargs)\n",
    "\n",
    "    mod_peptides_decoy = add_decoy_tag(mod_peptides_decoy)\n",
    "\n",
    "    mod_peptides.extend(mod_peptides_decoy)\n",
    "\n",
    "    return mod_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEPTIDEM', 'PEPTIDEoxM', 'MEDITPEP_decoy', 'oxMEDITPEP_decoy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {}\n",
    "\n",
    "kwargs[\"protease\"] = \"trypsin\"\n",
    "kwargs[\"num_missed_cleavages\"] = 2\n",
    "kwargs[\"min_length\"] = 6\n",
    "kwargs[\"max_length\"] = 27\n",
    "kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "kwargs[\"mods_variable_terminal\"] = []\n",
    "kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "kwargs[\"mods_fixed_terminal\"] = []\n",
    "kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "generate_peptides('PEPTIDEM', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_generate_peptides():\n",
    "    kwargs = {}\n",
    "\n",
    "    kwargs[\"protease\"] = \"trypsin\"\n",
    "    kwargs[\"num_missed_cleavages\"] = 2\n",
    "    kwargs[\"min_length\"] = 6\n",
    "    kwargs[\"max_length\"] = 27\n",
    "    kwargs[\"mods_variable\"] = [\"oxM\"]\n",
    "    kwargs[\"mods_variable_terminal\"] = []\n",
    "    kwargs[\"mods_fixed\"] = [\"cC\"]\n",
    "    kwargs[\"mods_fixed_terminal\"] = []\n",
    "    kwargs[\"mods_fixed_terminal_prot\"] = []\n",
    "    kwargs[\"mods_variable_terminal_prot\"]  = []\n",
    "    kwargs[\"max_isoforms\"] = 1024\n",
    "\n",
    "    peps = generate_peptides('PEPTIDEM', **kwargs)\n",
    "    \n",
    "    assert set(peps) == set(['PEPTIDEM', 'PEPTIDEoxM', 'MEDITPEP_decoy', 'oxMEDITPEP_decoy'])\n",
    "    \n",
    "test_generate_peptides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass Calculations\n",
    "\n",
    "Using the `mass_dict` from `constants` and being able to parse sequences with `parse` we can simply look up the masses for each modified or unmodified amino acid and add everything up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor\n",
    "\n",
    "To calculate the mass of the neutral precursor we start with the mass of an $H_2O$ and add the masses of all amino acids of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def get_precmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the mass of the neutral precursor\n",
    "    \"\"\"\n",
    "    tmass = mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep:\n",
    "        tmass += mass_dict[_]\n",
    "\n",
    "    return tmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799.3599642034599"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_precmass():\n",
    "    \n",
    "    precmass = get_precmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "test_get_precmass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragments\n",
    "\n",
    "Likewise, we can calculate the masses of the fragment ions. We employ two functions: `get_fragmass` and `get_frag_dict`. \n",
    "\n",
    "`get_fragmass` is a fast, `numba`-compatible function that calculates the fragmasses and returns an array indicating wheter the iontype was `b` or `y`. \n",
    "\n",
    "`get_frag_dict` instead is not `numba`-compatible and hence a bit slower. It returns a dictionary with the respective ion and can be used for plotting theoretical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@njit\n",
    "def get_fragmass(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_masses = np.zeros(n_frags, dtype=np.float64)\n",
    "    frag_type = np.zeros(n_frags, dtype=np.int8)\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 0\n",
    "        n_frag += 1\n",
    "\n",
    "    # y-ions -> 1\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        frag_masses[n_frag] = frag_m\n",
    "        frag_type[n_frag] = 1\n",
    "        n_frag += 1\n",
    "\n",
    "    return frag_masses, frag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
       "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
       "        376.17144135, 477.21911985, 574.27188371, 703.31447681]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], dtype=int8))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fragmass(parse('PEPTIDE'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_fragmass():\n",
    "    \n",
    "    frag_masses, frag_type = get_fragmass(parse('PEPTIDE'), constants.mass_dict)\n",
    "    \n",
    "    ref_masses = np.array([ 98.06004033, 227.10263343, 324.15539729, 425.20307579,\n",
    "        538.28713979, 653.31408289, 148.06043425, 263.08737735,\n",
    "        376.17144135, 477.21911985, 574.27188371, 703.31447681])\n",
    "    \n",
    "    assert np.allclose(frag_masses, ref_masses)\n",
    "                          \n",
    "test_get_fragmass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_frag_dict(parsed_pep, mass_dict):\n",
    "    \"\"\"\n",
    "    Calculate the masses of the fragment ions\n",
    "    \"\"\"\n",
    "    n_frags = (len(parsed_pep) - 1) * 2\n",
    "\n",
    "    frag_dict = {}\n",
    "\n",
    "    # b-ions -> 0\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"]\n",
    "\n",
    "    for _ in parsed_pep[:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "\n",
    "        frag_dict['b' + str(n_frag)] = frag_m\n",
    "\n",
    "    # y-ions -> 1\n",
    "    n_frag = 0\n",
    "    frag_m = mass_dict[\"Proton\"] + mass_dict[\"H2O\"]\n",
    "    for _ in parsed_pep[::-1][:-1]:\n",
    "        frag_m += mass_dict[_]\n",
    "        n_frag += 1\n",
    "        frag_dict['y' + str(n_frag)] = frag_m\n",
    "\n",
    "    return frag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': 98.06004032687,\n",
       " 'b2': 227.10263342686997,\n",
       " 'b3': 324.15539728686997,\n",
       " 'y1': 120.06551965033,\n",
       " 'y2': 217.11828351033,\n",
       " 'y3': 346.16087661033}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frag_dict(parse('PEPT'), constants.mass_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_frag_dict():\n",
    "    \n",
    "    refdict = {'b1': 98.06004032687,\n",
    " 'b2': 227.10263342686997,\n",
    " 'b3': 324.15539728686997,\n",
    " 'y1': 120.06551965033,\n",
    " 'y2': 217.11828351033,\n",
    " 'y3': 346.16087661033}\n",
    "    \n",
    "    newdict = get_frag_dict(parse('PEPT'), constants.mass_dict)\n",
    "    \n",
    "    for key in newdict.keys():\n",
    "        \n",
    "        assert np.allclose(refdict[key], newdict[key])\n",
    "        \n",
    "test_get_frag_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 µs ± 8.05 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "9.16 µs ± 658 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "peptide = parse('PEPTIDE')\n",
    "\n",
    "%timeit get_frag_dict(peptide, constants.mass_dict)\n",
    "%timeit get_fragmass(peptide, constants.mass_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us also to generate the theorteical isotopes for a fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "peptide = 'PEPTIDE'\n",
    "\n",
    "frag_dict = get_frag_dict(parse(peptide), constants.mass_dict)\n",
    "\n",
    "db_frag = list(frag_dict.values())\n",
    "db_int = [100 for _ in db_frag]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.vlines(db_frag, 0, db_int, \"k\", label=\"DB\", alpha=0.2)\n",
    "\n",
    "for _ in frag_dict.keys():\n",
    "    plt.text(frag_dict[_], 104, _, fontsize=12, alpha = 0.8)\n",
    "    \n",
    "plt.title('Theoretical Spectrum for {}'.format(peptide))\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.ylim([0,110])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra\n",
    "\n",
    "The function `get_spectrum` returns a tuple with the following content:\n",
    "\n",
    "* precursor mass\n",
    "* peptide sequence\n",
    "* fragmasses\n",
    "* fragtypes\n",
    "\n",
    "Likewise, `get_spectra` returns a list of tuples. We employ a list of tuples here as this way we can sort them easily by precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def get_spectrum(peptide, mass_dict):\n",
    "    parsed_peptide = parse(peptide)\n",
    "\n",
    "    fragmasses, fragtypes = get_fragmass(parsed_peptide, mass_dict)\n",
    "    sortindex = np.argsort(fragmasses)\n",
    "    fragmasses = fragmasses[sortindex]\n",
    "    fragtypes = fragtypes[sortindex]\n",
    "\n",
    "    precmass = get_precmass(parsed_peptide, mass_dict)\n",
    "\n",
    "    return (precmass, peptide, fragmasses, fragtypes)\n",
    "\n",
    "\n",
    "@njit\n",
    "def get_spectra(peptides, mass_dict):\n",
    "    # Numba function for parallel calculation of spectra\n",
    "    # prange does seem to make problems here..\n",
    "    spectra = []\n",
    "\n",
    "    for i in range(len(peptides)):\n",
    "        spectra.append(get_spectrum(peptides[i], mass_dict))\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(799.3599642034599, 'PEPTIDE', array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
      "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
      "       538.28713979, 574.27188371, 653.31408289, 703.31447681]), array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], dtype=int8))]\n"
     ]
    }
   ],
   "source": [
    "print(get_spectra(['PEPTIDE'], constants.mass_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def test_get_spectra():\n",
    "    \n",
    "    spectra = get_spectra(['PEPTIDE'], constants.mass_dict)\n",
    "    \n",
    "    precmass, peptide, frags, fragtypes = spectra[0]\n",
    "    \n",
    "    assert np.allclose(precmass, 799.3599642034599)\n",
    "    \n",
    "    assert peptide == 'PEPTIDE'\n",
    "    \n",
    "    assert np.allclose(frags, np.array([ 98.06004033, 148.06043425, 227.10263343, 263.08737735,\n",
    "       324.15539729, 376.17144135, 425.20307579, 477.21911985,\n",
    "       538.28713979, 574.27188371, 653.31408289, 703.31447681]))\n",
    "\n",
    "test_get_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading FASTA\n",
    "\n",
    "To read FASTA files we use the `SeqIO` module from the `Biopython` library.\n",
    "Generator expression so that we can read it one by one\n",
    "\n",
    "Additionally we define the wrapper `read_fasta` that allows to read multiple FASTA files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def read_fasta_file(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    given a fasta_file read fasta file line by line, return progress\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                parts = record.id.split(\"|\")  # pipe char\n",
    "                if len(parts) > 1:\n",
    "                    id = parts[1]\n",
    "                else:\n",
    "                    id = record.name\n",
    "                sequence = str(record.seq)\n",
    "                entry = {\n",
    "                    \"id\": id,\n",
    "                    \"name\": record.name,\n",
    "                    \"description\": record.description,\n",
    "                    \"sequence\": sequence,\n",
    "                }\n",
    "\n",
    "                yield entry\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "\n",
    "def read_fasta_file_entries(fasta_filename=\"\"):\n",
    "    \"\"\"\n",
    "    Function to count entries in fasta file\n",
    "    \"\"\"\n",
    "    with open(fasta_filename, \"rt\") as handle:\n",
    "        iterator = SeqIO.parse(handle, \"fasta\")\n",
    "        count = 0\n",
    "        while iterator:\n",
    "            try:\n",
    "                record = next(iterator)\n",
    "                count+=1\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        return count\n",
    "\n",
    "\n",
    "\n",
    "def read_fasta(path):\n",
    "    \"\"\"\n",
    "    Wrapper to read multiple files.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(path):\n",
    "        paths = glob(path + \"/*.fasta\")\n",
    "    else:\n",
    "        paths = glob(path)\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        raise KeyError(\"Not a valid Fasta Path: {}.\".format(path))\n",
    "\n",
    "    for fasta_file in paths:\n",
    "        for entry in read_fasta_file(fasta_file):\n",
    "            yield entry\n",
    "\n",
    "def check_sequence(element, AAs):\n",
    "    \"\"\"\n",
    "    Checks wheter a sequence from a FASTA entry contains valid AAs\n",
    "    \"\"\"\n",
    "    if not set(element['sequence']).issubset(AAs):\n",
    "        print('Error. This FASTA Entry contains unknown AAs and will be skipped: \\n {}\\n'.format(element))\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'A0PJZ0',\n",
       " 'name': 'sp|A0PJZ0|A20A5_HUMAN',\n",
       " 'description': 'sp|A0PJZ0|A20A5_HUMAN Putative ankyrin repeat domain-containing protein 20A5 OS=Homo sapiens OX=9606 GN=ANKRD20A5P PE=5 SV=1',\n",
       " 'sequence': 'MKLFGFRSRRGQTVLGSIDHLYTGSGYRIRYSELQKIHKAAVKGDAAEMERCLARRSGDLDALDKQHRTALHLACASGHVKVVTLLVNRKCQIDIYDKENRTPLIQAVHCQEEACAVILLEHGANPNLKDIYGNTALHYAVYSESTSLAEKLLFHGENIEALDKV'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load example fasta file\n",
    "\n",
    "fasta_path = './testfiles/test.fasta'\n",
    "\n",
    "list(read_fasta(fasta_path))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Dictionary\n",
    "\n",
    "In order to efficiently store peptides we rely on the python in dictionary. The idea is to have a dictionary with peptides as keys and indicies to proteins as values. This way we can quickly look up to which protein a peptide belongs to. The function `add_to_pept_dict` uses a regular python dictionary and allows to add peptides and stores indicies to the originating proteins as a list. If a peptide is already present in the dictionary the list is appended. The function returns a list of `added_peptides` which were not present in the dictionary yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_to_pept_dict(pept_dict, new_peptides, i):\n",
    "    \"\"\"\n",
    "    Add peptides to the peptide dictionary\n",
    "    \"\"\"\n",
    "    added_peptides = List()\n",
    "    for peptide in new_peptides:\n",
    "        if peptide in pept_dict:\n",
    "            pept_dict[peptide].append(i)\n",
    "        else:\n",
    "            pept_dict[peptide] = [i]\n",
    "            added_peptides.append(peptide)\n",
    "\n",
    "    return pept_dict, added_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABC': [0], 'DEF': [0, 1], 'GHI': [1]}\n"
     ]
    }
   ],
   "source": [
    "pept_dict = {}\n",
    "new_peptides = ['ABC','DEF']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 0)\n",
    "\n",
    "new_peptides = ['DEF','GHI']\n",
    "\n",
    "pept_dict, added_peptides = add_to_pept_dict(pept_dict, new_peptides, 1)\n",
    "\n",
    "print(pept_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a library\n",
    "\n",
    "To wrap everything up, we employ two functions `generate_library` and `generate_spectra`. The first one reads a FASTA file and generates a list of peptides, as well as the peptide dictionary and an ordered FASTA dictionary to be able to look up the protein indices laster. For the `callback` we first read the whole FASTA file to determine the total number of entries in the FASTA file.  For a typical FASTA file of 30 Mb with 40k entries, this should take less than a second. The progress of the digestion is monitored by processing the FASTA file one by one.\n",
    "The function `generate_spectra` then calculates precursor masses and fragment ions. Here, we split the total_number of sequences in `1000` steps to be able to track progress with the `callback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generate_library(mass_dict, fasta_path, callback = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "    to_add = List()\n",
    "    fasta_dict = OrderedDict()\n",
    "    fasta_index = 0\n",
    "\n",
    "    pept_dict = {}\n",
    "\n",
    "    n_entries = read_fasta_file_entries(fasta_path)\n",
    "\n",
    "    fasta_generator = read_fasta(fasta_path)\n",
    "\n",
    "    for element in fasta_generator:\n",
    "        if check_sequence(element, constants.AAs):\n",
    "            fasta_dict[fasta_index] = element\n",
    "            mod_peptides = generate_peptides(element[\"sequence\"], **kwargs)\n",
    "            pept_dict, added_seqs = add_to_pept_dict(pept_dict, mod_peptides, fasta_index)\n",
    "            if len(added_seqs) > 0:\n",
    "                to_add.extend(added_seqs)\n",
    "\n",
    "        fasta_index += 1\n",
    "\n",
    "        if callback:\n",
    "            callback(fasta_index/n_entries)\n",
    "\n",
    "    return to_add, pept_dict, fasta_dict\n",
    "\n",
    "\n",
    "def generate_spectra(to_add, mass_dict, callback = None):\n",
    "    \"\"\"\n",
    "    Function to generate a library from a fasta file\n",
    "    \"\"\"\n",
    "\n",
    "    if len(to_add) > 0:\n",
    "\n",
    "        if callback: #Chunk the spectra to get a progress_bar\n",
    "            spectra = []\n",
    "\n",
    "            stepsize = int(np.ceil(len(to_add)/1000))\n",
    "\n",
    "            for i in range(0, len(to_add), stepsize):\n",
    "                sub = to_add[i:i + stepsize]\n",
    "                spectra.extend(get_spectra(sub, mass_dict))\n",
    "                callback(i/len(to_add))\n",
    "\n",
    "        else:\n",
    "            spectra = get_spectra(to_add, mass_dict)\n",
    "    else:\n",
    "        raise ValueError(\"No spectra to generate.\")\n",
    "\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "To save the generated spectra, we rely on NumPy's NPZ format. For this we create a dictionary and save all the generated elements. The container will contain the following elements:\n",
    "\n",
    "* `precursors`: An array containing the precursor masses\n",
    "* `seqs`: An array containing the peptide sequences for the precursor masses\n",
    "* `pept_dict`: A peptide dictionary to look up the peptides and return their FASTA index\n",
    "* `fasta_dict`: A fasta dictionary to look up the FASTA entry based on a pept_dict index\n",
    "* `fragmasses`: An array containing the fragment masses. Unoccupied cells are filled with -1\n",
    "* `fragtypes:`: An array containg the fragment types. 0 equals b-ions and 1 equals y-ions. Unoccupied cells are filled with -1\n",
    "* `bounds`: An integer array containing the upper bounds for the fragment masses / types array. This is needed to quickly slice the data.\n",
    "\n",
    "All arrays are sorted according to the precursor mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from alphapept.io import list_to_numpy_f32\n",
    "\n",
    "\n",
    "def save_library(spectra, pept_dict, fasta_dict, library_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to save a library to the *.npz format.\n",
    "    \"\"\"\n",
    "\n",
    "    precmasses, seqs, fragmasses, fragtypes = zip(*spectra)\n",
    "    sortindex = np.argsort(precmasses)\n",
    "\n",
    "    to_save = {}\n",
    "\n",
    "    to_save[\"precursors\"] = np.array(precmasses)[sortindex]\n",
    "    to_save[\"seqs\"] = np.array(seqs)[sortindex]\n",
    "    to_save[\"pept_dict\"] = pept_dict\n",
    "    to_save[\"fasta_dict\"] = fasta_dict\n",
    "    to_save[\"fragmasses\"] = list_to_numpy_f32(np.array(fragmasses)[sortindex])\n",
    "    to_save[\"fragtypes\"] = list_to_numpy_f32(np.array(fragtypes)[sortindex])\n",
    "\n",
    "    to_save[\"bounds\"] = np.sum(to_save['fragmasses']>=0,axis=0).astype(np.int64)\n",
    "\n",
    "    np.savez(library_path, **to_save)\n",
    "\n",
    "    print(\"DB File saved to {}\".format)\n",
    "\n",
    "    return library_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 05_search.ipynb.\n",
      "Converted 06_score.ipynb.\n",
      "Converted 07_recalibration.ipynb.\n",
      "Converted 08_quantification.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_settings.ipynb.\n",
      "Converted 12_settings_template.ipynb.\n",
      "Converted Runner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
