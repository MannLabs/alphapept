{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification\n",
    "\n",
    "> Functions related to quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains everything to perform quantification\n",
    "\n",
    "Current ToDo here:\n",
    "\n",
    "- Most of the functions are not very well described yet\n",
    "- Introductory text to give an overview / relevant papers would be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import string\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "def to_numba_list(a_list):\n",
    "    numba_list = List()\n",
    "\n",
    "    for element in a_list:\n",
    "        numba_list.append(element)\n",
    "\n",
    "    return numba_list\n",
    "\n",
    "\n",
    "@njit\n",
    "def fast_error(normalization, profiles):\n",
    "\n",
    "    normalization = normalization.reshape(profiles[0].shape)\n",
    "\n",
    "    total_error = 0\n",
    "    for profile in profiles:\n",
    "        total_error += fast_peptide_error(profile, normalization)\n",
    "\n",
    "    return total_error\n",
    "\n",
    "\n",
    "@njit\n",
    "def fast_error_scalar(normalization, profiles):\n",
    "\n",
    "    normalization = normalization.reshape(profiles[0].shape)\n",
    "\n",
    "    total_error = np.zeros(len(profiles))\n",
    "\n",
    "    for index in range(len(profiles)):\n",
    "        profile = profiles[index]\n",
    "        total_error[index] = fast_peptide_error(profile, normalization)\n",
    "\n",
    "    return total_error\n",
    "\n",
    "\n",
    "@njit\n",
    "def fast_peptide_error(profile, normalization):\n",
    "\n",
    "    pep_ints = np.zeros(profile.shape[1])\n",
    "\n",
    "    normalized_profile = profile / normalization\n",
    "\n",
    "    for i in range(len(pep_ints)):\n",
    "        pep_ints[i] = np.nansum(normalized_profile[:, i])\n",
    "\n",
    "    pep_ints = pep_ints[pep_ints > 0]\n",
    "\n",
    "    # Loop through all combinations\n",
    "\n",
    "    n = len(pep_ints)\n",
    "\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            error += np.abs(np.log(pep_ints[i] / pep_ints[j])) ** 2\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def peptide_error(profile, normalization):\n",
    "    \"\"\"\n",
    "    Calculates the peptide error for all runs\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape normalization\n",
    "\n",
    "    normalization = normalization.reshape(profiles[0].shape)\n",
    "\n",
    "    pep_ints = np.nansum(profile / normalization, axis=0)\n",
    "\n",
    "    pep_ints = pep_ints[pep_ints > 0]\n",
    "\n",
    "    error = 0\n",
    "    column_combinations = list(combinations(range(len(pep_ints)), 2))\n",
    "\n",
    "    for ind1, ind2 in column_combinations:\n",
    "        error += np.abs(np.log(pep_ints[ind1] / pep_ints[ind2])) ** 2\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def elution_profile(timepoint, sigma, n_runs):\n",
    "    return gaussian(timepoint, sigma, np.arange(0, n_runs))\n",
    "\n",
    "\n",
    "def gaussian(mu, sigma, grid):\n",
    "    norm = 0.3989422804014327 / sigma\n",
    "    return norm * np.exp(-0.5 * ((grid - mu) / sigma) ** 2)\n",
    "\n",
    "\n",
    "def return_elution_profile(timepoint, sigma, n_runs):\n",
    "    return gaussian(timepoint, sigma, np.arange(0, n_runs))\n",
    "\n",
    "\n",
    "def simulate_sample_profiles(n_peptides, n_runs, n_samples, threshold, use_noise=True):\n",
    "    \"\"\"\n",
    "    Generate random profiles to serve as test data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    abundances = np.random.rand(n_peptides)\n",
    "    true_normalization = np.random.rand(n_runs, n_samples)\n",
    "\n",
    "    # Question: Should we normalize for each run?\n",
    "\n",
    "    maxvals = np.max(true_normalization, axis=1)\n",
    "    #true_normalization / maxvals.reshape(len(maxvals), 1)\n",
    "\n",
    "    elution_timepoints = random.choices(list(range(n_runs)), k=n_peptides)\n",
    "\n",
    "    profiles = []\n",
    "\n",
    "    for i in tqdm(range(n_peptides)):\n",
    "\n",
    "        elution_timepoint = elution_timepoints[i]\n",
    "        abundance = abundances[i]\n",
    "\n",
    "        profile = elution_profile(elution_timepoint, 1, n_runs) * abundance\n",
    "        elution_profiles = np.tile(profile, (n_samples, 1)).T\n",
    "\n",
    "        # Some gaussian noise\n",
    "        if use_noise:\n",
    "            noise = np.random.normal(1, 0.2, elution_profiles.shape)\n",
    "            noisy_profile = noise * elution_profiles\n",
    "        else:\n",
    "            noisy_profile = elution_profiles\n",
    "\n",
    "        normalized_profile = noisy_profile * true_normalization\n",
    "\n",
    "        normalized_profile[normalized_profile < threshold] = 0\n",
    "\n",
    "        normalized_profile[normalized_profile == 0] = np.nan\n",
    "\n",
    "        profiles.append(normalized_profile)\n",
    "\n",
    "    return profiles, true_normalization\n",
    "\n",
    "\n",
    "def simulate_peptide_intensities(\n",
    "    n_sequences,\n",
    "    n_samples,\n",
    "    noise=True,\n",
    "    remove=True,\n",
    "    peptide_ratio=True,\n",
    "    abundance=True,\n",
    "    signal_level=100,\n",
    "    noise_divider=10,\n",
    "    keep=0.7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Function simulate the peptide intensities\n",
    "\n",
    "    Args:\n",
    "        n_sequences: number of petpides to be simulated\n",
    "        n_samples: number of samples\n",
    "        noise: boolean to set whether to simulate noise or not\n",
    "        remove: boolean to set whether to remove intensities below a certian threshold\n",
    "        peptide_ratio: boolean to generate a random peptide ratio between samples, otherwise one\n",
    "        abundance: boolean to simulate random abundance of peptides, otherwise one,\n",
    "        signal_level: signal_level\n",
    "        noise_divider: noise level\n",
    "        keep: float for keep\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    Raises:\n",
    "        TODO: Include Exceptions\n",
    "        TODO: Consider maximum size limit of npz files.\n",
    "        TODO: also save a yaml file for this library\n",
    "    \"\"\"\n",
    "    species = [\"P\" + str(_) for _ in range(1, n_sequences + 1)]\n",
    "    sample = [string.ascii_uppercase[_] for _ in range(n_samples)]\n",
    "\n",
    "    if peptide_ratio:\n",
    "        peptide_ratio = np.random.rand(n_sequences)\n",
    "        peptide_ratio = peptide_ratio / np.sum(peptide_ratio)\n",
    "    else:\n",
    "        peptide_ratio = np.ones(n_sequences)\n",
    "\n",
    "    if abundance:\n",
    "        ab_profile = np.random.rand(n_samples, 1)\n",
    "    else:\n",
    "        ab_profile = np.ones((n_samples, 1))\n",
    "\n",
    "    original_signal = np.ones((n_samples, n_sequences))\n",
    "\n",
    "    noise_sim = (np.random.rand(n_samples, n_sequences) - 0.5) / noise_divider\n",
    "\n",
    "    if noise:\n",
    "        noisy_signal = original_signal + noise_sim\n",
    "        noisy_signal = noisy_signal * signal_level * peptide_ratio * ab_profile\n",
    "    else:\n",
    "        noisy_signal = (\n",
    "            original_signal * signal_level * peptide_ratio * ab_profile\n",
    "        )\n",
    "\n",
    "    if remove:\n",
    "        # Remove points\n",
    "        keep_probability = keep\n",
    "        to_remove = np.random.rand(n_samples, n_sequences)\n",
    "        to_remove = to_remove >= keep_probability\n",
    "\n",
    "        dummy_data = noisy_signal.copy()\n",
    "\n",
    "        dummy_data[to_remove] = 0\n",
    "\n",
    "    else:\n",
    "        dummy_data = noisy_signal\n",
    "\n",
    "    ground_truth = ab_profile.flatten()\n",
    "\n",
    "    return dummy_data, ground_truth, species, sample\n",
    "\n",
    "\n",
    "def get_protein_ratios(signal, minimum_ratios=2):\n",
    "    \"\"\"\n",
    "    Function to calculate pairwise protein ratios\n",
    "    \"\"\"\n",
    "    n_samples = signal.shape[0]\n",
    "\n",
    "    column_combinations = list(combinations(range(n_samples), 2))\n",
    "    ratios = np.empty((n_samples, n_samples))\n",
    "    weights = np.zeros((n_samples, n_samples))\n",
    "    ratios.fill(np.nan)\n",
    "\n",
    "    for element in column_combinations:\n",
    "        i = element[0]\n",
    "        j = element[1]\n",
    "\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            ratio = np.true_divide(signal[j, :], signal[i, :])\n",
    "            ratio[ratio == np.inf] = np.nan\n",
    "            ratio[ratio == 0] = np.nan\n",
    "            non_nan = np.sum(~np.isnan(ratio))\n",
    "\n",
    "            if non_nan >= minimum_ratios:\n",
    "                ratio = np.nanmedian(ratio)\n",
    "            else:\n",
    "                ratio = np.nan\n",
    "\n",
    "        ratios[j, i] = ratio\n",
    "        weights[j, i] = non_nan\n",
    "\n",
    "    return ratios, weights\n",
    "\n",
    "\n",
    "def triangle_error(normalization, ratios):\n",
    "    \"\"\"\n",
    "    Cost function for peptide normalization\n",
    "    For non-constrained solvers, returns scalar\n",
    "    \"\"\"\n",
    "    normalization = np.abs(normalization)\n",
    "\n",
    "    int_matrix = (\n",
    "        np.repeat(normalization, len(normalization))\n",
    "        .reshape((len(normalization), len(normalization)))\n",
    "        .transpose()\n",
    "    )\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        x = (np.log(ratios) - np.log(int_matrix.T) + np.log(int_matrix)) ** 2\n",
    "\n",
    "    return np.nansum(x)\n",
    "\n",
    "\n",
    "def solve_BFGS(signal):\n",
    "    \"\"\"\n",
    "    Wrapper to solve with BFGS\n",
    "    BFGS is not constrained\n",
    "    \"\"\"\n",
    "\n",
    "    ratios, weights = get_protein_ratios(signal)\n",
    "\n",
    "    n_samples = ratios.shape[0]\n",
    "    x0 = np.ones(n_samples)\n",
    "\n",
    "    res_wrapped = minimize(\n",
    "        triangle_error,\n",
    "        args=ratios,\n",
    "        x0=x0,\n",
    "        method=\"BFGS\",\n",
    "        options={\"maxiter\": 2000, \"disp\": False},\n",
    "    )\n",
    "    if res_wrapped.success:\n",
    "        solution = res_wrapped.x\n",
    "        solution = np.abs(solution / np.max(solution))\n",
    "    else:\n",
    "        solution = x0\n",
    "        print(\"Error. Minimization failed.\")\n",
    "\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_io.ipynb.\n",
      "Converted 03_fasta.ipynb.\n",
      "Converted 04_feature_finding.ipynb.\n",
      "Converted 09_matching.ipynb.\n",
      "Converted 10_constants.ipynb.\n",
      "Converted 11_runner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
